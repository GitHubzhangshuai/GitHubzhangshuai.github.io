<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张帅的Blog</title>
  
  <subtitle>用hexo搭建的简易博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-23T09:58:48.864Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Zhangshuai</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pytorch-Learning-cifar10tutorial-visualizing</title>
    <link href="http://yoursite.com/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/"/>
    <id>http://yoursite.com/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/</id>
    <published>2020-07-23T09:27:53.000Z</published>
    <updated>2020-07-23T09:58:48.864Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch-Learning-cifar10tutorial-visualizing</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h1 id="Training-a-Classifier"><a href="#Training-a-Classifier" class="headerlink" title="Training a Classifier"></a>Training a Classifier</h1><p>This is it. You have seen how to define neural networks, compute loss and make<br>updates to the weights of the network.</p><p>Now you might be thinking,</p><h2 id="What-about-data"><a href="#What-about-data" class="headerlink" title="What about data?"></a>What about data?</h2><p>Generally, when you have to deal with image, text, audio or video data,<br>you can use standard python packages that load data into a numpy array.<br>Then you can convert this array into a <code>torch.*Tensor</code>.</p><ul><li>For images, packages such as Pillow, OpenCV are useful</li><li>For audio, packages such as scipy and librosa</li><li>For text, either raw Python or Cython based loading, or NLTK and<br>SpaCy are useful</li></ul><p>Specifically for vision, we have created a package called<br><code>torchvision</code>, that has data loaders for common datasets such as<br>Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,<br><code>torchvision.datasets</code> and <code>torch.utils.data.DataLoader</code>.</p><p>This provides a huge convenience and avoids writing boilerplate code.</p><p>For this tutorial, we will use the CIFAR10 dataset.<br>It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,<br>‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of<br>size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.</p><p><img src="https://pytorch.org/tutorials/_images/cifar10.png" alt></p><p>   cifar10</p><h2 id="Training-an-image-classifier"><a href="#Training-an-image-classifier" class="headerlink" title="Training an image classifier"></a>Training an image classifier</h2><p>We will do the following steps in order:</p><ol><li><p>Load and normalizing the CIFAR10 training and test datasets using<br><code>torchvision</code></p></li><li><p>Define a Convolutional Neural Network</p></li><li><p>Define a loss function</p></li><li><p>Train the network on the training data</p></li><li><p>Test the network on the test data</p></li><li><p>Loading and normalizing CIFAR10</p></li></ol><hr><p>Using <code>torchvision</code>, it’s extremely easy to load CIFAR10.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure><p>The output of torchvision datasets are PILImage images of range [0, 1].<br>We transform them to Tensors of normalized range [-1, 1].</p><div class="alert alert-info"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting    the num_worker of torch.utils.data.DataLoader() to 0.</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">4</span>,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">4</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>,</span><br><span class="line">           <span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>)</span><br></pre></td></tr></table></figure><pre><code>Files already downloaded and verifiedFiles already downloaded and verified</code></pre><p>Let us show some of the training images, for fun.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># functions to show an image</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span><span class="params">(img)</span>:</span></span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>     <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = iter(trainloader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"><span class="comment"># print labels</span></span><br><span class="line">print(<span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_6_0.png" alt="png"></p><pre><code>horse   cat  deer   cat</code></pre><ol start="2"><li>Define a Convolutional Neural Network</li></ol><hr><p>Copy the neural network from the Neural Networks section before and modify it to<br>take 3-channel images (instead of 1-channel images as it was defined).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br></pre></td></tr></table></figure><ol start="3"><li>Define a Loss function and optimizer</li></ol><hr><p>Let’s use a Classification Cross-Entropy loss and SGD with momentum.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><ol start="4"><li>Train the network</li></ol><hr><p>This is when things start to get interesting.<br>We simply have to loop over our data iterator, and feed the inputs to the<br>network and optimize.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            print(<span class="string">'[%d, %5d] loss: %.3f'</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>[1,  2000] loss: 2.173[1,  4000] loss: 1.818[1,  6000] loss: 1.647[1,  8000] loss: 1.545[1, 10000] loss: 1.490[1, 12000] loss: 1.436[2,  2000] loss: 1.384[2,  4000] loss: 1.348[2,  6000] loss: 1.341[2,  8000] loss: 1.306[2, 10000] loss: 1.292[2, 12000] loss: 1.283Finished Training</code></pre><p>Let’s quickly save our trained model:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PATH = <span class="string">'./cifar_net.pth'</span></span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br></pre></td></tr></table></figure><p>See <code>here &lt;https://pytorch.org/docs/stable/notes/serialization.html&gt;</code>_<br>for more details on saving PyTorch models.</p><ol start="5"><li>Test the network on the test data</li></ol><hr><p>We have trained the network for 2 passes over the training dataset.<br>But we need to check if the network has learnt anything at all.</p><p>We will check this by predicting the class label that the neural network<br>outputs, and checking it against the ground-truth. If the prediction is<br>correct, we add the sample to the list of correct predictions.</p><p>Okay, first step. Let us display an image from the test set to get familiar.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataiter = iter(testloader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line">print(<span class="string">'GroundTruth: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[labels[j]] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_16_0.png" alt="png"></p><pre><code>GroundTruth:    cat  ship  ship plane</code></pre><p>Next, let’s load back in our saved model (note: saving and re-loading the model<br>wasn’t necessary here, we only did it to illustrate how to do so):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = Net()</span><br><span class="line">net.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure><pre><code>IncompatibleKeys(missing_keys=[], unexpected_keys=[])</code></pre><p>Okay, now let us see what the neural network thinks these examples above are:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputs = net(images)</span><br></pre></td></tr></table></figure><p>The outputs are energies for the 10 classes.<br>The higher the energy for a class, the more the network<br>thinks that the image is of the particular class.<br>So, let’s get the index of the highest energy:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Predicted: '</span>, <span class="string">' '</span>.join(<span class="string">'%5s'</span> % classes[predicted[j]]</span><br><span class="line">                              <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><pre><code>Predicted:    cat plane plane plane</code></pre><p>The results seem pretty good.</p><p>Let us look at how the network performs on the whole dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).sum().item()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Accuracy of the network on the 10000 test images: %d %%'</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure><pre><code>Accuracy of the network on the 10000 test images: 53 %</code></pre><p>That looks way better than chance, which is 10% accuracy (randomly picking<br>a class out of 10 classes).<br>Seems like the network learnt something.</p><p>Hmmm, what are the classes that performed well, and the classes that did<br>not perform well:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class_correct = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line">class_total = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">        c = (predicted == labels).squeeze()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            class_correct[label] += c[i].item()</span><br><span class="line">            class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'Accuracy of %5s : %2d %%'</span> % (</span><br><span class="line">        classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure><pre><code>Accuracy of plane : 71 %Accuracy of   car : 57 %Accuracy of  bird : 26 %Accuracy of   cat : 32 %Accuracy of  deer : 52 %Accuracy of   dog : 40 %Accuracy of  frog : 72 %Accuracy of horse : 74 %Accuracy of  ship : 57 %Accuracy of truck : 53 %</code></pre><p>Okay, so what next?</p><p>How do we run these neural networks on the GPU?</p><h2 id="Training-on-GPU"><a href="#Training-on-GPU" class="headerlink" title="Training on GPU"></a>Training on GPU</h2><p>Just like how you transfer a Tensor onto the GPU, you transfer the neural<br>net onto the GPU.</p><p>Let’s first define our device as the first visible cuda device if we have<br>CUDA available:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assuming that we are on a CUDA machine, this should print a CUDA device:</span></span><br><span class="line"></span><br><span class="line">print(device)</span><br></pre></td></tr></table></figure><pre><code>cpu</code></pre><p>The rest of this section assumes that <code>device</code> is a CUDA device.</p><p>Then these methods will recursively go over all modules and convert their<br>parameters and buffers to CUDA tensors:</p><p>.. code:: python</p><pre><code>net.to(device)</code></pre><p>Remember that you will have to send the inputs and targets at every step<br>to the GPU too:</p><p>.. code:: python</p><pre><code>inputs, labels = data[0].to(device), data[1].to(device)</code></pre><p>Why dont I notice MASSIVE speedup compared to CPU? Because your network<br>is really small.</p><p><strong>Exercise:</strong> Try increasing the width of your network (argument 2 of<br>the first <code>nn.Conv2d</code>, and argument 1 of the second <code>nn.Conv2d</code> –<br>they need to be the same number), see what kind of speedup you get.</p><p><strong>Goals achieved</strong>:</p><ul><li>Understanding PyTorch’s Tensor library and neural networks at a high level.</li><li>Train a small neural network to classify images</li></ul><h2 id="Training-on-multiple-GPUs"><a href="#Training-on-multiple-GPUs" class="headerlink" title="Training on multiple GPUs"></a>Training on multiple GPUs</h2><p>If you want to see even more MASSIVE speedup using all of your GPUs,<br>please check out :doc:<code>data_parallel_tutorial</code>.</p><h2 id="Where-do-I-go-next"><a href="#Where-do-I-go-next" class="headerlink" title="Where do I go next?"></a>Where do I go next?</h2><ul><li>:doc:<code>Train neural nets to play video games &lt;/intermediate/reinforcement_q_learning&gt;</code></li><li><code>Train a state-of-the-art ResNet network on imagenet</code>_</li><li><code>Train a face generator using Generative Adversarial Networks</code>_</li><li><code>Train a word-level language model using Recurrent LSTM networks</code>_</li><li><code>More examples</code>_</li><li><code>More tutorials</code>_</li><li><code>Discuss PyTorch on the Forums</code>_</li><li><code>Chat with other users on Slack</code>_</li></ul><h2 id="VISUALIZING-MODELS-DATA-AND-TRAINING-WITH-TENSORBOARD"><a href="#VISUALIZING-MODELS-DATA-AND-TRAINING-WITH-TENSORBOARD" class="headerlink" title="VISUALIZING MODELS, DATA, AND TRAINING WITH TENSORBOARD"></a>VISUALIZING MODELS, DATA, AND TRAINING WITH TENSORBOARD</h2><p>In the 60 Minute Blitz, we show you how to load in data, feed it through a model we define as a subclass of nn.Module, train this model on training data, and test it on test data. To see what’s happening, we print out some statistics as the model is training to get a sense for whether training is progressing. However, we can do much better than that: PyTorch integrates with TensorBoard, a tool designed for visualizing the results of neural network training runs. This tutorial illustrates some of its functionality, using the Fashion-MNIST dataset which can be read into PyTorch using torchvision.datasets.</p><p>In this tutorial, we’ll learn how to:</p><ul><li>Read in data and with appropriate transforms (nearly identical to the prior tutorial).</li><li>Set up TensorBoard.</li><li>Write to TensorBoard.</li><li>Inspect a model architecture using TensorBoard.</li></ul><p>Use TensorBoard to create interactive versions of the visualizations we created in last tutorial, with less code<br>Specifically, on point #5, we’ll see:</p><ul><li>A couple of ways to inspect our training data</li><li>How to track our model’s performance as it trains</li><li>How to assess our model’s performance once it is trained.</li><li>We’ll begin with similar boilerplate code as in the CIFAR-10 tutorial:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># transforms</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># datasets</span></span><br><span class="line">trainset = torchvision.datasets.FashionMNIST(<span class="string">'./data'</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    transform=transform)</span><br><span class="line">testset = torchvision.datasets.FashionMNIST(<span class="string">'./data'</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataloaders</span></span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">4</span>,</span><br><span class="line">                                        shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">4</span>,</span><br><span class="line">                                        shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># constant for classes</span></span><br><span class="line">classes = (<span class="string">'T-shirt/top'</span>, <span class="string">'Trouser'</span>, <span class="string">'Pullover'</span>, <span class="string">'Dress'</span>, <span class="string">'Coat'</span>,</span><br><span class="line">        <span class="string">'Sandal'</span>, <span class="string">'Shirt'</span>, <span class="string">'Sneaker'</span>, <span class="string">'Bag'</span>, <span class="string">'Ankle Boot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># helper function to show an image</span></span><br><span class="line"><span class="comment"># (used in the `plot_classes_preds` function below)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matplotlib_imshow</span><span class="params">(img, one_channel=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> one_channel:</span><br><span class="line">        img = img.mean(dim=<span class="number">0</span>)</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>     <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    <span class="keyword">if</span> one_channel:</span><br><span class="line">        plt.imshow(npimg, cmap=<span class="string">"Greys"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><pre><code>Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\FashionMNIST\raw\train-images-idx3-ubyte.gz100.0%Extracting ./data\FashionMNIST\raw\train-images-idx3-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\FashionMNIST\raw\train-labels-idx1-ubyte.gz111.0%Extracting ./data\FashionMNIST\raw\train-labels-idx1-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz100.0%Extracting ./data\FashionMNIST\raw\t10k-images-idx3-ubyte.gzDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz159.1%Extracting ./data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gzProcessing...Done!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. TensorBoard setup</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(<span class="string">'runs/fashion_mnist_experiment_1'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Writing to TensorBoard</span></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = iter(trainloader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line"><span class="comment"># create grid of images</span></span><br><span class="line">img_grid = torchvision.utils.make_grid(images)</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">matplotlib_imshow(img_grid, one_channel=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># write to tensorboard</span></span><br><span class="line">writer.add_image(<span class="string">'four_fashion_mnist_images'</span>, img_grid)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Now running: tensorboard --logdir=runs</span></span><br><span class="line"><span class="comment"># from the command line and then navigating to https://localhost:6006</span></span><br></pre></td></tr></table></figure><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_32_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. Inspect the model using TensorBoard</span></span><br><span class="line">writer.add_graph(net, images)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4. Adding a “Projector” to TensorBoard</span></span><br><span class="line"><span class="comment"># helper function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_n_random</span><span class="params">(data, labels, n=<span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Selects n random datapoints and their corresponding labels from a dataset</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> len(data) == len(labels)</span><br><span class="line"></span><br><span class="line">    perm = torch.randperm(len(data))</span><br><span class="line">    <span class="keyword">return</span> data[perm][:n], labels[perm][:n]</span><br><span class="line"></span><br><span class="line"><span class="comment"># select random images and their target indices</span></span><br><span class="line">images, labels = select_n_random(trainset.data, trainset.targets)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get the class labels for each image</span></span><br><span class="line">class_labels = [classes[lab] <span class="keyword">for</span> lab <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line"><span class="comment"># log embeddings</span></span><br><span class="line">features = images.view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">writer.add_embedding(features,</span><br><span class="line">                    metadata=class_labels,</span><br><span class="line">                    label_img=images.unsqueeze(<span class="number">1</span>))</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5. Tracking model training with TensorBoard</span></span><br><span class="line"><span class="comment"># helper functions</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">images_to_probs</span><span class="params">(net, images)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Generates predictions and corresponding probabilities from a trained</span></span><br><span class="line"><span class="string">    network and a list of images</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    output = net(images)</span><br><span class="line">    <span class="comment"># convert output probabilities to predicted class</span></span><br><span class="line">    _, preds_tensor = torch.max(output, <span class="number">1</span>)</span><br><span class="line">    preds = np.squeeze(preds_tensor.numpy())</span><br><span class="line">    <span class="keyword">return</span> preds, [F.softmax(el, dim=<span class="number">0</span>)[i].item() <span class="keyword">for</span> i, el <span class="keyword">in</span> zip(preds, output)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_classes_preds</span><span class="params">(net, images, labels)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Generates matplotlib Figure using a trained network, along with images</span></span><br><span class="line"><span class="string">    and labels from a batch, that shows the network's top prediction along</span></span><br><span class="line"><span class="string">    with its probability, alongside the actual label, coloring this</span></span><br><span class="line"><span class="string">    information based on whether the prediction was correct or not.</span></span><br><span class="line"><span class="string">    Uses the "images_to_probs" function.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    preds, probs = images_to_probs(net, images)</span><br><span class="line">    <span class="comment"># plot the images in the batch, along with predicted and true labels</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">48</span>))</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> np.arange(<span class="number">4</span>):</span><br><span class="line">        ax = fig.add_subplot(<span class="number">1</span>, <span class="number">4</span>, idx+<span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">        matplotlib_imshow(images[idx], one_channel=<span class="literal">True</span>)</span><br><span class="line">        ax.set_title(<span class="string">"&#123;0&#125;, &#123;1:.1f&#125;%\n(label: &#123;2&#125;)"</span>.format(</span><br><span class="line">            classes[preds[idx]],</span><br><span class="line">            probs[idx] * <span class="number">100.0</span>,</span><br><span class="line">            classes[labels[idx]]),</span><br><span class="line">                    color=(<span class="string">"green"</span> <span class="keyword">if</span> preds[idx]==labels[idx].item() <span class="keyword">else</span> <span class="string">"red"</span>))</span><br><span class="line">    <span class="keyword">return</span> fig</span><br><span class="line"></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get the inputs; data is a list of [inputs, labels]</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">999</span>:    <span class="comment"># every 1000 mini-batches...</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ...log the running loss</span></span><br><span class="line">            writer.add_scalar(<span class="string">'training loss'</span>,</span><br><span class="line">                            running_loss / <span class="number">1000</span>,</span><br><span class="line">                            epoch * len(trainloader) + i)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># ...log a Matplotlib Figure showing the model's predictions on a</span></span><br><span class="line">            <span class="comment"># random mini-batch</span></span><br><span class="line">            writer.add_figure(<span class="string">'predictions vs. actuals'</span>,</span><br><span class="line">                            plot_classes_preds(net, inputs, labels),</span><br><span class="line">                            global_step=epoch * len(trainloader) + i)</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><pre><code>Finished Training</code></pre><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_1.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_2.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_3.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_4.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_5.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_6.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_7.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_8.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_9.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_10.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_11.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_12.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_13.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_14.png" alt="png"></p><p><img src="/2020/07/23/Pytorch-Learning-cifar10tutorial-visualizing/output_35_15.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 6. Assessing trained models with TensorBoard</span></span><br><span class="line"><span class="comment"># 1. gets the probability predictions in a test_size x num_classes Tensor</span></span><br><span class="line"><span class="comment"># 2. gets the preds in a test_size Tensor</span></span><br><span class="line"><span class="comment"># takes ~10 seconds to run</span></span><br><span class="line">class_probs = []</span><br><span class="line">class_preds = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        output = net(images)</span><br><span class="line">        class_probs_batch = [F.softmax(el, dim=<span class="number">0</span>) <span class="keyword">for</span> el <span class="keyword">in</span> output]</span><br><span class="line">        _, class_preds_batch = torch.max(output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        class_probs.append(class_probs_batch)</span><br><span class="line">        class_preds.append(class_preds_batch)</span><br><span class="line"></span><br><span class="line">test_probs = torch.cat([torch.stack(batch) <span class="keyword">for</span> batch <span class="keyword">in</span> class_probs])</span><br><span class="line">test_preds = torch.cat(class_preds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># helper function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_pr_curve_tensorboard</span><span class="params">(class_index, test_probs, test_preds, global_step=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Takes in a "class_index" from 0 to 9 and plots the corresponding</span></span><br><span class="line"><span class="string">    precision-recall curve</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    tensorboard_preds = test_preds == class_index</span><br><span class="line">    tensorboard_probs = test_probs[:, class_index]</span><br><span class="line"></span><br><span class="line">    writer.add_pr_curve(classes[class_index],</span><br><span class="line">                        tensorboard_preds,</span><br><span class="line">                        tensorboard_probs,</span><br><span class="line">                        global_step=global_step)</span><br><span class="line">    writer.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot all the pr curves</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(classes)):</span><br><span class="line">    add_pr_curve_tensorboard(i, test_probs, test_preds)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch-Learning-cifar10tutorial-visualizing&lt;/p&gt;
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch1.51官网教程" scheme="http://yoursite.com/tags/pytorch1-51%E5%AE%98%E7%BD%91%E6%95%99%E7%A8%8B/"/>
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch-Learning-torch.nn</title>
    <link href="http://yoursite.com/2020/07/23/Pytorch-Learning-torch-nn/"/>
    <id>http://yoursite.com/2020/07/23/Pytorch-Learning-torch-nn/</id>
    <published>2020-07-23T09:25:48.000Z</published>
    <updated>2020-07-23T09:59:10.761Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch-Learning-torch.nn</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h1 id="What-is-torch-nn-really"><a href="#What-is-torch-nn-really" class="headerlink" title="What is torch.nn really?"></a>What is <code>torch.nn</code> <em>really</em>?</h1><p>by Jeremy Howard, <code>fast.ai &lt;https://www.fast.ai&gt;</code>_. Thanks to Rachel Thomas and Francisco Ingham.</p><p>We recommend running this tutorial as a notebook, not a script. To download the notebook (.ipynb) file,<br>click the link at the top of the page.</p><p>PyTorch provides the elegantly designed modules and classes <code>torch.nn &lt;https://pytorch.org/docs/stable/nn.html&gt;</code>_ ,<br><code>torch.optim &lt;https://pytorch.org/docs/stable/optim.html&gt;</code>_ ,<br><code>Dataset &lt;https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset&gt;</code>_ ,<br>and <code>DataLoader &lt;https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader&gt;</code>_<br>to help you create and train neural networks.<br>In order to fully utilize their power and customize<br>them for your problem, you need to really understand exactly what they’re<br>doing. To develop this understanding, we will first train basic neural net<br>on the MNIST data set without using any features from these models; we will<br>initially only use the most basic PyTorch tensor functionality. Then, we will<br>incrementally add one feature from <code>torch.nn</code>, <code>torch.optim</code>, <code>Dataset</code>, or<br><code>DataLoader</code> at a time, showing exactly what each piece does, and how it<br>works to make the code either more concise, or more flexible.</p><p><strong>This tutorial assumes you already have PyTorch installed, and are familiar<br>with the basics of tensor operations.</strong> (If you’re familiar with Numpy array<br>operations, you’ll find the PyTorch tensor operations used here nearly identical).</p><h2 id="MNIST-data-setup"><a href="#MNIST-data-setup" class="headerlink" title="MNIST data setup"></a>MNIST data setup</h2><p>We will use the classic <code>MNIST &lt;http://deeplearning.net/data/mnist/&gt;</code>_ dataset,<br>which consists of black-and-white images of hand-drawn digits (between 0 and 9).</p><p>We will use <code>pathlib &lt;https://docs.python.org/3/library/pathlib.html&gt;</code>_<br>for dealing with paths (part of the Python 3 standard library), and will<br>download the dataset using<br><code>requests &lt;http://docs.python-requests.org/en/master/&gt;</code>_. We will only<br>import modules when we use them, so you can see exactly what’s being<br>used at each point.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">DATA_PATH = Path(<span class="string">"data"</span>)</span><br><span class="line">PATH = DATA_PATH / <span class="string">"mnist"</span></span><br><span class="line"></span><br><span class="line">PATH.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">URL = <span class="string">"http://deeplearning.net/data/mnist/"</span></span><br><span class="line">FILENAME = <span class="string">"mnist.pkl.gz"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> (PATH / FILENAME).exists():</span><br><span class="line">        content = requests.get(URL + FILENAME).content</span><br><span class="line">        (PATH / FILENAME).open(<span class="string">"wb"</span>).write(content)</span><br></pre></td></tr></table></figure><p>This dataset is in numpy array format, and has been stored using pickle,<br>a python-specific format for serializing data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gzip.open((PATH / FILENAME).as_posix(), <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=<span class="string">"latin-1"</span>)</span><br></pre></td></tr></table></figure><p>Each image is 28 x 28, and is being stored as a flattened row of length<br>784 (=28x28). Let’s take a look at one; we need to reshape it to 2d<br>first.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">pyplot.imshow(x_train[<span class="number">0</span>].reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">"gray"</span>)</span><br><span class="line">print(x_train.shape)</span><br></pre></td></tr></table></figure><pre><code>(50000, 784)</code></pre><p><img src="/2020/07/23/Pytorch-Learning-torch-nn/output_7_1.png" alt="png"></p><p>PyTorch uses <code>torch.tensor</code>, rather than numpy arrays, so we need to<br>convert our data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x_train, y_train, x_valid, y_valid = map(</span><br><span class="line">    torch.tensor, (x_train, y_train, x_valid, y_valid)</span><br><span class="line">)</span><br><span class="line">n, c = x_train.shape</span><br><span class="line">x_train, x_train.shape, y_train.min(), y_train.max()</span><br><span class="line">print(x_train, y_train)</span><br><span class="line">print(x_train.shape)</span><br><span class="line">print(y_train.min(), y_train.max())</span><br></pre></td></tr></table></figure><pre><code>tensor([[0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        ...,        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])torch.Size([50000, 784])tensor(0) tensor(9)</code></pre><h2 id="Neural-net-from-scratch-no-torch-nn"><a href="#Neural-net-from-scratch-no-torch-nn" class="headerlink" title="Neural net from scratch (no torch.nn)"></a>Neural net from scratch (no torch.nn)</h2><p>Let’s first create a model using nothing but PyTorch tensor operations. We’re assuming<br>you’re already familiar with the basics of neural networks. (If you’re not, you can<br>learn them at <code>course.fast.ai &lt;https://course.fast.ai&gt;</code>_).</p><p>PyTorch provides methods to create random or zero-filled tensors, which we will<br>use to create our weights and bias for a simple linear model. These are just regular<br>tensors, with one very special addition: we tell PyTorch that they require a<br>gradient. This causes PyTorch to record all of the operations done on the tensor,<br>so that it can calculate the gradient during back-propagation <em>automatically</em>!</p><p>For the weights, we set <code>requires_grad</code> <strong>after</strong> the initialization, since we<br>don’t want that step included in the gradient. (Note that a trailling <code>_</code> in<br>PyTorch signifies that the operation is performed in-place.)</p><div class="alert alert-info"><h4>Note</h4><p>We are initializing the weights here with   `Xavier initialisation <http: proceedings.mlr.press v9 glorot10a glorot10a.pdf>`_   (by multiplying with 1/sqrt(n)).</http:></p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">weights = torch.randn(<span class="number">784</span>, <span class="number">10</span>) / math.sqrt(<span class="number">784</span>)</span><br><span class="line">weights.requires_grad_()</span><br><span class="line">bias = torch.zeros(<span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>Thanks to PyTorch’s ability to calculate gradients automatically, we can<br>use any standard Python function (or callable object) as a model! So<br>let’s just write a plain matrix multiplication and broadcasted addition<br>to create a simple linear model. We also need an activation function, so<br>we’ll write <code>log_softmax</code> and use it. Remember: although PyTorch<br>provides lots of pre-written loss functions, activation functions, and<br>so forth, you can easily write your own using plain python. PyTorch will<br>even create fast GPU or vectorized CPU code for your function<br>automatically.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x - x.exp().sum(<span class="number">-1</span>).log().unsqueeze(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(xb)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> log_softmax(xb @ weights + bias)</span><br></pre></td></tr></table></figure><p>In the above, the <code>@</code> stands for the dot product operation. We will call<br>our function on one batch of data (in this case, 64 images).  This is<br>one <em>forward pass</em>.  Note that our predictions won’t be any better than<br>random at this stage, since we start with random weights.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bs = <span class="number">64</span>  <span class="comment"># batch size</span></span><br><span class="line"></span><br><span class="line">xb = x_train[<span class="number">0</span>:bs]  <span class="comment"># a mini-batch from x</span></span><br><span class="line">preds = model(xb)  <span class="comment"># predictions</span></span><br><span class="line">preds[<span class="number">0</span>], preds.shape</span><br><span class="line">print(preds[<span class="number">0</span>], preds.shape)</span><br></pre></td></tr></table></figure><pre><code>tensor([-2.2669, -2.6024, -2.8454, -1.5665, -2.7687, -2.2455, -2.6885, -2.4918,        -2.1065, -2.1682], grad_fn=&lt;SelectBackward&gt;) torch.Size([64, 10])</code></pre><p>As you see, the <code>preds</code> tensor contains not only the tensor values, but also a<br>gradient function. We’ll use this later to do backprop.</p><p>Let’s implement negative log-likelihood to use as the loss function<br>(again, we can just use standard Python):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nll</span><span class="params">(input, target)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> -input[range(target.shape[<span class="number">0</span>]), target].mean()</span><br><span class="line"></span><br><span class="line">loss_func = nll</span><br></pre></td></tr></table></figure><p>Let’s check our loss with our random model, so we can see if we improve<br>after a backprop pass later.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yb = y_train[<span class="number">0</span>:bs]</span><br><span class="line">print(loss_func(preds, yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(2.2549, grad_fn=&lt;NegBackward&gt;)</code></pre><p>Let’s also implement a function to calculate the accuracy of our model.<br>For each prediction, if the index with the largest value matches the<br>target value, then the prediction was correct.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(out, yb)</span>:</span></span><br><span class="line">    preds = torch.argmax(out, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> (preds == yb).float().mean()</span><br></pre></td></tr></table></figure><p>Let’s check the accuracy of our random model, so we can see if our<br>accuracy improves as our loss improves.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(accuracy(preds, yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.1562)</code></pre><p>We can now run a training loop.  For each iteration, we will:</p><ul><li>select a mini-batch of data (of size <code>bs</code>)</li><li>use the model to make predictions</li><li>calculate the loss</li><li><code>loss.backward()</code> updates the gradients of the model, in this case, <code>weights</code><br>and <code>bias</code>.</li></ul><p>We now use these gradients to update the weights and bias.  We do this<br>within the <code>torch.no_grad()</code> context manager, because we do not want these<br>actions to be recorded for our next calculation of the gradient.  You can read<br>more about how PyTorch’s Autograd records operations<br><code>here &lt;https://pytorch.org/docs/stable/notes/autograd.html&gt;</code>_.</p><p>We then set the<br>gradients to zero, so that we are ready for the next loop.<br>Otherwise, our gradients would record a running tally of all the operations<br>that had happened (i.e. <code>loss.backward()</code> <em>adds</em> the gradients to whatever is<br>already stored, rather than replacing them).</p><p>.. tip:: You can use the standard python debugger to step through PyTorch<br>   code, allowing you to check the various variable values at each step.<br>   Uncomment <code>set_trace()</code> below to try it out.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.core.debugger <span class="keyword">import</span> set_trace</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.5</span>  <span class="comment"># learning rate</span></span><br><span class="line">epochs = <span class="number">2</span>  <span class="comment"># how many epochs to train for</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range((n - <span class="number">1</span>) // bs + <span class="number">1</span>):</span><br><span class="line"><span class="comment">#         set_trace()</span></span><br><span class="line">        start_i = i * bs</span><br><span class="line">        end_i = start_i + bs</span><br><span class="line">        xb = x_train[start_i:end_i]</span><br><span class="line">        yb = y_train[start_i:end_i]</span><br><span class="line">        pred = model(xb)</span><br><span class="line">        loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            weights -= weights.grad * lr</span><br><span class="line">            bias -= bias.grad * lr</span><br><span class="line">            weights.grad.zero_()</span><br><span class="line">            bias.grad.zero_()</span><br></pre></td></tr></table></figure><p>That’s it: we’ve created and trained a minimal neural network (in this case, a<br>logistic regression, since we have no hidden layers) entirely from scratch!</p><p>Let’s check the loss and accuracy and compare those to what we got<br>earlier. We expect that the loss will have decreased and accuracy to<br>have increased, and they have.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(loss_func(model(xb), yb), accuracy(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.0781, grad_fn=&lt;NegBackward&gt;) tensor(1.)</code></pre><h2 id="Using-torch-nn-functional"><a href="#Using-torch-nn-functional" class="headerlink" title="Using torch.nn.functional"></a>Using torch.nn.functional</h2><p>We will now refactor our code, so that it does the same thing as before, only<br>we’ll start taking advantage of PyTorch’s <code>nn</code> classes to make it more concise<br>and flexible. At each step from here, we should be making our code one or more<br>of: shorter, more understandable, and/or more flexible.</p><p>The first and easiest step is to make our code shorter by replacing our<br>hand-written activation and loss functions with those from <code>torch.nn.functional</code><br>(which is generally imported into the namespace <code>F</code> by convention). This module<br>contains all the functions in the <code>torch.nn</code> library (whereas other parts of the<br>library contain classes). As well as a wide range of loss and activation<br>functions, you’ll also find here some convenient functions for creating neural<br>nets, such as pooling functions. (There are also functions for doing convolutions,<br>linear layers, etc, but as we’ll see, these are usually better handled using<br>other parts of the library.)</p><p>If you’re using negative log likelihood loss and log softmax activation,<br>then Pytorch provides a single function <code>F.cross_entropy</code> that combines<br>the two. So we can even remove the activation function from our model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">loss_func = F.cross_entropy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(xb)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> xb @ weights + bias</span><br></pre></td></tr></table></figure><p>Note that we no longer call <code>log_softmax</code> in the <code>model</code> function. Let’s<br>confirm that our loss and accuracy are the same as before:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(loss_func(model(xb), yb), accuracy(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.0781, grad_fn=&lt;NllLossBackward&gt;) tensor(1.)</code></pre><h2 id="Refactor-using-nn-Module"><a href="#Refactor-using-nn-Module" class="headerlink" title="Refactor using nn.Module"></a>Refactor using nn.Module</h2><p>Next up, we’ll use <code>nn.Module</code> and <code>nn.Parameter</code>, for a clearer and more<br>concise training loop. We subclass <code>nn.Module</code> (which itself is a class and<br>able to keep track of state).  In this case, we want to create a class that<br>holds our weights, bias, and method for the forward step.  <code>nn.Module</code> has a<br>number of attributes and methods (such as <code>.parameters()</code> and <code>.zero_grad()</code>)<br>which we will be using.</p><div class="alert alert-info"><h4>Note</h4><p>``nn.Module`` (uppercase M) is a PyTorch specific concept, and is a   class we'll be using a lot. ``nn.Module`` is not to be confused with the Python   concept of a (lowercase ``m``) `module <https: 3 docs.python.org tutorial modules.html>`_,   which is a file of Python code that can be imported.</https:></p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mnist_Logistic</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.weights = nn.Parameter(torch.randn(<span class="number">784</span>, <span class="number">10</span>) / math.sqrt(<span class="number">784</span>))</span><br><span class="line">        self.bias = nn.Parameter(torch.zeros(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, xb)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> xb @ self.weights + self.bias</span><br></pre></td></tr></table></figure><p>Since we’re now using an object instead of just using a function, we<br>first have to instantiate our model:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = Mnist_Logistic()</span><br></pre></td></tr></table></figure><p>Now we can calculate the loss in the same way as before. Note that<br><code>nn.Module</code> objects are used as if they are functions (i.e they are<br><em>callable</em>), but behind the scenes Pytorch will call our <code>forward</code><br>method automatically.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(2.4768, grad_fn=&lt;NllLossBackward&gt;)</code></pre><p>Previously for our training loop we had to update the values for each parameter<br>by name, and manually zero out the grads for each parameter separately, like this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with torch.no_grad():</span><br><span class="line">    weights -&#x3D; weights.grad * lr</span><br><span class="line">    bias -&#x3D; bias.grad * lr</span><br><span class="line">    weights.grad.zero_()</span><br><span class="line">    bias.grad.zero_()</span><br></pre></td></tr></table></figure><p>Now we can take advantage of model.parameters() and model.zero_grad() (which<br>are both defined by PyTorch for <code>nn.Module</code>) to make those steps more concise<br>and less prone to the error of forgetting some of our parameters, particularly<br>if we had a more complicated model:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with torch.no_grad():</span><br><span class="line">    for p in model.parameters(): </span><br><span class="line">        p -&#x3D; p.grad * lr</span><br><span class="line">        model.zero_grad()</span><br></pre></td></tr></table></figure><p>We’ll wrap our little training loop in a <code>fit</code> function so we can run it<br>again later.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range((n - <span class="number">1</span>) // bs + <span class="number">1</span>):</span><br><span class="line">            start_i = i * bs</span><br><span class="line">            end_i = start_i + bs</span><br><span class="line">            xb = x_train[start_i:end_i]</span><br><span class="line">            yb = y_train[start_i:end_i]</span><br><span class="line">            pred = model(xb)</span><br><span class="line">            loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">                    p -= p.grad * lr</span><br><span class="line">                model.zero_grad()</span><br><span class="line"></span><br><span class="line">fit()</span><br></pre></td></tr></table></figure><p>Let’s double-check that our loss has gone down:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.0860, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h2 id="Refactor-using-nn-Linear"><a href="#Refactor-using-nn-Linear" class="headerlink" title="Refactor using nn.Linear"></a>Refactor using nn.Linear</h2><p>We continue to refactor our code.  Instead of manually defining and<br>initializing <code>self.weights</code> and <code>self.bias</code>, and calculating <code>xb  @self.weights + self.bias</code>, we will instead use the Pytorch class<br><code>nn.Linear &lt;https://pytorch.org/docs/stable/nn.html#linear-layers&gt;</code>_ for a<br>linear layer, which does all that for us. Pytorch has many types of<br>predefined layers that can greatly simplify our code, and often makes it<br>faster too.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mnist_Logistic</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.lin = nn.Linear(<span class="number">784</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, xb)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.lin(xb)</span><br></pre></td></tr></table></figure><p>We instantiate our model and calculate the loss in the same way as before:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Mnist_Logistic()</span><br><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(2.3752, grad_fn=&lt;NllLossBackward&gt;)</code></pre><p>We are still able to use our same <code>fit</code> method as before.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fit()</span><br><span class="line"></span><br><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.0814, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h2 id="Refactor-using-optim"><a href="#Refactor-using-optim" class="headerlink" title="Refactor using optim"></a>Refactor using optim</h2><p>Pytorch also has a package with various optimization algorithms, <code>torch.optim</code>.<br>We can use the <code>step</code> method from our optimizer to take a forward step, instead<br>of manually updating each parameter.</p><p>This will let us replace our previous manually coded optimization step:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with torch.no_grad():</span><br><span class="line">    for p in model.parameters(): </span><br><span class="line">        p -&#x3D; p.grad * lr</span><br><span class="line">        model.zero_grad()</span><br></pre></td></tr></table></figure><p>and instead use just:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">opt.step()</span><br><span class="line">opt.zero_grad()</span><br></pre></td></tr></table></figure><p>(<code>optim.zero_grad()</code> resets the gradient to 0 and we need to call it before<br>computing the gradient for the next minibatch.)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br></pre></td></tr></table></figure><p>We’ll define a little function to create our model and optimizer so we<br>can reuse it in the future.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = Mnist_Logistic()</span><br><span class="line">    <span class="keyword">return</span> model, optim.SGD(model.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line">model, opt = get_model()</span><br><span class="line">print(loss_func(model(xb), yb))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range((n - <span class="number">1</span>) // bs + <span class="number">1</span>):</span><br><span class="line">        start_i = i * bs</span><br><span class="line">        end_i = start_i + bs</span><br><span class="line">        xb = x_train[start_i:end_i]</span><br><span class="line">        yb = y_train[start_i:end_i]</span><br><span class="line">        pred = model(xb)</span><br><span class="line">        loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line">        opt.zero_grad()</span><br><span class="line"></span><br><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(2.2501, grad_fn=&lt;NllLossBackward&gt;)tensor(0.0822, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h2 id="Refactor-using-Dataset"><a href="#Refactor-using-Dataset" class="headerlink" title="Refactor using Dataset"></a>Refactor using Dataset</h2><p>PyTorch has an abstract Dataset class.  A Dataset can be anything that has<br>a <code>__len__</code> function (called by Python’s standard <code>len</code> function) and<br>a <code>__getitem__</code> function as a way of indexing into it.<br><code>This tutorial &lt;https://pytorch.org/tutorials/beginner/data_loading_tutorial.html&gt;</code>_<br>walks through a nice example of creating a custom <code>FacialLandmarkDataset</code> class<br>as a subclass of <code>Dataset</code>.</p><p>PyTorch’s <code>TensorDataset &lt;https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#TensorDataset&gt;</code>_<br>is a Dataset wrapping tensors. By defining a length and way of indexing,<br>this also gives us a way to iterate, index, and slice along the first<br>dimension of a tensor. This will make it easier to access both the<br>independent and dependent variables in the same line as we train.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset</span><br></pre></td></tr></table></figure><p>Both <code>x_train</code> and <code>y_train</code> can be combined in a single <code>TensorDataset</code>,<br>which will be easier to iterate over and slice.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_ds = TensorDataset(x_train, y_train)</span><br></pre></td></tr></table></figure><p>Previously, we had to iterate through minibatches of x and y values separately:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xb &#x3D; x_train[start_i:end_i]</span><br><span class="line">yb &#x3D; y_train[start_i:end_i]</span><br></pre></td></tr></table></figure><p>Now, we can do these two steps together:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xb,yb &#x3D; train_ds[i*bs : i*bs+bs]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model, opt = get_model()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range((n - <span class="number">1</span>) // bs + <span class="number">1</span>):</span><br><span class="line">        xb, yb = train_ds[i * bs: i * bs + bs]</span><br><span class="line">        pred = model(xb)</span><br><span class="line">        loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line">        opt.zero_grad()</span><br><span class="line"></span><br><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.0801, grad_fn=&lt;NllLossBackward&gt;)</code></pre><h2 id="Refactor-using-DataLoader"><a href="#Refactor-using-DataLoader" class="headerlink" title="Refactor using DataLoader"></a>Refactor using DataLoader</h2><p>Pytorch’s <code>DataLoader</code> is responsible for managing batches. You can<br>create a <code>DataLoader</code> from any <code>Dataset</code>. <code>DataLoader</code> makes it easier<br>to iterate over batches. Rather than having to use <code>train_ds[i*bs : i*bs+bs]</code>,<br>the DataLoader gives us each minibatch automatically.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_ds = TensorDataset(x_train, y_train)</span><br><span class="line">train_dl = DataLoader(train_ds, batch_size=bs)</span><br></pre></td></tr></table></figure><p>Previously, our loop iterated over batches (xb, yb) like this:<br>::<br>      for i in range((n-1)//bs + 1):<br>          xb,yb = train_ds[i<em>bs : i</em>bs+bs]<br>          pred = model(xb)</p><p>Now, our loop is much cleaner, as (xb, yb) are loaded automatically from the data loader:<br>::<br>      for xb,yb in train_dl:<br>          pred = model(xb)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model, opt = get_model()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> xb, yb <span class="keyword">in</span> train_dl:</span><br><span class="line">        pred = model(xb)</span><br><span class="line">        loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line">        opt.zero_grad()</span><br><span class="line"></span><br><span class="line">print(loss_func(model(xb), yb))</span><br></pre></td></tr></table></figure><pre><code>tensor(0.0824, grad_fn=&lt;NllLossBackward&gt;)</code></pre><p>Thanks to Pytorch’s <code>nn.Module</code>, <code>nn.Parameter</code>, <code>Dataset</code>, and <code>DataLoader</code>,<br>our training loop is now dramatically smaller and easier to understand. Let’s<br>now try to add the basic features necessary to create effecive models in practice.</p><h2 id="Add-validation"><a href="#Add-validation" class="headerlink" title="Add validation"></a>Add validation</h2><p>In section 1, we were just trying to get a reasonable training loop set up for<br>use on our training data.  In reality, you <strong>always</strong> should also have<br>a <code>validation set &lt;https://www.fast.ai/2017/11/13/validation-sets/&gt;</code>_, in order<br>to identify if you are overfitting.</p><p>Shuffling the training data is<br><code>important &lt;https://www.quora.com/Does-the-order-of-training-data-matter-when-training-neural-networks&gt;</code>_<br>to prevent correlation between batches and overfitting. On the other hand, the<br>validation loss will be identical whether we shuffle the validation set or not.<br>Since shuffling takes extra time, it makes no sense to shuffle the validation data.</p><p>We’ll use a batch size for the validation set that is twice as large as<br>that for the training set. This is because the validation set does not<br>need backpropagation and thus takes less memory (it doesn’t need to<br>store the gradients). We take advantage of this to use a larger batch<br>size and compute the loss more quickly.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_ds = TensorDataset(x_train, y_train)</span><br><span class="line">train_dl = DataLoader(train_ds, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">valid_ds = TensorDataset(x_valid, y_valid)</span><br><span class="line">valid_dl = DataLoader(valid_ds, batch_size=bs * <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>We will calculate and print the validation loss at the end of each epoch.</p><p>(Note that we always call <code>model.train()</code> before training, and <code>model.eval()</code><br>before inference, because these are used by layers such as <code>nn.BatchNorm2d</code><br>and <code>nn.Dropout</code> to ensure appropriate behaviour for these different phases.)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model, opt = get_model()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> xb, yb <span class="keyword">in</span> train_dl:</span><br><span class="line">        pred = model(xb)</span><br><span class="line">        loss = loss_func(pred, yb)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line">        opt.zero_grad()</span><br><span class="line"></span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        valid_loss = sum(loss_func(model(xb), yb) <span class="keyword">for</span> xb, yb <span class="keyword">in</span> valid_dl)</span><br><span class="line"></span><br><span class="line">    print(epoch, valid_loss / len(valid_dl))</span><br></pre></td></tr></table></figure><pre><code>0 tensor(0.3169)1 tensor(0.4910)</code></pre><h2 id="Create-fit-and-get-data"><a href="#Create-fit-and-get-data" class="headerlink" title="Create fit() and get_data()"></a>Create fit() and get_data()</h2><p>We’ll now do a little refactoring of our own. Since we go through a similar<br>process twice of calculating the loss for both the training set and the<br>validation set, let’s make that into its own function, <code>loss_batch</code>, which<br>computes the loss for one batch.</p><p>We pass an optimizer in for the training set, and use it to perform<br>backprop.  For the validation set, we don’t pass an optimizer, so the<br>method doesn’t perform backprop.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_batch</span><span class="params">(model, loss_func, xb, yb, opt=None)</span>:</span></span><br><span class="line">    loss = loss_func(model(xb), yb)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line">        opt.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item(), len(xb)</span><br></pre></td></tr></table></figure><p><code>fit</code> runs the necessary operations to train our model and compute the<br>training and validation losses for each epoch.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(epochs, model, loss_func, opt, train_dl, valid_dl)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        <span class="keyword">for</span> xb, yb <span class="keyword">in</span> train_dl:</span><br><span class="line">            loss_batch(model, loss_func, xb, yb, opt)</span><br><span class="line"></span><br><span class="line">        model.eval()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            losses, nums = zip(</span><br><span class="line">                *[loss_batch(model, loss_func, xb, yb) <span class="keyword">for</span> xb, yb <span class="keyword">in</span> valid_dl]</span><br><span class="line">            )</span><br><span class="line">        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)</span><br><span class="line"></span><br><span class="line">        print(epoch, val_loss)</span><br></pre></td></tr></table></figure><p><code>get_data</code> returns dataloaders for the training and validation sets.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(train_ds, valid_ds, bs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        DataLoader(train_ds, batch_size=bs, shuffle=<span class="literal">True</span>),</span><br><span class="line">        DataLoader(valid_ds, batch_size=bs * <span class="number">2</span>),</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>Now, our whole process of obtaining the data loaders and fitting the<br>model can be run in 3 lines of code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_dl, valid_dl = get_data(train_ds, valid_ds, bs)</span><br><span class="line">model, opt = get_model()</span><br><span class="line">fit(epochs, model, loss_func, opt, train_dl, valid_dl)</span><br></pre></td></tr></table></figure><pre><code>0 0.307052354145050051 0.31455935287475584</code></pre><p>You can use these basic 3 lines of code to train a wide variety of models.<br>Let’s see if we can use them to train a convolutional neural network (CNN)!</p><h2 id="Switch-to-CNN"><a href="#Switch-to-CNN" class="headerlink" title="Switch to CNN"></a>Switch to CNN</h2><p>We are now going to build our neural network with three convolutional layers.<br>Because none of the functions in the previous section assume anything about<br>the model form, we’ll be able to use them to train a CNN without any modification.</p><p>We will use Pytorch’s predefined<br><code>Conv2d &lt;https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d&gt;</code>_ class<br>as our convolutional layer. We define a CNN with 3 convolutional layers.<br>Each convolution is followed by a ReLU.  At the end, we perform an<br>average pooling.  (Note that <code>view</code> is PyTorch’s version of numpy’s<br><code>reshape</code>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mnist_CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">16</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, xb)</span>:</span></span><br><span class="line">        xb = xb.view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        xb = F.relu(self.conv1(xb))</span><br><span class="line">        xb = F.relu(self.conv2(xb))</span><br><span class="line">        xb = F.relu(self.conv3(xb))</span><br><span class="line">        xb = F.avg_pool2d(xb, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">return</span> xb.view(<span class="number">-1</span>, xb.size(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.1</span></span><br></pre></td></tr></table></figure><p><code>Momentum &lt;https://cs231n.github.io/neural-networks-3/#sgd&gt;</code>_ is a variation on<br>stochastic gradient descent that takes previous updates into account as well<br>and generally leads to faster training.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = Mnist_CNN()</span><br><span class="line">opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">fit(epochs, model, loss_func, opt, train_dl, valid_dl)</span><br></pre></td></tr></table></figure><pre><code>0 0.88983625602722171 0.7796085683822632</code></pre><h2 id="nn-Sequential"><a href="#nn-Sequential" class="headerlink" title="nn.Sequential"></a>nn.Sequential</h2><p><code>torch.nn</code> has another handy class we can use to simply our code:<br><code>Sequential &lt;https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential&gt;</code>_ .<br>A <code>Sequential</code> object runs each of the modules contained within it, in a<br>sequential manner. This is a simpler way of writing our neural network.</p><p>To take advantage of this, we need to be able to easily define a<br><strong>custom layer</strong> from a given function.  For instance, PyTorch doesn’t<br>have a <code>view</code> layer, and we need to create one for our network. <code>Lambda</code><br>will create a layer that we can then use when defining a network with<br><code>Sequential</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lambda</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, func)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.func(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x.view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br></pre></td></tr></table></figure><p>The model created with <code>Sequential</code> is simply:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Sequential(</span><br><span class="line">    Lambda(preprocess),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">4</span>),</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">fit(epochs, model, loss_func, opt, train_dl, valid_dl)</span><br></pre></td></tr></table></figure><pre><code>0 0.47461769504547121 0.3015344765663147</code></pre><h2 id="Wrapping-DataLoader"><a href="#Wrapping-DataLoader" class="headerlink" title="Wrapping DataLoader"></a>Wrapping DataLoader</h2><p>Our CNN is fairly concise, but it only works with MNIST, because:</p><ul><li>It assumes the input is a 28*28 long vector</li><li>It assumes that the final CNN grid size is 4*4 (since that’s the average<br>pooling kernel size we used)</li></ul><p>Let’s get rid of these two assumptions, so our model works with any 2d<br>single channel image. First, we can remove the initial Lambda layer but<br>moving the data preprocessing into a generator:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x.view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WrappedDataLoader</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dl, func)</span>:</span></span><br><span class="line">        self.dl = dl</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.dl)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        batches = iter(self.dl)</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> batches:</span><br><span class="line">            <span class="keyword">yield</span> (self.func(*b))</span><br><span class="line"></span><br><span class="line">train_dl, valid_dl = get_data(train_ds, valid_ds, bs)</span><br><span class="line">train_dl = WrappedDataLoader(train_dl, preprocess)</span><br><span class="line">valid_dl = WrappedDataLoader(valid_dl, preprocess)</span><br></pre></td></tr></table></figure><p>Next, we can replace <code>nn.AvgPool2d</code> with <code>nn.AdaptiveAvgPool2d</code>, which<br>allows us to define the size of the <em>output</em> tensor we want, rather than<br>the <em>input</em> tensor we have. As a result, our model will work with any<br>size input.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.AdaptiveAvgPool2d(<span class="number">1</span>),</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>Let’s try it out:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fit(epochs, model, loss_func, opt, train_dl, valid_dl)</span><br></pre></td></tr></table></figure><pre><code>0 0.439469513940811131 0.2360862446308136</code></pre><h2 id="Using-your-GPU"><a href="#Using-your-GPU" class="headerlink" title="Using your GPU"></a>Using your GPU</h2><p>If you’re lucky enough to have access to a CUDA-capable GPU (you can<br>rent one for about $0.50/hour from most cloud providers) you can<br>use it to speed up your code. First check that your GPU is working in<br>Pytorch:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(torch.cuda.is_available())</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><p>And then create a device object for it:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dev = torch.device(</span><br><span class="line">    <span class="string">"cuda"</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">"cpu"</span>)</span><br></pre></td></tr></table></figure><p>Let’s update <code>preprocess</code> to move batches to the GPU:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x.view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).to(dev), y.to(dev)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_dl, valid_dl = get_data(train_ds, valid_ds, bs)</span><br><span class="line">train_dl = WrappedDataLoader(train_dl, preprocess)</span><br><span class="line">valid_dl = WrappedDataLoader(valid_dl, preprocess)</span><br></pre></td></tr></table></figure><p>Finally, we can move our model to the GPU.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.to(dev)</span><br><span class="line">opt = optim.SGD(model.parameters(), lr=lr, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><p>You should find it runs faster now:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fit(epochs, model, loss_func, opt, train_dl, valid_dl)</span><br></pre></td></tr></table></figure><pre><code>0 0.200874821186065671 0.21629996614456176</code></pre><h2 id="Closing-thoughts"><a href="#Closing-thoughts" class="headerlink" title="Closing thoughts"></a>Closing thoughts</h2><p>We now have a general data pipeline and training loop which you can use for<br>training many types of models using Pytorch. To see how simple training a model<br>can now be, take a look at the <code>mnist_sample</code> sample notebook.</p><p>Of course, there are many things you’ll want to add, such as data augmentation,<br>hyperparameter tuning, monitoring training, transfer learning, and so forth.<br>These features are available in the fastai library, which has been developed<br>using the same design approach shown in this tutorial, providing a natural<br>next step for practitioners looking to take their models further.</p><p>We promised at the start of this tutorial we’d explain through example each of<br><code>torch.nn</code>, <code>torch.optim</code>, <code>Dataset</code>, and <code>DataLoader</code>. So let’s summarize<br>what we’ve seen:</p><ul><li><p><strong>torch.nn</strong></p><ul><li><code>Module</code>: creates a callable which behaves like a function, but can also<br>contain state(such as neural net layer weights). It knows what <code>Parameter</code> (s) it<br>contains and can zero all their gradients, loop through them for weight updates, etc.</li><li><code>Parameter</code>: a wrapper for a tensor that tells a <code>Module</code> that it has weights<br>that need updating during backprop. Only tensors with the <code>requires_grad</code> attribute set are updated</li><li><code>functional</code>: a module(usually imported into the <code>F</code> namespace by convention)<br>which contains activation functions, loss functions, etc, as well as non-stateful<br>versions of layers such as convolutional and linear layers.</li></ul></li><li><p><code>torch.optim</code>: Contains optimizers such as <code>SGD</code>, which update the weights<br>of <code>Parameter</code> during the backward step</p></li><li><p><code>Dataset</code>: An abstract interface of objects with a <code>__len__</code> and a <code>__getitem__</code>,<br>including classes provided with Pytorch such as <code>TensorDataset</code></p></li><li><p><code>DataLoader</code>: Takes any <code>Dataset</code> and creates an iterator which returns batches of data.</p></li></ul><h2 id="我不会的单词"><a href="#我不会的单词" class="headerlink" title="我不会的单词"></a>我不会的单词</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">utilize:利用</span><br><span class="line">customize:定制</span><br><span class="line">refactor:重构</span><br><span class="line">identical:相同的</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch-Learning-torch.nn&lt;/p&gt;
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch1.51官网教程" scheme="http://yoursite.com/tags/pytorch1-51%E5%AE%98%E7%BD%91%E6%95%99%E7%A8%8B/"/>
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch-Learning-examples</title>
    <link href="http://yoursite.com/2020/07/23/Pytorch-Learning-examples/"/>
    <id>http://yoursite.com/2020/07/23/Pytorch-Learning-examples/</id>
    <published>2020-07-23T09:25:32.000Z</published>
    <updated>2020-07-23T10:00:20.579Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch-Learning-examples</p><a id="more"></a><ul><li>1.<a href="#header1">warm-up:numpy</a></li><li>2.<a href="#header2">pytorch:tensors</a></li><li>3.<a href="#header3">pytorch:tensors and autograd</a></li><li>4.<a href="#header4">pytorch:defining new autograd functions</a></li><li>5.<a href="#header5">tensorflow1.x:static graphs</a></li><li>6.<a href="#header6">pytorch:nn</a></li><li>7.<a href="#header7">pytorch:optim</a></li><li>8.<a href="#header8">pytorch:custom nn modules</a></li><li>9.<a href="#header9">pytorch:control flow+weight sharing</a></li></ul><h1 id="warm-up-numpy"><a href="#warm-up-numpy" class="headerlink" title="warm-up:numpy"></a><span id="header1">warm-up:numpy</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="Warm-up-numpy"><a href="#Warm-up-numpy" class="headerlink" title="Warm-up: numpy"></a>Warm-up: numpy</h2><p>A fully-connected ReLU network with one hidden layer and no biases, trained to<br>predict y from x using Euclidean error.</p><p>This implementation uses numpy to manually compute the forward pass, loss, and<br>backward pass.</p><p>A numpy array is a generic n-dimensional array; it does not know anything about<br>deep learning or gradients or computational graphs, and is just a way to perform<br>generic numeric computations.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.dot(w1)</span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.dot(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><pre><code>0 38502658.121784671 39021030.5051500352 43783005.359469283 43513345.957547724 33130647.5743021565 18494184.5827089066 8309147.3120929747 3709728.90043023378 1973222.00640194479 1292160.302042167910 969207.669652336611 777313.216624471112 642885.445805720413 539862.096494385614 457706.3691039313615 390776.9998036827316 335541.366044388217 289534.969840669718 250999.089117504719 218440.892216002120 190801.0350538508221 167229.4111161939222 147030.1499517079823 129644.5566975234324 114634.8557394440125 101654.5091088093826 90379.6691015803427 80547.5042060514128 71942.3023425903129 64389.5389746246530 57755.01160866779531 51903.6147844508232 46747.3782186621833 42180.3667054835634 38120.1014324445335 34504.836786208536 31283.62582576260337 28409.55482622988338 25832.8441065927139 23520.94490195371340 21443.9287248615841 19573.4961957905442 17887.5296118543143 16364.90191715814244 14986.99907487606145 13739.2178249793446 12607.39291010569847 11579.32265338763948 10644.06182831764549 9792.95616820409150 9016.95690620057851 8309.61938771363652 7664.01398516503953 7073.44980079116654 6532.83392081704255 6037.53846405572256 5583.27482231634557 5166.315037295702558 4783.43896688735659 4431.26511821845660 4107.30625067173561 3809.17324428442462 3534.306552632403563 3281.38248719660964 3048.272032777972565 2832.961363890582666 2634.055248654373467 2450.120868078801368 2280.003861210682869 2122.502034812571870 1976.614076376976571 1841.48028219392272 1716.143614435584673 1599.849821051512774 1491.92510360600675 1391.7478816340876 1298.70082166170277 1212.21245078229978 1131.794269697062679 1057.043004330298880 987.492519928740681 922.746029889500582 862.463745582051883 806.33529070793284 754.034789026812985 705.303259019786886 659.864058368210987 617.471504349213588 577.936932077719989 541.038271159059690 506.6213968822449491 474.4614646023590692 444.428985022876193 416.383171450924194 390.178126241481895 365.6841615686796696 342.782824305860997 321.3745103325069398 301.3434434552800799 282.6049616675032100 265.0769405906856101 248.66706624922423102 233.31182982470165103 218.93579583019107104 205.47399586723316105 192.8673639685237106 181.05784775853311107 169.9914161272534108 159.62205201703807109 149.90414548125696110 140.7986893389537111 132.2586907147042112 124.25279696970381113 116.74222194734885114 109.70210950592357115 103.09497001058955116 96.89525543441061117 91.07884065063246118 85.6198765958778119 80.49732520749234120 75.6882961733577121 71.1722154368565122 66.93235677110607123 62.95241596773887124 59.21332801738676125 55.70220136122839126 52.40276978766286127 49.30324491666052128 46.39219465065453129 43.6561631420701130 41.08445097890545131 38.66705716574056132 36.39569090451589133 34.2596896820596134 32.25129366141559135 30.36277332849072136 28.58840749936592137 26.91886404849481138 25.348295684128104139 23.871887568407733140 22.482392230639924141 21.1752612429013142 19.94540814626695143 18.78848359075504144 17.699455611505552145 16.674867891142245146 15.710568962031482147 14.802825886952098148 13.94842074029503149 13.144227723348116150 12.387131550628439151 11.674026481428772152 11.002689146006661153 10.370609949309603154 9.775509369377593155 9.215072226656517156 8.687075426828947157 8.189767782525552158 7.7214576865624025159 7.280233710481657160 6.864642688917494161 6.473008103216368162 6.104105173833666163 5.7564916113754085164 5.428879681554832165 5.120147993533515166 4.829259142691539167 4.555145740046442168 4.29672213329475169 4.053143156190888170 3.8235214202376655171 3.607138244094545172 3.4031196927940224173 3.210757574413539174 3.0293765387034064175 2.858454621478234176 2.697234384156207177 2.545177266862872178 2.4017939117722404179 2.2665997813870664180 2.1391195167593566181 2.0188693271562754182 1.9054496369340477183 1.7984763417415828184 1.6975705115269373185 1.6023729047397333186 1.512573512380922187 1.4278650471502181188 1.347969970837449189 1.272567002922919190 1.2014204465432794191 1.1342855863955332192 1.0709568915888343193 1.0111820179227746194 0.9547746744541861195 0.9015532749111042196 0.8513302278674784197 0.803922014568537198 0.7591740066091374199 0.7169375303267338200 0.6770877114086349201 0.6394607979618921202 0.6039480138637082203 0.5704178896870162204 0.5387711941311117205 0.5088920505641997206 0.4806800135074349207 0.45404935956164216208 0.4289117734184146209 0.40517486327826213210 0.38275697069924214211 0.36158944936278636212 0.3416070794747825213 0.3227344916114124214 0.3049141167911339215 0.28808300182326085216 0.27219060149023244217 0.2571773488343734218 0.24299758077475503219 0.22960605968706874220 0.21696181922245522221 0.20501866875786806222 0.19373590402638502223 0.1830764093023291224 0.17300985254584955225 0.1635004063397864226 0.15451596252804456227 0.14602859536330753228 0.13801270444499963229 0.1304395543791902230 0.12328307118542486231 0.1165215280650118232 0.11013498048221826233 0.10409915585381448234 0.09839683048227854235 0.09300849009893092236 0.08791893479291592237 0.08310796594355277238 0.07856156604359649239 0.07426508307950577240 0.07020565731703925241 0.06636946700613897242 0.0627437660794708243 0.059317781060088316244 0.05608034093448906245 0.05301955241121613246 0.050126674069563906247 0.04739256213401111248 0.04480928906259292249 0.04236691748155608250 0.04005879599601969251 0.03787661761938381252 0.03581475257492655253 0.033864928740949526254 0.032021804201541854255 0.030279858100986354256 0.02863334928312954257 0.02707658789186648258 0.025604569332906155259 0.024213249395320283260 0.022897970661672578261 0.02165425187746097262 0.020478737432682297263 0.01936719332160696264 0.018316430865928372265 0.017322619307502316266 0.016383050617920083267 0.015494734481326376268 0.014655032299327592269 0.013860819190983916270 0.013109809002567857271 0.0123997755042141272 0.011728358290906498273 0.011093355906296416274 0.01049298268330884275 0.009925290535664889276 0.009388360895355642277 0.008880549450207519278 0.008400420664047465279 0.007946325800609208280 0.00751686776061394281 0.007110688095051999282 0.006726592064373132283 0.00636331544306615284 0.006019761179348237285 0.005694800059913335286 0.005387424438387055287 0.005096730276146309288 0.004821747870498604289 0.004561741644547909290 0.004315728687198646291 0.004083088241466739292 0.0038630342216639736293 0.0036548280743543514294 0.003457908894412565295 0.0032716544897889873296 0.003095480430783593297 0.0029287903501173454298 0.0027711283850350016299 0.002622002726801867300 0.0024808885834647024301 0.0023473968087844807302 0.00222113284310873303 0.00210170542574699304 0.0019887074497667136305 0.0018817802500325769306 0.00178065116010868307 0.0016849552143364992308 0.0015944091801416442309 0.001508753706017779310 0.0014277397746070208311 0.0013510695821452332312 0.0012785229777043136313 0.0012098928983483854314 0.0011449625641886667315 0.0010835156717760649316 0.001025377588941091317 0.0009703758384736077318 0.0009183361752611588319 0.0008690850720838991320 0.0008224940700348837321 0.0007784029943592372322 0.0007366791771033156323 0.0006971989990605096324 0.0006598426281655082325 0.000624495741732001326 0.0005910439292796761327 0.0005593973773407745328 0.0005294403512899198329 0.0005010976939705757330 0.00047427317778801455331 0.0004488877470686361332 0.0004248669939759654333 0.0004021385047171281334 0.0003806279081745162335 0.0003602664168058468336 0.00034099755680728995337 0.0003227653070463328338 0.00030550707403562225339 0.0002891754204576711340 0.000273721587865668341 0.00025909406293294767342 0.0002452471530517434343 0.0002321429824444712344 0.00021974540966147302345 0.00020800723976222412346 0.00019689755859322988347 0.00018638458674544666348 0.00017643522452308918349 0.00016701530053816744350 0.0001581003279303452351 0.00014966407110653316352 0.00014167707307891997353 0.00013411790417482185354 0.00012696356477874673355 0.00012019230146127977356 0.00011378157083006711357 0.00010771346551538498358 0.0001019705019676451359 9.653404961343065e-05360 9.138760257508527e-05361 8.651709721760377e-05362 8.19070094203869e-05363 7.754226881202036e-05364 7.341041687150536e-05365 6.94995078743375e-05366 6.579726835351665e-05367 6.229309750532338e-05368 5.897611236256165e-05369 5.583565153701364e-05370 5.286297313654044e-05371 5.004834708849745e-05372 4.738444170826265e-05373 4.486241750382573e-05374 4.2474866618345255e-05375 4.0215019660048885e-05376 3.807518640145299e-05377 3.604963907599714e-05378 3.4131911558009186e-05379 3.231655671510322e-05380 3.059770246224207e-05381 2.8970757618958097e-05382 2.743057310133526e-05383 2.5972006538400987e-05384 2.459140169431031e-05385 2.3284245013094282e-05386 2.2046767101248254e-05387 2.0874974705148337e-05388 1.976572632623195e-05389 1.8715764940418173e-05390 1.7721415862570632e-05391 1.6779971953419194e-05392 1.588871637152896e-05393 1.5044836588187851e-05394 1.4245828226986497e-05395 1.3489410778399332e-05396 1.2773364399028685e-05397 1.2095139789484804e-05398 1.145299443496586e-05399 1.0845077903682161e-05400 1.0269508212283454e-05401 9.724527789368986e-06402 9.208527492374383e-06403 8.720045436070135e-06404 8.2573575243078e-06405 7.819257808270196e-06406 7.404463436549593e-06407 7.011821523303816e-06408 6.639943046336263e-06409 6.2878326555936834e-06410 5.954457206733875e-06411 5.638725815406013e-06412 5.339791165439266e-06413 5.056690012109548e-06414 4.7886913275527965e-06415 4.5348871524205895e-06416 4.294550962428522e-06417 4.0669989344986414e-06418 3.851507524029607e-06419 3.6474147842461815e-06420 3.4541567135768535e-06421 3.2712066098541254e-06422 3.0979501309951946e-06423 2.9338623570734417e-06424 2.778486859288849e-06425 2.6313579995304816e-06426 2.492005877958706e-06427 2.3600400344687442e-06428 2.235117848833567e-06429 2.1168180481419086e-06430 2.0047497870126444e-06431 1.8986381787503396e-06432 1.7981531121369732e-06433 1.7029874912083225e-06434 1.6128687459205246e-06435 1.5275476848984372e-06436 1.4467329944515942e-06437 1.3701865914534269e-06438 1.2977020898043846e-06439 1.2290629088171652e-06440 1.164051733130194e-06441 1.1024831847468408e-06442 1.0441903271914875e-06443 9.889751182032595e-07444 9.366772125412096e-07445 8.871553290035977e-07446 8.402520019677647e-07447 7.958308104042071e-07448 7.53763518098307e-07449 7.139244346971557e-07450 6.761960655207478e-07451 6.404595540956439e-07452 6.066124906303541e-07453 5.74556854302957e-07454 5.442030621013854e-07455 5.154497792919255e-07456 4.882203577154002e-07457 4.6243074105866146e-07458 4.380049551012981e-07459 4.1486836737937236e-07460 3.929552794591328e-07461 3.722082406282778e-07462 3.525512434892848e-07463 3.339350935587304e-07464 3.163035075274776e-07465 2.9960560558970377e-07466 2.8378833766961356e-07467 2.688083814724989e-07468 2.5461985965457267e-07469 2.4117912639785815e-07470 2.2845076123088963e-07471 2.1639404311547854e-07472 2.049768154586423e-07473 1.9416035947365062e-07474 1.8391578287894605e-07475 1.742122640542393e-07476 1.6502075323866398e-07477 1.5631602307949188e-07478 1.4807025488750153e-07479 1.4026124873333745e-07480 1.3286339655833968e-07481 1.2585529347481789e-07482 1.1921849306789818e-07483 1.1293151084301514e-07484 1.069766166825837e-07485 1.0133619692710931e-07486 9.599472852904284e-08487 9.093341825332011e-08488 8.613939196599216e-08489 8.159862515209676e-08490 7.729751975546753e-08491 7.322345528572764e-08492 6.936479915203619e-08493 6.57099781685289e-08494 6.224692745752194e-08495 5.896657665795129e-08496 5.585950062511546e-08497 5.291656163586972e-08498 5.012926872369238e-08499 4.748859133659835e-08</code></pre><h1 id="pytorch-tensors"><a href="#pytorch-tensors" class="headerlink" title="pytorch:tensors"></a><span id="header2">pytorch:tensors</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Tensors"><a href="#PyTorch-Tensors" class="headerlink" title="PyTorch: Tensors"></a>PyTorch: Tensors</h2><p>A fully-connected ReLU network with one hidden layer and no biases, trained to<br>predict y from x by minimizing squared Euclidean distance.</p><p>This implementation uses PyTorch tensors to manually compute the forward pass,<br>loss, and backward pass.</p><p>A PyTorch Tensor is basically the same as a numpy array: it does not know<br>anything about deep learning or computational graphs or gradients, and is just<br>a generic n-dimensional array to be used for arbitrary numeric computation.</p><p>The biggest difference between a numpy array and a PyTorch Tensor is that<br>a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU,<br>just cast the Tensor to a cuda datatype.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment"># device = torch.device("cuda:0") # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.mm(w1)</span><br><span class="line">    h_relu = h.clamp(min=<span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using gradient descent</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><pre><code>99 784.6785888671875199 5.850834846496582299 0.07988587021827698399 0.0017072007758542895499 0.00015852594515308738</code></pre><h1 id="pytorch-tensors-and-autograd"><a href="#pytorch-tensors-and-autograd" class="headerlink" title="pytorch:tensors and autograd"></a><span id="header3">pytorch:tensors and autograd</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Tensors-and-autograd"><a href="#PyTorch-Tensors-and-autograd" class="headerlink" title="PyTorch: Tensors and autograd"></a>PyTorch: Tensors and autograd</h2><p>A fully-connected ReLU network with one hidden layer and no biases, trained to<br>predict y from x by minimizing squared Euclidean distance.</p><p>This implementation computes the forward pass using operations on PyTorch<br>Tensors, and uses PyTorch autograd to compute gradients.</p><p>A PyTorch Tensor represents a node in a computational graph. If <code>x</code> is a<br>Tensor that has <code>x.requires_grad=True</code> then <code>x.grad</code> is another Tensor<br>holding the gradient of <code>x</code> with respect to some scalar value.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment"># device = torch.device("cuda:0") # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold input and outputs.</span></span><br><span class="line"><span class="comment"># Setting requires_grad=False indicates that we do not need to compute gradients</span></span><br><span class="line"><span class="comment"># with respect to these Tensors during the backward pass.</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors for weights.</span></span><br><span class="line"><span class="comment"># Setting requires_grad=True indicates that we want to compute gradients with</span></span><br><span class="line"><span class="comment"># respect to these Tensors during the backward pass.</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y using operations on Tensors; these</span></span><br><span class="line">    <span class="comment"># are exactly the same operations we used to compute the forward pass using</span></span><br><span class="line">    <span class="comment"># Tensors, but we do not need to keep references to intermediate values since</span></span><br><span class="line">    <span class="comment"># we are not implementing the backward pass by hand.</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(min=<span class="number">0</span>).mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss using operations on Tensors.</span></span><br><span class="line">    <span class="comment"># Now loss is a Tensor of shape (1,)</span></span><br><span class="line">    <span class="comment"># loss.item() gets the scalar value held in the loss.</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use autograd to compute the backward pass. This call will compute the</span></span><br><span class="line">    <span class="comment"># gradient of loss with respect to all Tensors with requires_grad=True.</span></span><br><span class="line">    <span class="comment"># After this call w1.grad and w2.grad will be Tensors holding the gradient</span></span><br><span class="line">    <span class="comment"># of the loss with respect to w1 and w2 respectively.</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Manually update weights using gradient descent. Wrap in torch.no_grad()</span></span><br><span class="line">    <span class="comment"># because weights have requires_grad=True, but we don't need to track this</span></span><br><span class="line">    <span class="comment"># in autograd.</span></span><br><span class="line">    <span class="comment"># An alternative way is to operate on weight.data and weight.grad.data.</span></span><br><span class="line">    <span class="comment"># Recall that tensor.data gives a tensor that shares the storage with</span></span><br><span class="line">    <span class="comment"># tensor, but doesn't track history.</span></span><br><span class="line">    <span class="comment"># You can also use torch.optim.SGD to achieve this.</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Manually zero the gradients after updating weights</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure><pre><code>99 850.6499633789062199 5.497010231018066299 0.0542689710855484399 0.0009686618577688932499 0.000102342150057666</code></pre><h1 id="pytorch-defining-new-autograd-functions"><a href="#pytorch-defining-new-autograd-functions" class="headerlink" title="pytorch:defining new autograd functions"></a><span id="header4">pytorch:defining new autograd functions</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Defining-New-autograd-Functions"><a href="#PyTorch-Defining-New-autograd-Functions" class="headerlink" title="PyTorch: Defining New autograd Functions"></a>PyTorch: Defining New autograd Functions</h2><p>A fully-connected ReLU network with one hidden layer and no biases, trained to<br>predict y from x by minimizing squared Euclidean distance.</p><p>This implementation computes the forward pass using operations on PyTorch<br>Variables, and uses PyTorch autograd to compute gradients.</p><p>In this implementation we implement our own custom autograd function to perform<br>the ReLU function.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)</span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment"># device = torch.device("cuda:0") # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold input and outputs.</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors for weights.</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># To apply our Function, we use Function.apply method. We alias this as 'relu'.</span></span><br><span class="line">    relu = MyReLU.apply</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y using operations; we compute</span></span><br><span class="line">    <span class="comment"># ReLU using our custom autograd operation.</span></span><br><span class="line">    y_pred = relu(x.mm(w1)).mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum()</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use autograd to compute the backward pass.</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using gradient descent</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Manually zero the gradients after updating weights</span></span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure><pre><code>99 173.57586669921875199 0.16617316007614136299 0.0004797253059223294399 3.693650069180876e-05499 1.2812281056540087e-05</code></pre><h1 id="pytorch-static-graphs"><a href="#pytorch-static-graphs" class="headerlink" title="pytorch:static graphs"></a><span id="header5">pytorch:static graphs</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Tensors-1"><a href="#PyTorch-Tensors-1" class="headerlink" title="PyTorch: Tensors"></a>PyTorch: Tensors</h2><p>A fully-connected ReLU network with one hidden layer and no biases, trained to<br>predict y from x by minimizing squared Euclidean distance.</p><p>This implementation uses PyTorch tensors to manually compute the forward pass,<br>loss, and backward pass.</p><p>A PyTorch Tensor is basically the same as a numpy array: it does not know<br>anything about deep learning or computational graphs or gradients, and is just<br>a generic n-dimensional array to be used for arbitrary numeric computation.</p><p>The biggest difference between a numpy array and a PyTorch Tensor is that<br>a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU,<br>just cast the Tensor to a cuda datatype.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dtype = torch.float</span><br><span class="line">device = torch.device(<span class="string">"cpu"</span>)</span><br><span class="line"><span class="comment"># device = torch.device("cuda:0") # Uncomment this to run on GPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = torch.randn(N, D_in, device=device, dtype=dtype)</span><br><span class="line">y = torch.randn(N, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = torch.randn(D_in, H, device=device, dtype=dtype)</span><br><span class="line">w2 = torch.randn(H, D_out, device=device, dtype=dtype)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.mm(w1)</span><br><span class="line">    h_relu = h.clamp(min=<span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.mm(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using gradient descent</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><pre><code>99 784.6785888671875199 5.850834846496582299 0.07988587021827698399 0.0017072007758542895499 0.00015852594515308738</code></pre><h1 id="pytorch-nn"><a href="#pytorch-nn" class="headerlink" title="pytorch:nn"></a><span id="header6">pytorch:nn</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-nn"><a href="#PyTorch-nn" class="headerlink" title="PyTorch: nn"></a>PyTorch: nn</h2><p>A fully-connected ReLU network with one hidden layer, trained to predict y from x<br>by minimizing squared Euclidean distance.</p><p>This implementation uses the nn package from PyTorch to build the network.<br>PyTorch autograd makes it easy to define computational graphs and take gradients,<br>but raw autograd can be a bit too low-level for defining complex neural networks;<br>this is where the nn package can help. The nn package defines a set of Modules,<br>which you can think of as a neural network layer that has produces output from<br>input and may have some trainable weights.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the nn package to define our model as a sequence of layers. nn.Sequential</span></span><br><span class="line"><span class="comment"># is a Module which contains other Modules, and applies them in sequence to</span></span><br><span class="line"><span class="comment"># produce its output. Each Linear Module computes output from input using a</span></span><br><span class="line"><span class="comment"># linear function, and holds internal Tensors for its weight and bias.</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The nn package also contains definitions of popular loss functions; in this</span></span><br><span class="line"><span class="comment"># case we will use Mean Squared Error (MSE) as our loss function.</span></span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span><br><span class="line">    <span class="comment"># override the __call__ operator so you can call them like functions. When</span></span><br><span class="line">    <span class="comment"># doing so you pass a Tensor of input data to the Module and it produces</span></span><br><span class="line">    <span class="comment"># a Tensor of output data.</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss. We pass Tensors containing the predicted and true</span></span><br><span class="line">    <span class="comment"># values of y, and the loss function returns a Tensor containing the</span></span><br><span class="line">    <span class="comment"># loss.</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero the gradients before running the backward pass.</span></span><br><span class="line">    model.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span><br><span class="line">    <span class="comment"># parameters of the model. Internally, the parameters of each Module are stored</span></span><br><span class="line">    <span class="comment"># in Tensors with requires_grad=True, so this call will compute gradients for</span></span><br><span class="line">    <span class="comment"># all learnable parameters in the model.</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update the weights using gradient descent. Each parameter is a Tensor, so</span></span><br><span class="line">    <span class="comment"># we can access its gradients like we did before.</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br></pre></td></tr></table></figure><pre><code>99 2.456005573272705199 0.04037925601005554299 0.001298694172874093399 5.4667791118845344e-05499 2.6507393613428576e-06</code></pre><h1 id="pytorch-optim"><a href="#pytorch-optim" class="headerlink" title="pytorch:optim"></a><span id="header7">pytorch:optim</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-optim"><a href="#PyTorch-optim" class="headerlink" title="PyTorch: optim"></a>PyTorch: optim</h2><p>A fully-connected ReLU network with one hidden layer, trained to predict y from x<br>by minimizing squared Euclidean distance.</p><p>This implementation uses the nn package from PyTorch to build the network.</p><p>Rather than manually updating the weights of the model as we have been doing,<br>we use the optim package to define an Optimizer that will update the weights<br>for us. The optim package defines many optimization algorithms that are commonly<br>used for deep learning, including SGD+momentum, RMSProp, Adam, etc.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the nn package to define our model and loss function.</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H),</span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out),</span><br><span class="line">)</span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the optim package to define an Optimizer that will update the weights of</span></span><br><span class="line"><span class="comment"># the model for us. Here we will use Adam; the optim package contains many other</span></span><br><span class="line"><span class="comment"># optimization algorithms. The first argument to the Adam constructor tells the</span></span><br><span class="line"><span class="comment"># optimizer which Tensors it should update.</span></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y by passing x to the model.</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss.</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Before the backward pass, use the optimizer object to zero all of the</span></span><br><span class="line">    <span class="comment"># gradients for the variables it will update (which are the learnable</span></span><br><span class="line">    <span class="comment"># weights of the model). This is because by default, gradients are</span></span><br><span class="line">    <span class="comment"># accumulated in buffers( i.e, not overwritten) whenever .backward()</span></span><br><span class="line">    <span class="comment"># is called. Checkout docs of torch.autograd.backward for more details.</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradient of the loss with respect to model</span></span><br><span class="line">    <span class="comment"># parameters</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calling the step function on an Optimizer makes an update to its</span></span><br><span class="line">    <span class="comment"># parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><pre><code>99 40.16399383544922199 0.3977137506008148299 0.001604456570930779399 1.6438591046608053e-05499 8.815557350771996e-08</code></pre><h1 id="pytorch-custom-nn-modules"><a href="#pytorch-custom-nn-modules" class="headerlink" title="pytorch:custom nn modules"></a><span id="header8">pytorch:custom nn modules</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Custom-nn-Modules"><a href="#PyTorch-Custom-nn-Modules" class="headerlink" title="PyTorch: Custom nn Modules"></a>PyTorch: Custom nn Modules</h2><p>A fully-connected ReLU network with one hidden layer, trained to predict y from x<br>by minimizing squared Euclidean distance.</p><p>This implementation defines the model as a custom Module subclass. Whenever you<br>want a model more complex than a simple sequence of existing Modules you will<br>need to define your model this way.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the constructor we instantiate two nn.Linear modules and assign them as</span></span><br><span class="line"><span class="string">        member variables.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward function we accept a Tensor of input data and we must return</span></span><br><span class="line"><span class="string">        a Tensor of output data. We can use Modules defined in the constructor as</span></span><br><span class="line"><span class="string">        well as arbitrary operators on Tensors.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        h_relu = self.linear1(x).clamp(min=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.linear2(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our model by instantiating the class defined above</span></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our loss function and an Optimizer. The call to model.parameters()</span></span><br><span class="line"><span class="comment"># in the SGD constructor will contain the learnable parameters of the two</span></span><br><span class="line"><span class="comment"># nn.Linear modules which are members of the model.</span></span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: Compute predicted y by passing x to the model</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = criterion(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero gradients, perform a backward pass, and update the weights.</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h1 id="pytorch-control-flow-weight-sharing"><a href="#pytorch-control-flow-weight-sharing" class="headerlink" title="pytorch:control flow+weight sharing"></a><span id="header9">pytorch:control flow+weight sharing</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="PyTorch-Control-Flow-Weight-Sharing"><a href="#PyTorch-Control-Flow-Weight-Sharing" class="headerlink" title="PyTorch: Control Flow + Weight Sharing"></a>PyTorch: Control Flow + Weight Sharing</h2><p>To showcase the power of PyTorch dynamic graphs, we will implement a very strange<br>model: a fully-connected ReLU network that on each forward pass randomly chooses<br>a number between 1 and 4 and has that many hidden layers, reusing the same<br>weights multiple times to compute the innermost hidden layers.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DynamicNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the constructor we construct three nn.Linear instances that we will use</span></span><br><span class="line"><span class="string">        in the forward pass.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(DynamicNet, self).__init__()</span><br><span class="line">        self.input_linear = torch.nn.Linear(D_in, H)</span><br><span class="line">        self.middle_linear = torch.nn.Linear(H, H)</span><br><span class="line">        self.output_linear = torch.nn.Linear(H, D_out)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3</span></span><br><span class="line"><span class="string">        and reuse the middle_linear Module that many times to compute hidden layer</span></span><br><span class="line"><span class="string">        representations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Since each forward pass builds a dynamic computation graph, we can use normal</span></span><br><span class="line"><span class="string">        Python control-flow operators like loops or conditional statements when</span></span><br><span class="line"><span class="string">        defining the forward pass of the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Here we also see that it is perfectly safe to reuse the same Module many</span></span><br><span class="line"><span class="string">        times when defining a computational graph. This is a big improvement from Lua</span></span><br><span class="line"><span class="string">        Torch, where each Module could be used only once.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        h_relu = self.input_linear(x).clamp(min=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(random.randint(<span class="number">0</span>, <span class="number">3</span>)):</span><br><span class="line">            h_relu = self.middle_linear(h_relu).clamp(min=<span class="number">0</span>)</span><br><span class="line">        y_pred = self.output_linear(h_relu)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random Tensors to hold inputs and outputs</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our model by instantiating the class defined above</span></span><br><span class="line">model = DynamicNet(D_in, H, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct our loss function and an Optimizer. Training this strange model with</span></span><br><span class="line"><span class="comment"># vanilla stochastic gradient descent is tough, so we use momentum</span></span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: Compute predicted y by passing x to the model</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = criterion(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        print(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero gradients, perform a backward pass, and update the weights.</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><pre><code>99 18.901199340820312199 7.5054731369018555299 1.1003623008728027399 0.8731748461723328499 2.003668785095215</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch-Learning-examples&lt;/p&gt;
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch1.51官网教程" scheme="http://yoursite.com/tags/pytorch1-51%E5%AE%98%E7%BD%91%E6%95%99%E7%A8%8B/"/>
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch-Learning-neural_newworks</title>
    <link href="http://yoursite.com/2020/07/23/Pytorch-Learning-neural-newworks/"/>
    <id>http://yoursite.com/2020/07/23/Pytorch-Learning-neural-newworks/</id>
    <published>2020-07-23T08:04:49.000Z</published>
    <updated>2020-07-23T09:30:14.903Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch-Learning-autograd:</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h1 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h1><p>Neural networks can be constructed using the <code>torch.nn</code> package.</p><p>Now that you had a glimpse of <code>autograd</code>, <code>nn</code> depends on<br><code>autograd</code> to define models and differentiate them.<br>An <code>nn.Module</code> contains layers, and a method <code>forward(input)</code> that<br>returns the <code>output</code>.</p><p>For example, look at this network that classifies digit images:</p><p><img src="https://pytorch.org/tutorials/_images/mnist.png" alt></p><p>   convnet</p><p>It is a simple feed-forward network. It takes the input, feeds it<br>through several layers one after the other, and then finally gives the<br>output.</p><p>A typical training procedure for a neural network is as follows:</p><ul><li>Define the neural network that has some learnable parameters (or<br>weights)</li><li>Iterate over a dataset of inputs</li><li>Process input through the network</li><li>Compute the loss (how far is the output from being correct)</li><li>Propagate gradients back into the network’s parameters</li><li>Update the weights of the network, typically using a simple update rule:<br><code>weight = weight - learning_rate * gradient</code></li></ul><h2 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a>Define the network</h2><p>Let’s define this network:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 3x3 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">6</span> * <span class="number">6</span>, <span class="number">120</span>)  <span class="comment"># 6*6 from image dimension </span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))  (fc1): Linear(in_features=576, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><p>You just have to define the <code>forward</code> function, and the <code>backward</code><br>function (where gradients are computed) is automatically defined for you<br>using <code>autograd</code>.<br>You can use any of the Tensor operations in the <code>forward</code> function.</p><p>The learnable parameters of a model are returned by <code>net.parameters()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = list(net.parameters())</span><br><span class="line">print(len(params))</span><br><span class="line">print(params[<span class="number">0</span>].size())  <span class="comment"># conv1's .weight</span></span><br></pre></td></tr></table></figure><pre><code>10torch.Size([6, 1, 3, 3])</code></pre><p>Let’s try a random 32x32 input.<br>Note: expected input size of this net (LeNet) is 32x32. To use this net on<br>the MNIST dataset, please resize the images from the dataset to 32x32.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.0416,  0.0926, -0.0761, -0.0135, -0.0745, -0.0158,  0.0696, -0.0040,         -0.0099, -0.1799]], grad_fn=&lt;AddmmBackward&gt;)</code></pre><p>Zero the gradient buffers of all parameters and backprops with random<br>gradients:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><div class="alert alert-info">    <h4>Note</h4><pre><code>torch.nn only supports mini-batches. The entire torch.nnpackage only supports inputs that are a mini-batch of samples, and nota single sample.For example, nn.Conv2d will take in a 4D Tensor ofnSamples x nChannels x Height x Width.If you have a single sample, just use input.unsqueeze(0) to adda fake batch dimension.</code></pre></div><p>Before proceeding further, let’s recap all the classes you’ve seen so far.</p><p><strong>Recap:</strong></p><ul><li><code>torch.Tensor</code> - A <em>multi-dimensional array</em> with support for autograd<br>operations like <code>backward()</code>. Also <em>holds the gradient</em> w.r.t. the<br>tensor.</li><li><code>nn.Module</code> - Neural network module. <em>Convenient way of<br>encapsulating parameters</em>, with helpers for moving them to GPU,<br>exporting, loading, etc.</li><li><code>nn.Parameter</code> - A kind of Tensor, that is <em>automatically<br>registered as a parameter when assigned as an attribute to a</em><br><code>Module</code>.</li><li><code>autograd.Function</code> - Implements <em>forward and backward definitions<br>of an autograd operation</em>. Every <code>Tensor</code> operation creates at<br>least a single <code>Function</code> node that connects to functions that<br>created a <code>Tensor</code> and <em>encodes its history</em>.</li></ul><p><strong>At this point, we covered:</strong></p><ul><li>Defining a neural network</li><li>Processing inputs and calling backward</li></ul><p><strong>Still Left:</strong></p><ul><li>Computing the loss</li><li>Updating the weights of the network</li></ul><h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>A loss function takes the (output, target) pair of inputs, and computes a<br>value that estimates how far away the output is from the target.</p><p>There are several different<br><code>loss functions &lt;https://pytorch.org/docs/nn.html#loss-functions&gt;</code>_ under the<br>nn package .<br>A simple loss is: <code>nn.MSELoss</code> which computes the mean-squared error<br>between the input and the target.</p><p>For example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output = net(input)</span><br><span class="line">target = torch.randn(<span class="number">10</span>)  <span class="comment"># a dummy target, for example</span></span><br><span class="line">target = target.view(<span class="number">1</span>, <span class="number">-1</span>)  <span class="comment"># make it the same shape as output</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure><pre><code>tensor(0.9128, grad_fn=&lt;MseLossBackward&gt;)</code></pre><p>Now, if you follow <code>loss</code> in the backward direction, using its<br><code>.grad_fn</code> attribute, you will see a graph of computations that looks<br>like this:</p><p>::</p><pre><code>input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear      -&gt; MSELoss      -&gt; loss</code></pre><p>So, when we call <code>loss.backward()</code>, the whole graph is differentiated<br>w.r.t. the loss, and all Tensors in the graph that has <code>requires_grad=True</code><br>will have their <code>.grad</code> Tensor accumulated with the gradient.</p><p>For illustration, let us follow a few steps backward:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(loss.grad_fn)  <span class="comment"># MSELoss</span></span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>])  <span class="comment"># Linear</span></span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>].next_functions[<span class="number">0</span>][<span class="number">0</span>])  <span class="comment"># ReLU</span></span><br></pre></td></tr></table></figure><pre><code>&lt;MseLossBackward object at 0x000001F109346C88&gt;&lt;AddmmBackward object at 0x000001F109346EB8&gt;&lt;AccumulateGrad object at 0x000001F109346C88&gt;</code></pre><h2 id="Backprop"><a href="#Backprop" class="headerlink" title="Backprop"></a>Backprop</h2><p>To backpropagate the error all we have to do is to <code>loss.backward()</code>.<br>You need to clear the existing gradients though, else gradients will be<br>accumulated to existing gradients.</p><p>Now we shall call <code>loss.backward()</code>, and have a look at conv1’s bias<br>gradients before and after the backward.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()     <span class="comment"># zeroes the gradient buffers of all parameters</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad before backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad after backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><pre><code>conv1.bias.grad before backwardtensor([0., 0., 0., 0., 0., 0.])conv1.bias.grad after backwardtensor([-0.0032, -0.0131,  0.0148,  0.0334, -0.0327, -0.0073])</code></pre><p>Now, we have seen how to use loss functions.</p><p><strong>Read Later:</strong></p><p>  The neural network package contains various modules and loss functions<br>  that form the building blocks of deep neural networks. A full list with<br>  documentation is <code>here &lt;https://pytorch.org/docs/nn&gt;</code>_.</p><p><strong>The only thing left to learn is:</strong></p><ul><li>Updating the weights of the network</li></ul><h2 id="Update-the-weights"><a href="#Update-the-weights" class="headerlink" title="Update the weights"></a>Update the weights</h2><p>The simplest update rule used in practice is the Stochastic Gradient<br>Descent (SGD):</p><pre><code>``weight = weight - learning_rate * gradient``</code></pre><p>We can implement this using simple Python code:</p><p>.. code:: python</p><pre><code>learning_rate = 0.01for f in net.parameters():    f.data.sub_(f.grad.data * learning_rate)</code></pre><p>However, as you use neural networks, you want to use various different<br>update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.<br>To enable this, we built a small package: <code>torch.optim</code> that<br>implements all these methods. Using it is very simple:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># create your optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in your training loop:</span></span><br><span class="line">optimizer.zero_grad()   <span class="comment"># zero the gradient buffers</span></span><br><span class="line">output = net(input)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()    <span class="comment"># Does the update</span></span><br></pre></td></tr></table></figure><p>.. Note::</p><pre><code>Observe how gradient buffers had to be manually set to zero using``optimizer.zero_grad()``. This is because gradients are accumulatedas explained in the `Backprop`_ section.</code></pre><h2 id="我不认识的单词"><a href="#我不认识的单词" class="headerlink" title="我不认识的单词"></a>我不认识的单词</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">feed-forward:前向</span><br><span class="line">glimpse:一瞥</span><br><span class="line">proce:进行</span><br><span class="line">recap:回顾</span><br><span class="line">encapsulat:封装</span><br><span class="line">assign:分配</span><br><span class="line">For illustration:为了说明</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch-Learning-autograd:&lt;/p&gt;
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch1.51官网教程" scheme="http://yoursite.com/tags/pytorch1-51%E5%AE%98%E7%BD%91%E6%95%99%E7%A8%8B/"/>
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch-Learning-autograd</title>
    <link href="http://yoursite.com/2020/07/23/Pytorch-Learning-autograd/"/>
    <id>http://yoursite.com/2020/07/23/Pytorch-Learning-autograd/</id>
    <published>2020-07-23T08:03:14.000Z</published>
    <updated>2020-07-23T09:29:50.621Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch-Learning-autograd:</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h1 id="Autograd-Automatic-Differentiation"><a href="#Autograd-Automatic-Differentiation" class="headerlink" title="Autograd: Automatic Differentiation"></a>Autograd: Automatic Differentiation</h1><p>Central to all neural networks in PyTorch is the <code>autograd</code> package.<br>Let’s first briefly visit this, and we will then go to training our<br>first neural network.</p><p>The <code>autograd</code> package provides automatic differentiation for all operations<br>on Tensors. It is a define-by-run framework, which means that your backprop is<br>defined by how your code is run, and that every single iteration can be<br>different.</p><p>Let us see this in more simple terms with some examples.</p><h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p><code>torch.Tensor</code> is the central class of the package. If you set its attribute<br><code>.requires_grad</code> as <code>True</code>, it starts to track all operations on it. When<br>you finish your computation you can call <code>.backward()</code> and have all the<br>gradients computed automatically. The gradient for this tensor will be<br>accumulated into <code>.grad</code> attribute.</p><p>To stop a tensor from tracking history, you can call <code>.detach()</code> to detach<br>it from the computation history, and to prevent future computation from being<br>tracked.</p><p>To prevent tracking history (and using memory), you can also wrap the code block<br>in <code>with torch.no_grad():</code>. This can be particularly helpful when evaluating a<br>model because the model may have trainable parameters with<br><code>requires_grad=True</code>, but for which we don’t need the gradients.</p><p>There’s one more class which is very important for autograd<br>implementation - a <code>Function</code>.</p><p><code>Tensor</code> and <code>Function</code> are interconnected and build up an acyclic<br>graph, that encodes a complete history of computation. Each tensor has<br>a <code>.grad_fn</code> attribute that references a <code>Function</code> that has created<br>the <code>Tensor</code> (except for Tensors created by the user - their<br><code>grad_fn is None</code>).</p><p>If you want to compute the derivatives, you can call <code>.backward()</code> on<br>a <code>Tensor</code>. If <code>Tensor</code> is a scalar (i.e. it holds a one element<br>data), you don’t need to specify any arguments to <code>backward()</code>,<br>however if it has more elements, you need to specify a <code>gradient</code><br>argument that is a tensor of matching shape.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><p>Create a tensor and set <code>requires_grad=True</code> to track computation with it</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[1., 1.],        [1., 1.]], requires_grad=True)</code></pre><p>Do a tensor operation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x + <span class="number">2</span></span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([[3., 3.],        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)</code></pre><p><code>y</code> was created as a result of an operation, so it has a <code>grad_fn</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(y.grad_fn)</span><br></pre></td></tr></table></figure><pre><code>&lt;AddBackward0 object at 0x0000015370CAB438&gt;</code></pre><p>Do more operations on <code>y</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">print(z, out)</span><br></pre></td></tr></table></figure><pre><code>tensor([[27., 27.],        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)</code></pre><p><code>.requires_grad_( ... )</code> changes an existing Tensor’s <code>requires_grad</code><br>flag in-place. The input flag defaults to <code>False</code> if not given.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line">print(a.requires_grad)</span><br><span class="line">a.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">print(a.requires_grad)</span><br><span class="line">b = (a * a).sum()</span><br><span class="line">print(b.grad_fn)</span><br></pre></td></tr></table></figure><pre><code>FalseTrue&lt;SumBackward0 object at 0x000001536D5A24E0&gt;</code></pre><h2 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h2><p>Let’s backprop now.<br>Because <code>out</code> contains a single scalar, <code>out.backward()</code> is<br>equivalent to <code>out.backward(torch.tensor(1.))</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out.backward()</span><br></pre></td></tr></table></figure><p>Print gradients d(out)/dx</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([[4.5000, 4.5000],        [4.5000, 4.5000]])</code></pre><p>You should have got a matrix of <code>4.5</code>. Let’s call the <code>out</code><br><em>Tensor</em> “$o$”.<br>We have that $o = \frac{1}{4}\sum_i z_i$,<br>$z_i = 3(x_i+2)^2$ and $z_i\bigr\rvert_{x_i=1} = 27$.<br>Therefore,<br>$\frac{\partial o}{\partial x_i} = \frac{3}{2}(x_i+2)$, hence<br>$\frac{\partial o}{\partial x_i}\bigr\rvert_{x_i=1} = \frac{9}{2} = 4.5$.</p><p>Mathematically, if you have a vector valued function $\vec{y}=f(\vec{x})$,<br>then the gradient of $\vec{y}$ with respect to $\vec{x}$<br>is a Jacobian matrix:</p><p>\begin{align}J=\left(\begin{array}{ccc}<br>   \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}}\<br>   \vdots &amp; \ddots &amp; \vdots\<br>   \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}<br>   \end{array}\right)\end{align}</p><p>Generally speaking, <code>torch.autograd</code> is an engine for computing<br>vector-Jacobian product. That is, given any vector<br>$v=\left(\begin{array}{cccc} v_{1} &amp; v_{2} &amp; \cdots &amp; v_{m}\end{array}\right)^{T}$,<br>compute the product $v^{T}\cdot J$. If $v$ happens to be<br>the gradient of a scalar function $l=g\left(\vec{y}\right)$,<br>that is,<br>$v=\left(\begin{array}{ccc}\frac{\partial l}{\partial y_{1}} &amp; \cdots &amp; \frac{\partial l}{\partial y_{m}}\end{array}\right)^{T}$,<br>then by the chain rule, the vector-Jacobian product would be the<br>gradient of $l$ with respect to $\vec{x}$:</p><p>\begin{align}J^{T}\cdot v=\left(\begin{array}{ccc}<br>   \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{1}}\<br>   \vdots &amp; \ddots &amp; \vdots\<br>   \frac{\partial y_{1}}{\partial x_{n}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}<br>   \end{array}\right)\left(\begin{array}{c}<br>   \frac{\partial l}{\partial y_{1}}\<br>   \vdots\<br>   \frac{\partial l}{\partial y_{m}}<br>   \end{array}\right)=\left(\begin{array}{c}<br>   \frac{\partial l}{\partial x_{1}}\<br>   \vdots\<br>   \frac{\partial l}{\partial x_{n}}<br>   \end{array}\right)\end{align}</p><p>(Note that $v^{T}\cdot J$ gives a row vector which can be<br>treated as a column vector by taking $J^{T}\cdot v$.)</p><p>This characteristic of vector-Jacobian product makes it very<br>convenient to feed external gradients into a model that has<br>non-scalar output.</p><p>Now let’s take a look at an example of vector-Jacobian product:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([849.9269, 245.4694, 633.8903], grad_fn=&lt;MulBackward0&gt;)</code></pre><p>Now in this case <code>y</code> is no longer a scalar. <code>torch.autograd</code><br>could not compute the full Jacobian directly, but if we just<br>want the vector-Jacobian product, simply pass the vector to<br><code>backward</code> as argument:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.float)</span><br><span class="line">y.backward(v)</span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><pre><code>tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])</code></pre><p>You can also stop autograd from tracking history on Tensors<br>with <code>.requires_grad=True</code> either by wrapping the code block in<br><code>with torch.no_grad():</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(x.requires_grad)</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br></pre></td></tr></table></figure><pre><code>TrueTrueFalse</code></pre><p>Or by using <code>.detach()</code> to get a new Tensor with the same<br>content but that does not require gradients:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(x.requires_grad)</span><br><span class="line">y = x.detach()</span><br><span class="line">print(y.requires_grad)</span><br><span class="line">print(x.eq(y).all())</span><br></pre></td></tr></table></figure><pre><code>TrueFalsetensor(1, dtype=torch.uint8)</code></pre><p><strong>Read Later:</strong></p><p>Document about <code>autograd.Function</code> is at<br><a href="https://pytorch.org/docs/stable/autograd.html#function" target="_blank" rel="noopener">https://pytorch.org/docs/stable/autograd.html#function</a></p><h2 id="不认识的单词"><a href="#不认识的单词" class="headerlink" title="不认识的单词"></a>不认识的单词</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Automatic:自动的</span><br><span class="line">briefly:短暂的</span><br><span class="line">track:跟踪</span><br><span class="line">specify:指明</span><br><span class="line">accumulate:累加</span><br><span class="line">particularly:尤其,格外的</span><br><span class="line">interconnect:互相连接</span><br><span class="line">acyclic:非循环的,无环的</span><br><span class="line">Mathematically:数学上</span><br><span class="line">Jacobian:雅可比</span><br><span class="line">scalar:标量</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch-Learning-autograd:&lt;/p&gt;
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="pytorch1.5.1官网教程" scheme="http://yoursite.com/tags/pytorch1-5-1%E5%AE%98%E7%BD%91%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch-Learning-tensor</title>
    <link href="http://yoursite.com/2020/07/23/Pytorch-Learning-tensor/"/>
    <id>http://yoursite.com/2020/07/23/Pytorch-Learning-tensor/</id>
    <published>2020-07-23T08:00:23.000Z</published>
    <updated>2020-07-23T09:30:20.963Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch-Learning-tensor:</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h1 id="What-is-PyTorch"><a href="#What-is-PyTorch" class="headerlink" title="What is PyTorch?"></a>What is PyTorch?</h1><p>It’s a Python-based scientific computing package targeted at two sets of<br>audiences:</p><ul><li>A replacement for NumPy to use the power of GPUs</li><li>a deep learning research platform that provides maximum flexibility<br>and speed</li></ul><h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><p>Tensors</p><p>Tensors are similar to NumPy’s ndarrays, with the addition being that<br>Tensors can also be used on a GPU to accelerate computing.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><div class="alert alert-info"><h4>Note</h4><p>An uninitialized matrix is declared,    but does not contain definite known    values before it is used. When an    uninitialized matrix is created,    whatever values were in the allocated    memory at the time will appear as the initial values.</p></div><p>Construct a 5x3 matrix, uninitialized:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[-3.4374e-14,  7.1046e-43, -3.4374e-14],        [ 7.1046e-43, -3.4374e-14,  7.1046e-43],        [-3.4374e-14,  7.1046e-43, -3.4374e-14],        [ 7.1046e-43, -3.4374e-14,  7.1046e-43],        [-3.4374e-14,  7.1046e-43, -3.4374e-14]])</code></pre><p>Construct a randomly initialized matrix:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0.6385, 0.8264, 0.0737],        [0.1567, 0.5029, 0.7141],        [0.8297, 0.3453, 0.2860],        [0.0158, 0.3826, 0.7823],        [0.3434, 0.0977, 0.1530]])</code></pre><p>Construct a matrix filled zeros and of dtype long:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0, 0, 0],        [0, 0, 0],        [0, 0, 0],        [0, 0, 0],        [0, 0, 0]])</code></pre><p>Construct a tensor directly from data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>tensor([5.5000, 3.0000])</code></pre><p>or create a tensor based on an existing tensor. These methods<br>will reuse properties of the input tensor, e.g. dtype, unless<br>new values are provided by user</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)      <span class="comment"># new_* methods take in sizes</span></span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">x = torch.randn_like(x, dtype=torch.float)    <span class="comment"># override dtype!</span></span><br><span class="line">print(x)                                      <span class="comment"># result has the same size</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]], dtype=torch.float64)tensor([[ 2.0072,  0.0294,  0.1776],        [-0.3961, -1.7436, -0.1741],        [ 0.7820,  0.5535, -0.0059],        [-1.9826, -0.7387, -0.3942],        [ 0.3501,  0.5796, -1.3633]])</code></pre><p>Get its size:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.size())</span><br></pre></td></tr></table></figure><pre><code>torch.Size([5, 3])</code></pre><div class="alert alert-info"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div><p>Operations</p><p>There are multiple syntaxes for operations. In the following<br>example, we will take a look at the addition operation.</p><p>Addition: syntax 1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x + y)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 2.6168e+00,  9.4984e-01,  4.0212e-01],        [-1.7379e-01, -9.1149e-01,  7.2974e-01],        [ 7.8210e-01,  1.0687e+00,  6.7449e-01],        [-1.4469e+00, -1.0496e-01, -1.7707e-03],        [ 7.3285e-01,  1.0422e+00, -1.0675e+00]])</code></pre><p>Addition: syntax 2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(torch.add(x, y))</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 2.6168e+00,  9.4984e-01,  4.0212e-01],        [-1.7379e-01, -9.1149e-01,  7.2974e-01],        [ 7.8210e-01,  1.0687e+00,  6.7449e-01],        [-1.4469e+00, -1.0496e-01, -1.7707e-03],        [ 7.3285e-01,  1.0422e+00, -1.0675e+00]])</code></pre><p>Addition: providing an output tensor as argument</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 2.6168e+00,  9.4984e-01,  4.0212e-01],        [-1.7379e-01, -9.1149e-01,  7.2974e-01],        [ 7.8210e-01,  1.0687e+00,  6.7449e-01],        [-1.4469e+00, -1.0496e-01, -1.7707e-03],        [ 7.3285e-01,  1.0422e+00, -1.0675e+00]])</code></pre><p>Addition: in-place</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># adds x to y</span></span><br><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 2.6168e+00,  9.4984e-01,  4.0212e-01],        [-1.7379e-01, -9.1149e-01,  7.2974e-01],        [ 7.8210e-01,  1.0687e+00,  6.7449e-01],        [-1.4469e+00, -1.0496e-01, -1.7707e-03],        [ 7.3285e-01,  1.0422e+00, -1.0675e+00]])</code></pre><div class="alert alert-info"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div><p>You can use standard NumPy-like indexing with all bells and whistles!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x[:, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>tensor([ 0.0294, -1.7436,  0.5535, -0.7387,  0.5796])</code></pre><p>Resizing: If you want to resize/reshape tensor, you can use <code>torch.view</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(<span class="number">-1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred from other dimensions</span></span><br><span class="line">print(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure><pre><code>torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</code></pre><p>If you have a one element tensor, use <code>.item()</code> to get the value as a<br>Python number</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line">print(x.item())</span><br></pre></td></tr></table></figure><pre><code>tensor([1.0191])1.0191349983215332</code></pre><p><strong>Read later:</strong></p><p>  100+ Tensor operations, including transposing, indexing, slicing,<br>  mathematical operations, linear algebra, random numbers, etc.,<br>  are described<br>  <code>here &lt;https://pytorch.org/docs/torch&gt;</code>_.</p><h2 id="NumPy-Bridge"><a href="#NumPy-Bridge" class="headerlink" title="NumPy Bridge"></a>NumPy Bridge</h2><p>Converting a Torch Tensor to a NumPy array and vice versa is a breeze.</p><p>The Torch Tensor and NumPy array will share their underlying memory<br>locations (if the Torch Tensor is on CPU), and changing one will change<br>the other.</p><p>Converting a Torch Tensor to a NumPy Array</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><pre><code>tensor([1., 1., 1., 1., 1.])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><pre><code>[1. 1. 1. 1. 1.]</code></pre><p>See how the numpy array changed in value.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.add_(<span class="number">1</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><pre><code>tensor([2., 2., 2., 2., 2.])[2. 2. 2. 2. 2.]</code></pre><p>Converting NumPy Array to Torch Tensor</p><p>See how changing the np array changed the Torch Tensor automatically</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, <span class="number">1</span>, out=a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><pre><code>[2. 2. 2. 2. 2.]tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</code></pre><p>All the Tensors on the CPU except a CharTensor support converting to<br>NumPy and back.</p><h2 id="CUDA-Tensors"><a href="#CUDA-Tensors" class="headerlink" title="CUDA Tensors"></a>CUDA Tensors</h2><p>Tensors can be moved onto any device using the <code>.to</code> method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># let us run this cell only if CUDA is available</span></span><br><span class="line"><span class="comment"># We will use ``torch.device`` objects to move tensors in and out of GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">"cuda"</span>)          <span class="comment"># a CUDA device object</span></span><br><span class="line">    y = torch.ones_like(x, device=device)  <span class="comment"># directly create a tensor on GPU</span></span><br><span class="line">    x = x.to(device)                       <span class="comment"># or just use strings ``.to("cuda")``</span></span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(<span class="string">"cpu"</span>, torch.double))       <span class="comment"># ``.to`` can also change dtype together!</span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">allocate:分配</span><br><span class="line">mutate:变异</span><br><span class="line">Bridge:桥</span><br><span class="line">vice versa:反之亦然</span><br><span class="line">underlying:底层的</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch-Learning-tensor:&lt;/p&gt;
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch1.51官网教程" scheme="http://yoursite.com/tags/pytorch1-51%E5%AE%98%E7%BD%91%E6%95%99%E7%A8%8B/"/>
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习实战-泰坦尼克号获救预测</title>
    <link href="http://yoursite.com/2020/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E8%8E%B7%E6%95%91%E9%A2%84%E6%B5%8B/"/>
    <id>http://yoursite.com/2020/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E8%8E%B7%E6%95%91%E9%A2%84%E6%B5%8B/</id>
    <published>2020-07-15T02:43:32.000Z</published>
    <updated>2020-07-15T02:46:47.711Z</updated>
    
    <content type="html"><![CDATA[<p>数据集:<a href="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/titanic_train.csv" target="_blank" rel="noopener">titanic_train.csv</a></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">titianic = pandas.read_csv(<span class="string">'../data/titanic_train.csv'</span>)</span><br><span class="line">titianic[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Name</th>      <th>Sex</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Ticket</th>      <th>Fare</th>      <th>Cabin</th>      <th>Embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>0</td>      <td>3</td>      <td>Braund, Mr. Owen Harris</td>      <td>male</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>A/5 21171</td>      <td>7.2500</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>      <td>female</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>PC 17599</td>      <td>71.2833</td>      <td>C85</td>      <td>C</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>3</td>      <td>Heikkinen, Miss. Laina</td>      <td>female</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>STON/O2. 3101282</td>      <td>7.9250</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>1</td>      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>      <td>female</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>113803</td>      <td>53.1000</td>      <td>C123</td>      <td>S</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>0</td>      <td>3</td>      <td>Allen, Mr. William Henry</td>      <td>male</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>373450</td>      <td>8.0500</td>      <td>NaN</td>      <td>S</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">titianic[<span class="string">'Age'</span>]=titianic[<span class="string">'Age'</span>].fillna(titianic[<span class="string">'Age'</span>].median())</span><br><span class="line">print(titianic.describe())</span><br></pre></td></tr></table></figure><pre><code>       PassengerId    Survived      Pclass         Age       SibSp  \count   891.000000  891.000000  891.000000  891.000000  891.000000   mean    446.000000    0.383838    2.308642   29.361582    0.523008   std     257.353842    0.486592    0.836071   13.019697    1.102743   min       1.000000    0.000000    1.000000    0.420000    0.000000   25%     223.500000    0.000000    2.000000   22.000000    0.000000   50%     446.000000    0.000000    3.000000   28.000000    0.000000   75%     668.500000    1.000000    3.000000   35.000000    1.000000   max     891.000000    1.000000    3.000000   80.000000    8.000000               Parch        Fare  count  891.000000  891.000000  mean     0.381594   32.204208  std      0.806057   49.693429  min      0.000000    0.000000  25%      0.000000    7.910400  50%      0.000000   14.454200  75%      0.000000   31.000000  max      6.000000  512.329200  </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">titianic[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Name</th>      <th>Sex</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Ticket</th>      <th>Fare</th>      <th>Cabin</th>      <th>Embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>0</td>      <td>3</td>      <td>Braund, Mr. Owen Harris</td>      <td>male</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>A/5 21171</td>      <td>7.2500</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>      <td>female</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>PC 17599</td>      <td>71.2833</td>      <td>C85</td>      <td>C</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>3</td>      <td>Heikkinen, Miss. Laina</td>      <td>female</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>STON/O2. 3101282</td>      <td>7.9250</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>1</td>      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>      <td>female</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>113803</td>      <td>53.1000</td>      <td>C123</td>      <td>S</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>0</td>      <td>3</td>      <td>Allen, Mr. William Henry</td>      <td>male</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>373450</td>      <td>8.0500</td>      <td>NaN</td>      <td>S</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(titianic[<span class="string">'Sex'</span>].unique())</span><br><span class="line">titianic[<span class="string">'Sex'</span>] = titianic[<span class="string">'Sex'</span>].map(&#123;<span class="string">'male'</span>:<span class="number">0</span>,<span class="string">'female'</span>:<span class="number">1</span>&#125;)</span><br><span class="line"><span class="comment"># 把male变成0，把female变成1</span></span><br><span class="line"><span class="comment"># titanic.loc[titanic["Sex"] == "male", "Sex"] = 0</span></span><br><span class="line"><span class="comment"># titanic.loc[titanic["Sex"] == "female", "Sex"] = 1</span></span><br></pre></td></tr></table></figure><pre><code>[&apos;male&apos; &apos;female&apos;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">titianic[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Name</th>      <th>Sex</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Ticket</th>      <th>Fare</th>      <th>Cabin</th>      <th>Embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>0</td>      <td>3</td>      <td>Braund, Mr. Owen Harris</td>      <td>0</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>A/5 21171</td>      <td>7.2500</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>      <td>1</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>PC 17599</td>      <td>71.2833</td>      <td>C85</td>      <td>C</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>3</td>      <td>Heikkinen, Miss. Laina</td>      <td>1</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>STON/O2. 3101282</td>      <td>7.9250</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>1</td>      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>      <td>1</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>113803</td>      <td>53.1000</td>      <td>C123</td>      <td>S</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>0</td>      <td>3</td>      <td>Allen, Mr. William Henry</td>      <td>0</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>373450</td>      <td>8.0500</td>      <td>NaN</td>      <td>S</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(titianic[<span class="string">'Embarked'</span>].unique())</span><br><span class="line">titianic[<span class="string">'Embarked'</span>]=titianic[<span class="string">'Embarked'</span>].fillna(<span class="string">'S'</span>)</span><br><span class="line">titianic[<span class="string">'Embarked'</span>]=titianic[<span class="string">'Embarked'</span>].map(&#123;<span class="string">'S'</span>:<span class="number">0</span>,<span class="string">'C'</span>:<span class="number">1</span>,<span class="string">'Q'</span>:<span class="number">2</span>&#125;)</span><br><span class="line">titianic[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><pre><code>[&apos;S&apos; &apos;C&apos; &apos;Q&apos; nan]</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Name</th>      <th>Sex</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Ticket</th>      <th>Fare</th>      <th>Cabin</th>      <th>Embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>0</td>      <td>3</td>      <td>Braund, Mr. Owen Harris</td>      <td>0</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>A/5 21171</td>      <td>7.2500</td>      <td>NaN</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>      <td>1</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>PC 17599</td>      <td>71.2833</td>      <td>C85</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>3</td>      <td>Heikkinen, Miss. Laina</td>      <td>1</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>STON/O2. 3101282</td>      <td>7.9250</td>      <td>NaN</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>1</td>      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>      <td>1</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>113803</td>      <td>53.1000</td>      <td>C123</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>0</td>      <td>3</td>      <td>Allen, Mr. William Henry</td>      <td>0</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>373450</td>      <td>8.0500</td>      <td>NaN</td>      <td>0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">predictors = [<span class="string">'Pclass'</span>,<span class="string">'Sex'</span>,<span class="string">'Age'</span>,<span class="string">'SibSp'</span>,<span class="string">'Parch'</span>,<span class="string">'Fare'</span>,<span class="string">'Embarked'</span>]</span><br><span class="line">x_data = titianic[predictors]</span><br><span class="line">y_data = titianic[<span class="string">'Survived'</span>]</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">x_data = scaler.fit_transform(x_data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">LR = LogisticRegression()</span><br><span class="line">scores = model_selection.cross_val_score(LR,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.7901234567901234</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">20</span>,<span class="number">10</span>),max_iter=<span class="number">1000</span>)</span><br><span class="line">scores = model_selection.cross_val_score(mlp,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)0.8002244668911335</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line">knn = neighbors.KNeighborsClassifier(<span class="number">21</span>)</span><br><span class="line">scores=model_selection.cross_val_score(knn,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.8125701459034792</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">dtree = tree.DecisionTreeClassifier(max_depth=<span class="number">5</span>,min_samples_split=<span class="number">4</span>)</span><br><span class="line">scores = model_selection.cross_val_score(dtree,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.8080808080808081</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">RF1 = RandomForestClassifier(random_state=<span class="number">1</span>,n_estimators=<span class="number">10</span>,min_samples_split=<span class="number">2</span>)</span><br><span class="line">scores = model_selection.cross_val_score(RF1,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.7991021324354657</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RF2 = RandomForestClassifier(n_estimators=<span class="number">100</span>,min_samples_split=<span class="number">4</span>)</span><br><span class="line">scores = model_selection.cross_val_score(RF2,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.8125701459034792</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line">bagging_clf = BaggingClassifier(RF2,n_estimators=<span class="number">20</span>)</span><br><span class="line">scores=model_selection.cross_val_score(bagging_clf,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.819304152637486</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">adaboost = AdaBoostClassifier(bagging_clf,n_estimators=<span class="number">10</span>)</span><br><span class="line">scores=model_selection.cross_val_score(adaboost,x_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>0.8181818181818182</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"><span class="keyword">from</span> mlxtend.classifier <span class="keyword">import</span> StackingClassifier</span><br><span class="line">sclf = StackingClassifier(classifiers=[bagging_clf,mlp,LR],</span><br><span class="line">                         meta_classifier=LogisticRegression())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scores = model_selection.cross_val_score(sclf,x_data,y_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)0.819304152637486</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sclf2 = VotingClassifier([(<span class="string">'adaboost'</span>,adaboost),(<span class="string">'mlp'</span>,mlp),(<span class="string">'LR'</span>,LR),(<span class="string">'knn'</span>,knn),(<span class="string">'dtree'</span>,dtree)])</span><br><span class="line"></span><br><span class="line">scores = model_selection.cross_val_score(sclf2,x_data,y_data,y_data,cv=<span class="number">3</span>)</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><pre><code>c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&apos;t converged yet.  % self.max_iter, ConvergenceWarning)0.8159371492704826</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据集:&lt;a href=&quot;http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/titanic_train.csv&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;titanic_train.csv&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习实战" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>opencv中的图像处理5</title>
    <link href="http://yoursite.com/2020/07/14/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%865/"/>
    <id>http://yoursite.com/2020/07/14/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%865/</id>
    <published>2020-07-14T04:03:19.000Z</published>
    <updated>2020-07-14T04:09:17.202Z</updated>
    
    <content type="html"><![CDATA[<ul><li>11.<a href="#header1">傅里叶变换</a></li><li>12.<a href="#header2">模板匹配</a></li><li>13.<a href="#header3">霍夫线变换</a></li><li>14.<a href="#header4">霍夫圈变换</a></li><li>15.<a href="#header5">图像分割与Watershed算法</a></li><li>16.<a href="#header6">交互式前景提取使用GrabCut算法</a><a id="more"></a></li></ul><h1 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a><span id="header1">傅里叶变换</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>在本节中，我们将学习 </p><ul><li>使用OpenCV查找图像的傅立叶变换 </li><li>利用Numpy中可用的FFT函数 </li><li>傅立叶变换的某些应用程序 </li><li>我们将看到以下函数：cv.dft()，cv.idft()等</li></ul><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>傅立叶变换用于分析各种滤波器的频率特性。</p><p>对于图像，使用<strong>2D离散傅里叶变换</strong>(DFT)查找频域。</p><p>一种称为<strong>快速傅立叶变换</strong>(FFT)的快速算法用于DFT的计算。</p><p>关于这些的详细信息可以在任何图像处理或信号处理教科书中找到。请参阅其他资源部分。</p><p>对于正弦信号x(t)=Asin(2πft)，我们可以说f是信号的频率，如果采用其频域，则可以看到f的尖峰。</p><p>如果对信号进行采样以形成离散信号，我们将获得相同的频域，但是在[−π，π]或[0,2π]范围内（对于N点DFT为[0，N]）是周期性的。</p><p>您可以将图像视为在两个方向上采样的信号。因此，在X和Y方向都进行傅立叶变换，可以得到图像的频率表示。</p><p>更直观地说，对于正弦信号，如果幅度在短时间内变化如此之快，则可以说它是高频信号。</p><p>如果变化缓慢，则为低频信号。您可以将相同的想法扩展到图像。</p><p>图像中的振幅在哪里急剧变化？在边缘点或噪声。因此，可以说边缘和噪声是图像中的高频内容。</p><p>如果幅度没有太大变化，则它是低频分量。（一些链接已添加到“其他资源”，其中通过示例直观地说明了频率变换）。</p><p>现在，我们将看到如何找到傅立叶变换。</p><h2 id="Numpy中的傅里叶变换"><a href="#Numpy中的傅里叶变换" class="headerlink" title="Numpy中的傅里叶变换"></a>Numpy中的傅里叶变换</h2><p>首先，我们将看到如何使用Numpy查找傅立叶变换。</p><p>Numpy具有FFT软件包来执行此操作。np.fft.fft2()为我们提供了频率转换，它将是一个复杂的数组。</p><ul><li>它的第一个参数是输入图像，即灰度图像。</li><li>第二个参数是可选的，它决定输出数组的大小。如果它大于输入图像的大小，则在计算FFT之前用零填充输入图像。如果小于输入图像，将裁切输入图像。如果未传递任何参数，则输出数组的大小将与输入的大小相同。</li></ul><p>现在，一旦获得结果，零频率分量（DC分量）将位于左上角。</p><p>如果要使其居中，则需要在两个方向上将结果都移动N2。</p><p>只需通过函数<strong>np.fft.fftshift</strong>()即可完成。（它更容易分析）。找到频率变换后，就可以找到幅度谱。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;messi5.jpg&#39;,0)</span><br><span class="line">f &#x3D; np.fft.fft2(img)</span><br><span class="line">fshift &#x3D; np.fft.fftshift(f)</span><br><span class="line">magnitude_spectrum &#x3D; 20*np.log(np.abs(fshift))</span><br><span class="line">plt.subplot(121),plt.imshow(img, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Input Image&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(122),plt.imshow(magnitude_spectrum, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Magnitude Spectrum&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>Result look like below:<br>结果看起来像下面这样:<br><img src="http://qiniu.aihubs.net/fft1.jpg" alt></p><p>看，您可以在中心看到更多白色区域，这表明低频内容更多。</p><p>因此，您发现了频率变换现在，您可以在频域中进行一些操作，例如高通滤波和重建图像，即找到逆DFT。</p><p>为此，您只需用尺寸为60x60的矩形窗口遮罩即可消除低频。</p><p>然后，使用<strong>np.fft.ifftshift</strong>()应用反向移位，以使DC分量再次出现在左上角。</p><p>然后使用<strong>np.ifft2</strong>()函数找到逆FFT。同样，结果将是一个复数。您可以采用其绝对值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rows, cols &#x3D; img.shape</span><br><span class="line">crow,ccol &#x3D; rows&#x2F;&#x2F;2 , cols&#x2F;&#x2F;2</span><br><span class="line">fshift[crow-30:crow+31, ccol-30:ccol+31] &#x3D; 0</span><br><span class="line">f_ishift &#x3D; np.fft.ifftshift(fshift)</span><br><span class="line">img_back &#x3D; np.fft.ifft2(f_ishift)</span><br><span class="line">img_back &#x3D; np.real(img_back)</span><br><span class="line">plt.subplot(131),plt.imshow(img, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Input Image&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(132),plt.imshow(img_back, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Image after HPF&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(133),plt.imshow(img_back)</span><br><span class="line">plt.title(&#39;Result in JET&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果看起来像下面这样：<br><img src="http://qiniu.aihubs.net/fft2.jpg" alt></p><p>结果表明高通滤波是边缘检测操作。</p><p>这就是我们在“图像渐变”一章中看到的。</p><p>这也表明大多数图像数据都存在于频谱的低频区域。</p><p>无论如何，我们已经看到了如何在Numpy中找到DFT，IDFT等。</p><p>现在，让我们看看如何在OpenCV中进行操作。 </p><p>如果您仔细观察结果，尤其是最后一张JET颜色的图像，您会看到一些伪像（我用红色箭头标记的一个实例）。</p><p>它在那里显示出一些波纹状结构，称为<strong>振铃效应</strong>。</p><p>这是由我们用于遮罩的矩形窗口引起的。此掩码转换为正弦形状，从而导致此问题。</p><p>因此，矩形窗口不用于过滤。更好的选择是高斯窗口。</p><h2 id="OpenCV中的傅里叶变换"><a href="#OpenCV中的傅里叶变换" class="headerlink" title="OpenCV中的傅里叶变换"></a>OpenCV中的傅里叶变换</h2><p>OpenCV为此提供了<strong>cv.dft</strong>()和<strong>cv.idft</strong>()函数。它返回与前一个相同的结果，但是有两个通道。</p><p>第一个通道是结果的实部，第二个通道是结果的虚部。输入图像首先应转换为np.float32。我们来看看怎么做。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;messi5.jpg&#39;,0)</span><br><span class="line">dft &#x3D; cv.dft(np.float32(img),flags &#x3D; cv.DFT_COMPLEX_OUTPUT)</span><br><span class="line">dft_shift &#x3D; np.fft.fftshift(dft)</span><br><span class="line">magnitude_spectrum &#x3D; 20*np.log(cv.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))</span><br><span class="line">plt.subplot(121),plt.imshow(img, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Input Image&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(122),plt.imshow(magnitude_spectrum, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Magnitude Spectrum&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>注意 您还可以使用<strong>cv.cartToPolar</strong>()，它在单个镜头中同时返回幅值和相位</p><p>现在我们要做DFT的逆变换。在上一节中，我们创建了一个HPF，这次我们将看到如何删除图像中的高频内容，即我们将LPF应用到图像中。</p><p>它实际上模糊了图像。为此，我们首先创建一个高值(1)在低频部分，即我们过滤低频内容，0在高频区。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">rows, cols &#x3D; img.shape</span><br><span class="line">crow,ccol &#x3D; rows&#x2F;2 , cols&#x2F;2</span><br><span class="line"># 首先创建一个掩码，中心正方形为1，其余全为零</span><br><span class="line">mask &#x3D; np.zeros((rows,cols,2),np.uint8)</span><br><span class="line">mask[crow-30:crow+30, ccol-30:ccol+30] &#x3D; 1</span><br><span class="line"># 应用掩码和逆DFT</span><br><span class="line">fshift &#x3D; dft_shift*mask</span><br><span class="line">f_ishift &#x3D; np.fft.ifftshift(fshift)</span><br><span class="line">img_back &#x3D; cv.idft(f_ishift)</span><br><span class="line">img_back &#x3D; cv.magnitude(img_back[:,:,0],img_back[:,:,1])</span><br><span class="line">plt.subplot(121),plt.imshow(img, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Input Image&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(122),plt.imshow(img_back, cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">plt.title(&#39;Magnitude Spectrum&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/fft4.jpg" alt></p><p>注意 通常，OpenCV函数<strong>cv.dft</strong>()和<strong>cv.idft</strong>()比Numpy函数更快。但是Numpy函数更容易使用。有关性能问题的更多细节，请参见下面的部分。</p><h2 id="DFT的性能优化"><a href="#DFT的性能优化" class="headerlink" title="DFT的性能优化"></a>DFT的性能优化</h2><p>对于某些数组尺寸，DFT的计算性能较好。当数组大小为2的幂时，速度最快。</p><p>对于大小为2、3和5的乘积的数组，也可以非常有效地进行处理。</p><p>因此，如果您担心代码的性能，可以在找到DFT之前将数组的大小修改为任何最佳大小(通过填充零)。对</p><p>于OpenCV，您必须手动填充零。但是对于Numpy，您指定FFT计算的新大小，它将自动为您填充零。</p><p>那么如何找到最优的大小呢?OpenCV为此提供了一个函数，cv.getOptimalDFTSize()。它同时适用于<strong>cv.dft</strong>()和<strong>np.fft.fft2</strong>()。让我们使用IPython魔术命令timeit来检查它们的性能。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [16]: img &#x3D; cv.imread(&#39;messi5.jpg&#39;,0)</span><br><span class="line">In [17]: rows,cols &#x3D; img.shape</span><br><span class="line">In [18]: print(&quot;&#123;&#125; &#123;&#125;&quot;.format(rows,cols))</span><br><span class="line">342 548</span><br><span class="line">In [19]: nrows &#x3D; cv.getOptimalDFTSize(rows)</span><br><span class="line">In [20]: ncols &#x3D; cv.getOptimalDFTSize(cols)</span><br><span class="line">In [21]: print(&quot;&#123;&#125; &#123;&#125;&quot;.format(nrows,ncols))</span><br><span class="line">360 576</span><br></pre></td></tr></table></figure><p>参见，将大小(342,548)修改为(360，576)。现在让我们用零填充（对于OpenCV），并找到其DFT计算性能。您可以通过创建一个新的零数组并将数据复制到其中来完成此操作，或者使用<strong>cv.copyMakeBorder</strong>()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nimg &#x3D; np.zeros((nrows,ncols))</span><br><span class="line">nimg[:rows,:cols] &#x3D; img</span><br></pre></td></tr></table></figure><p>或者:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">right &#x3D; ncols - cols</span><br><span class="line">bottom &#x3D; nrows - rows</span><br><span class="line">bordertype &#x3D; cv.BORDER_CONSTANT ＃只是为了避免PDF文件中的行中断</span><br><span class="line">nimg &#x3D; cv.copyMakeBorder(img,0,bottom,0,right,bordertype, value &#x3D; 0)</span><br></pre></td></tr></table></figure><p>现在，我们计算Numpy函数的DFT性能比较：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [22]: %timeit fft1 &#x3D; np.fft.fft2(img)</span><br><span class="line">10 loops, best of 3: 40.9 ms per loop</span><br><span class="line">In [23]: %timeit fft2 &#x3D; np.fft.fft2(img,[nrows,ncols])</span><br><span class="line">100 loops, best of 3: 10.4 ms per loop</span><br></pre></td></tr></table></figure><p>它显示了4倍的加速。现在，我们将尝试使用OpenCV函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [24]: %timeit dft1&#x3D; cv.dft(np.float32(img),flags&#x3D;cv.DFT_COMPLEX_OUTPUT)</span><br><span class="line">100 loops, best of 3: 13.5 ms per loop</span><br><span class="line">In [27]: %timeit dft2&#x3D; cv.dft(np.float32(nimg),flags&#x3D;cv.DFT_COMPLEX_OUTPUT)</span><br><span class="line">100 loops, best of 3: 3.11 ms per loop</span><br></pre></td></tr></table></figure><p>它还显示了4倍的加速。您还可以看到OpenCV函数比Numpy函数快3倍左右。也可以对逆FFT进行测试，这留给您练习。</p><h2 id="为什么拉普拉斯算子是高通滤波器？"><a href="#为什么拉普拉斯算子是高通滤波器？" class="headerlink" title="为什么拉普拉斯算子是高通滤波器？"></a>为什么拉普拉斯算子是高通滤波器？</h2><p>在一个论坛上也有人提出了类似的问题。问题是，为什么拉普拉斯变换是高通滤波器?</p><p>为什么Sobel是HPF?等。第一个答案是关于傅里叶变换的。对于更大的FFT只需要拉普拉斯变换。分析下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"># 没有缩放参数的简单均值滤波器</span><br><span class="line">mean_filter &#x3D; np.ones((3,3))</span><br><span class="line"># 创建高斯滤波器</span><br><span class="line">x &#x3D; cv.getGaussianKernel(5,10)</span><br><span class="line">gaussian &#x3D; x*x.T</span><br><span class="line"># 不同的边缘检测滤波器</span><br><span class="line"># x方向上的scharr</span><br><span class="line">scharr &#x3D; np.array([[-3, 0, 3],</span><br><span class="line">                   [-10,0,10],</span><br><span class="line">                   [-3, 0, 3]])</span><br><span class="line"># x方向上的sobel</span><br><span class="line">sobel_x&#x3D; np.array([[-1, 0, 1],</span><br><span class="line">                   [-2, 0, 2],</span><br><span class="line">                   [-1, 0, 1]])</span><br><span class="line"># y方向上的sobel</span><br><span class="line">sobel_y&#x3D; np.array([[-1,-2,-1],</span><br><span class="line">                   [0, 0, 0],</span><br><span class="line">                   [1, 2, 1]])</span><br><span class="line"># 拉普拉斯变换</span><br><span class="line">laplacian&#x3D;np.array([[0, 1, 0],</span><br><span class="line">                    [1,-4, 1],</span><br><span class="line">                    [0, 1, 0]])</span><br><span class="line">filters &#x3D; [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]</span><br><span class="line">filter_name &#x3D; [&#39;mean_filter&#39;, &#39;gaussian&#39;,&#39;laplacian&#39;, &#39;sobel_x&#39;, \</span><br><span class="line">                &#39;sobel_y&#39;, &#39;scharr_x&#39;]</span><br><span class="line">fft_filters &#x3D; [np.fft.fft2(x) for x in filters]</span><br><span class="line">fft_shift &#x3D; [np.fft.fftshift(y) for y in fft_filters]</span><br><span class="line">mag_spectrum &#x3D; [np.log(np.abs(z)+1) for z in fft_shift]</span><br><span class="line">for i in range(6):</span><br><span class="line">    plt.subplot(2,3,i+1),plt.imshow(mag_spectrum[i],cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>看看结果：<br><img src="http://qiniu.aihubs.net/fft5.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="模板匹配"><a href="#模板匹配" class="headerlink" title="模板匹配"></a><span id="header2">模板匹配</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>在本章中，您将学习 - 使用模板匹配在图像中查找对象 - 你将看到以下功能：cv.matchTemplate()，cv.minMaxLoc()</p><h2 id="理论-1"><a href="#理论-1" class="headerlink" title="理论"></a>理论</h2><p>模板匹配是一种用于在较大图像中搜索和查找模板图像位置的方法。</p><p>为此，OpenCV带有一个函数<strong>cv.matchTemplate</strong>()。 </p><p>它只是将模板图​​像滑动到输入图像上（就像在2D卷积中一样），然后在模板图像下比较模板和输入图像的拼图。 </p><p>OpenCV中实现了几种比较方法。（您可以检查文档以了解更多详细信息）。它返回一个灰度图像，其中每个像素表示该像素的邻域与模板匹配的程度。</p><p>如果输入图像的大小为(WxH)，而模板图像的大小为(wxh)，则输出图像的大小将为(W-w + 1，H-h + 1)。得到结果后，可以使用<strong>cv.minMaxLoc</strong>()函数查找最大/最小值在哪。将其作为矩形的左上角，并以(w，h)作为矩形的宽度和高度。该矩形是您模板的区域。</p><p>注意 如果使用<strong>cv.TM_SQDIFF</strong>作为比较方法，则最小值提供最佳匹配。</p><h2 id="OpenCV中的模板匹配"><a href="#OpenCV中的模板匹配" class="headerlink" title="OpenCV中的模板匹配"></a>OpenCV中的模板匹配</h2><p>作为示例，我们将在梅西的照片中搜索他的脸。所以我创建了一个模板，如下所示： <img src="http://qiniu.aihubs.net/messi_face.jpg" alt> 我们将尝试所有比较方法，以便我们可以看到它们的结果如何：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;messi5.jpg&#39;,0)</span><br><span class="line">img2 &#x3D; img.copy()</span><br><span class="line">template &#x3D; cv.imread(&#39;template.jpg&#39;,0)</span><br><span class="line">w, h &#x3D; template.shape[::-1]</span><br><span class="line"># 列表中所有的6种比较方法</span><br><span class="line">methods &#x3D; [&#39;cv.TM_CCOEFF&#39;, &#39;cv.TM_CCOEFF_NORMED&#39;, &#39;cv.TM_CCORR&#39;,</span><br><span class="line">            &#39;cv.TM_CCORR_NORMED&#39;, &#39;cv.TM_SQDIFF&#39;, &#39;cv.TM_SQDIFF_NORMED&#39;]</span><br><span class="line">for meth in methods:</span><br><span class="line">    img &#x3D; img2.copy()</span><br><span class="line">    method &#x3D; eval(meth)</span><br><span class="line">    # 应用模板匹配</span><br><span class="line">    res &#x3D; cv.matchTemplate(img,template,method)</span><br><span class="line">    min_val, max_val, min_loc, max_loc &#x3D; cv.minMaxLoc(res)</span><br><span class="line">    # 如果方法是TM_SQDIFF或TM_SQDIFF_NORMED，则取最小值</span><br><span class="line">    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:</span><br><span class="line">        top_left &#x3D; min_loc</span><br><span class="line">    else:</span><br><span class="line">        top_left &#x3D; max_loc</span><br><span class="line">    bottom_right &#x3D; (top_left[0] + w, top_left[1] + h)</span><br><span class="line">    cv.rectangle(img,top_left, bottom_right, 255, 2)</span><br><span class="line">    plt.subplot(121),plt.imshow(res,cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">    plt.title(&#39;Matching Result&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.subplot(122),plt.imshow(img,cmap &#x3D; &#39;gray&#39;)</span><br><span class="line">    plt.title(&#39;Detected Point&#39;), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.suptitle(meth)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>查看以下结果：</p><ul><li>cv.TM_CCOEFF<img src="http://qiniu.aihubs.net/template_ccoeff_1.jpg" alt></li><li>cv.TM_CCOEFF_NORMED<img src="http://qiniu.aihubs.net/template_ccoeffn_2.jpg" alt></li><li>cv.TM_CCORR<img src="http://qiniu.aihubs.net/template_ccorr_3.jpg" alt></li><li>cv.TM_CCORR_NORMED<img src="http://qiniu.aihubs.net/template_ccorrn_4.jpg" alt></li><li>cv.TM_SQDIFF<img src="http://qiniu.aihubs.net/template_sqdiff_5.jpg" alt></li><li>cv.TM_SQDIFF_NORMED<img src="http://qiniu.aihubs.net/template_sqdiffn_6.jpg" alt><br>使用<strong>cv.TM_CCORR</strong>的结果并不理想。</li></ul><h2 id="多对象的模板匹配"><a href="#多对象的模板匹配" class="headerlink" title="多对象的模板匹配"></a>多对象的模板匹配</h2><p>在上一节中，我们在图像中搜索了梅西的脸，该脸在图像中仅出现一次。</p><p>假设您正在搜索具有多次出现的对象，则<strong>cv.minMaxLoc</strong>()不会为您提供所有位置。</p><p>在这种情况下，我们将使用阈值化。因此，在此示例中，我们将使用著名游戏<strong>Mario</strong>的屏幕截图，并在其中找到硬币。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img_rgb &#x3D; cv.imread(&#39;mario.png&#39;)</span><br><span class="line">img_gray &#x3D; cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)</span><br><span class="line">template &#x3D; cv.imread(&#39;mario_coin.png&#39;,0)</span><br><span class="line">w, h &#x3D; template.shape[::-1]</span><br><span class="line">res &#x3D; cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)</span><br><span class="line">threshold &#x3D; 0.8</span><br><span class="line">loc &#x3D; np.where( res &gt;&#x3D; threshold)</span><br><span class="line">for pt in zip(*loc[::-1]):</span><br><span class="line">    cv.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)</span><br><span class="line">cv.imwrite(&#39;res.png&#39;,img_rgb)</span><br></pre></td></tr></table></figure><p>结果:<br><img src="http://qiniu.aihubs.net/res_mario.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="霍夫线变换"><a href="#霍夫线变换" class="headerlink" title="霍夫线变换"></a><span id="header3">霍夫线变换</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><p>在这一章当中， </p><ul><li>我们将了解霍夫变换的概念。 </li><li>我们将看到如何使用它来检测图像中的线条。 </li><li>我们将看到以下函数：cv.HoughLines()，cv.HoughLinesP()</li></ul><h2 id="理论-2"><a href="#理论-2" class="headerlink" title="理论"></a>理论</h2><p>如果可以用数学形式表示形状，则霍夫变换是一种检测任何形状的流行技术。</p><p>即使形状有些破损或变形，也可以检测出形状。我们将看到它如何作用于一条线。</p><p>一条线可以表示为y=mx+c或以参数形式表示为ρ=xcosθ+ysinθ，</p><p>其中ρ是从原点到该线的垂直距离，</p><p>而θ是由该垂直线和水平轴形成的角度以逆时针方向测量（该方向随您如何表示坐标系而变化。此表示形式在OpenCV中使用）。</p><p>查看下面的图片：<br><img src="http://qiniu.aihubs.net/1.png" alt></p><p>因此，如果线在原点下方通过，则它将具有正的ρ且角度小于180。如果线在原点上方，则将角度取为小于180，而不是大于180的角度。</p><p>ρ取负值。任何垂直线将具有0度，水平线将具有90度。</p><p>现在，让我们看一下霍夫变换如何处理线条。任何一条线都可以用(ρ，θ)这两个术语表示。</p><p>因此，首先创建2D数组或累加器（以保存两个参数的值），并将其初始设置为0。</p><p>让行表示ρ，列表示θ。阵列的大小取决于所需的精度。假设您希望角度的精度为1度，则需要180列。</p><p>对于ρ，最大距离可能是图像的对角线长度。因此，以一个像素精度为准，行数可以是图像的对角线长度。</p><p>考虑一个100x100的图像，中间有一条水平线。</p><p>取直线的第一点。您知道它的(x，y)值。</p><p>现在在线性方程式中，将值θ= 0,1,2，….. 180放进去，然后检查得到ρ。</p><p>对于每对(ρ，θ)，在累加器中对应的(ρ，θ)单元格将值增加1。所以现在在累加器中，单元格(50,90)= 1以及其他一些单元格。</p><p>现在，对行的第二个点。执行与上述相同的操作。递增(ρ，θ)对应的单元格中的值。</p><p>这次，单元格(50,90)=2。实际上，您正在对(ρ，θ)值进行投票。</p><p>您对线路上的每个点都继续执行此过程。</p><p>在每个点上，单元格(50,90)都会增加或投票，而其他单元格可能会或可能不会投票。</p><p>这样一来，最后，单元格(50,90)的投票数将最高。</p><p>因此，如果您在累加器中搜索最大票数，则将获得(50,90)值，该值表示该图像中的一条线与原点的距离为50，角度为90度。</p><p>在下面的动画中很好地显示了该图片(图片提供：Amos Storkey)<br><img src="http://qiniu.aihubs.net/houghlinesdemo.gif" alt></p><p>这就是霍夫变换对线条的工作方式。它很简单，也许您可​​以自己使用Numpy来实现它。</p><p>下图显示了累加器。某些位置的亮点表示它们是图像中可能的线条的参数。</p><p><img src="http://qiniu.aihubs.net/houghlines2.jpg" alt></p><h2 id="OpenCV中的霍夫曼变换"><a href="#OpenCV中的霍夫曼变换" class="headerlink" title="OpenCV中的霍夫曼变换"></a>OpenCV中的霍夫曼变换</h2><p>上面说明的所有内容都封装在OpenCV函数<strong>cv.HoughLines</strong>()中。</p><p>它只是返回一个：math:(rho，theta)值的数组。ρ以像素为单位，θ以弧度为单位。</p><p>第一个参数，输入图像应该是二进制图像，因此在应用霍夫变换之前，请应用阈值或使用Canny边缘检测。</p><p>第二和第三参数分别是ρ和θ精度。</p><p>第四个参数是阈值，这意味着应该将其视为行的最低投票。</p><p>请记住，票数取决于线上的点数。因此，它表示应检测到的最小线长。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">img &#x3D; cv.imread(cv.samples.findFile(&#39;sudoku.png&#39;))</span><br><span class="line">gray &#x3D; cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">edges &#x3D; cv.Canny(gray,50,150,apertureSize &#x3D; 3)</span><br><span class="line">lines &#x3D; cv.HoughLines(edges,1,np.pi&#x2F;180,200)</span><br><span class="line">for line in lines:</span><br><span class="line">    rho,theta &#x3D; line[0]</span><br><span class="line">    a &#x3D; np.cos(theta)</span><br><span class="line">    b &#x3D; np.sin(theta)</span><br><span class="line">    x0 &#x3D; a*rho</span><br><span class="line">    y0 &#x3D; b*rho</span><br><span class="line">    x1 &#x3D; int(x0 + 1000*(-b))</span><br><span class="line">    y1 &#x3D; int(y0 + 1000*(a))</span><br><span class="line">    x2 &#x3D; int(x0 - 1000*(-b))</span><br><span class="line">    y2 &#x3D; int(y0 - 1000*(a))</span><br><span class="line">    cv.line(img,(x1,y1),(x2,y2),(0,0,255),2)</span><br><span class="line">cv.imwrite(&#39;houghlines3.jpg&#39;,img)</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/houghlines3.jpg" alt></p><h2 id="概率霍夫变换"><a href="#概率霍夫变换" class="headerlink" title="概率霍夫变换"></a>概率霍夫变换</h2><p>在霍夫变换中，您可以看到，即使对于带有两个参数的行，也需要大量计算。</p><p>概率霍夫变换是我们看到的霍夫变换的优化。它没有考虑所有要点。</p><p>取而代之的是，它仅采用随机的点子集，足以进行线检测。</p><p>只是我们必须降低阈值。参见下图，比较了霍夫空间中的霍夫变换和概率霍夫变换。<br><img src="http://qiniu.aihubs.net/houghlines4.png" alt></p><p>OpenCV的实现基于Matas,J.和Galambos,C.和Kittler, J.V.使用渐进概率霍夫变换对行进行的稳健检测[145]。</p><p>使用的函数是<strong>cv.HoughLinesP</strong>()。它有两个新的论点。 </p><ul><li>minLineLength - 最小行长。小于此长度的线段将被拒绝。 </li><li>maxLineGap - 线段之间允许将它们视为一条线的最大间隙。</li></ul><p>最好的是，它直接返回行的两个端点。在以前的情况下，您仅获得线的参数，并且必须找到所有点。在这里，一切都是直接而简单的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">img &#x3D; cv.imread(cv.samples.findFile(&#39;sudoku.png&#39;))</span><br><span class="line">gray &#x3D; cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">edges &#x3D; cv.Canny(gray,50,150,apertureSize &#x3D; 3)</span><br><span class="line">lines &#x3D; cv.HoughLinesP(edges,1,np.pi&#x2F;180,100,minLineLength&#x3D;100,maxLineGap&#x3D;10)</span><br><span class="line">for line in lines:</span><br><span class="line">    x1,y1,x2,y2 &#x3D; line[0]</span><br><span class="line">    cv.line(img,(x1,y1),(x2,y2),(0,255,0),2)</span><br><span class="line">cv.imwrite(&#39;houghlines5.jpg&#39;,img)</span><br></pre></td></tr></table></figure><p>看到如下结果：<br><img src="http://qiniu.aihubs.net/houghlines5.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="霍夫圈变换"><a href="#霍夫圈变换" class="headerlink" title="霍夫圈变换"></a><span id="header4">霍夫圈变换</span></h1><h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><p>在本章中， </p><ul><li>我们将学习使用霍夫变换来查找图像中的圆。 </li><li>我们将看到以下函数：cv.HoughCircles()</li></ul><p>理论<br>圆在数学上表示为$(x−x_{center})^2+(y−y_{center})^2=r^2$，其中$(x_{center},y_{center})$是圆的中心，r是圆的半径。从等式中，我们可以看到我们有3个参数，因此我们需要3D累加器进行霍夫变换，这将非常低效。因此，OpenCV使用更加技巧性的方法，即使用边缘的梯度信息的<strong>Hough梯度方法</strong>。</p><p>我们在这里使用的函数是<strong>cv.HoughCircles</strong>()。它有很多参数，这些参数在文档中有很好的解释。因此，我们直接转到代码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">img &#x3D; cv.imread(&#39;opencv-logo-white.png&#39;,0)</span><br><span class="line">img &#x3D; cv.medianBlur(img,5)</span><br><span class="line">cimg &#x3D; cv.cvtColor(img,cv.COLOR_GRAY2BGR)</span><br><span class="line">circles &#x3D; cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,</span><br><span class="line">                            param1&#x3D;50,param2&#x3D;30,minRadius&#x3D;0,maxRadius&#x3D;0)</span><br><span class="line">circles &#x3D; np.uint16(np.around(circles))</span><br><span class="line">for i in circles[0,:]:</span><br><span class="line">    # 绘制外圆</span><br><span class="line">    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)</span><br><span class="line">    # 绘制圆心</span><br><span class="line">    cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)</span><br><span class="line">cv.imshow(&#39;detected circles&#39;,cimg)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/houghcircles2.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="图像分割与Watershed算法"><a href="#图像分割与Watershed算法" class="headerlink" title="图像分割与Watershed算法"></a><span id="header5">图像分割与Watershed算法</span></h1><h2 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h2><p>在本章中， - 我们将学习使用分水岭算法实现基于标记的图像分割 - 我们将看到：cv.watershed()</p><h2 id="理论-3"><a href="#理论-3" class="headerlink" title="理论"></a>理论</h2><p>任何灰度图像都可以看作是一个地形表面，其中高强度表示山峰，低强度表示山谷。</p><p>你开始用不同颜色的水(标签)填充每个孤立的山谷(局部最小值)。</p><p>随着水位的上升，根据附近的山峰(坡度)，来自不同山谷的水明显会开始合并，颜色也不同。</p><p>为了避免这种情况，你要在水融合的地方建造屏障。你继续填满水，建造障碍，直到所有的山峰都在水下。</p><p>然后你创建的屏障将返回你的分割结果。这就是Watershed背后的“思想”。</p><p>你可以访问Watershed的CMM网页，了解它与一些动画的帮助。</p><p>但是这种方法会由于图像中的噪声或其他不规则性而产生过度分割的结果。</p><p>因此OpenCV实现了一个基于标记的分水岭算法，你可以指定哪些是要合并的山谷点，哪些不是。</p><p>这是一个交互式的图像分割。我们所做的是给我们知道的对象赋予不同的标签。</p><p>用一种颜色(或强度)标记我们确定为前景或对象的区域，用另一种颜色标记我们确定为背景或非对象的区域，最后用0标记我们不确定的区域。</p><p>这是我们的标记。然后应用分水岭算法。然后我们的标记将使用我们给出的标签进行更新，对象的边界值将为-1。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>下面我们将看到一个有关如何使用距离变换和分水岭来分割相互接触的对象的示例。</p><p>考虑下面的硬币图像，硬币彼此接触。即使你设置阈值，它也会彼此接触。<br><img src="http://qiniu.aihubs.net/water_coins.jpg" alt></p><p>我们先从寻找硬币的近似估计开始。因此，我们可以使用Otsu的二值化。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;coins.png&#39;)</span><br><span class="line">gray &#x3D; cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh &#x3D; cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/water_thresh.jpg" alt></p><p>现在我们需要去除图像中的任何白点噪声。为此，我们可以使用形态学扩张。</p><p>要去除对象中的任何小孔，我们可以使用形态学侵蚀。因此，现在我们可以确定，靠近对象中心的区域是前景，而离对象中心很远的区域是背景。</p><p>我们不确定的唯一区域是硬币的边界区域。</p><p>因此，我们需要提取我们可确定为硬币的区域。侵蚀会去除边界像素。</p><p>因此，无论剩余多少，我们都可以肯定它是硬币。如果物体彼此不接触，那将起作用。</p><p>但是，由于它们彼此接触，因此另一个好选择是找到距离变换并应用适当的阈值。</p><p>接下来，我们需要找到我们确定它们不是硬币的区域。</p><p>为此，我们扩张了结果。膨胀将对象边界增加到背景。</p><p>这样，由于边界区域已删除，因此我们可以确保结果中背景中的任何区域实际上都是背景。参见下图。<br><img src="http://qiniu.aihubs.net/water_fgbg.jpg" alt></p><p>剩下的区域是我们不知道的区域，无论是硬币还是背景。分水岭算法应该找到它。</p><p>这些区域通常位于前景和背景相遇（甚至两个不同的硬币相遇）的硬币边界附近。我们称之为边界。可以通过从sure_bg区域中减去sure_fg区域来获得。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 噪声去除</span><br><span class="line">kernel &#x3D; np.ones((3,3),np.uint8)</span><br><span class="line">opening &#x3D; cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations &#x3D; 2)</span><br><span class="line"># 确定背景区域</span><br><span class="line">sure_bg &#x3D; cv.dilate(opening,kernel,iterations&#x3D;3)</span><br><span class="line"># 寻找前景区域</span><br><span class="line">dist_transform &#x3D; cv.distanceTransform(opening,cv.DIST_L2,5)</span><br><span class="line">ret, sure_fg &#x3D; cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)</span><br><span class="line"># 找到未知区域</span><br><span class="line">sure_fg &#x3D; np.uint8(sure_fg)</span><br><span class="line">unknown &#x3D; cv.subtract(sure_bg,sure_fg)</span><br></pre></td></tr></table></figure><p>查看结果。在阈值图像中，我们得到了一些硬币区域，我们确定它们是硬币，并且现在已分离它们。（在某些情况下，你可能只对前景分割感兴趣，而不对分离相互接触的对象感兴趣。在那种情况下，你无需使用距离变换，只需侵蚀就足够了。侵蚀只是提取确定前景区域的另一种方法。）</p><p><img src="http://qiniu.aihubs.net/water_dt.jpg" alt></p><p>现在我们可以确定哪些是硬币的区域，哪些是背景。</p><p>因此，我们创建了标记（它的大小与原始图像的大小相同，但具有int32数据类型），并标记其中的区域。</p><p>我们肯定知道的区域（无论是前景还是背景）都标有任何正整数，但是带有不同的整数，而我们不确定的区域则保留为零。</p><p>为此，我们使用<strong>cv.connectedComponents</strong>()。它用0标记图像的背景，然后其他对象用从1开始的整数标记。</p><p>但是我们知道，如果背景标记为0，则分水岭会将其视为未知区域。所以我们想用不同的整数来标记它。相反，我们将未知定义的未知区域标记为0。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 类别标记</span><br><span class="line">ret, markers &#x3D; cv.connectedComponents(sure_fg)</span><br><span class="line"># 为所有的标记加1，保证背景是0而不是1</span><br><span class="line">markers &#x3D; markers+1</span><br><span class="line"># 现在让所有的未知区域为0</span><br><span class="line">markers[unknown&#x3D;&#x3D;255] &#x3D; 0</span><br></pre></td></tr></table></figure><p>参见JET colormap中显示的结果。深蓝色区域显示未知区域。当然,硬币的颜色不同。剩下,肯定为背景的区域显示在较浅的蓝色，跟未知区域相比。<br><img src="http://qiniu.aihubs.net/water_marker.jpg" alt></p><p>现在我们的标记已准备就绪。现在是最后一步的时候了，使用分水岭算法。然后标记图像将被修改。边界区域将标记为-1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">markers &#x3D; cv.watershed(img,markers) </span><br><span class="line">img[markers &#x3D;&#x3D; -1] &#x3D; [255,0,0]</span><br></pre></td></tr></table></figure><p>请参阅下面的结果。对某些硬币，它们接触的区域被正确地分割，而对于某些硬币，却不是。</p><p><img src="http://qiniu.aihubs.net/water_result.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="交互式前景提取使用GrabCut算法"><a href="#交互式前景提取使用GrabCut算法" class="headerlink" title="交互式前景提取使用GrabCut算法"></a><span id="header6">交互式前景提取使用GrabCut算法</span></h1><h2 id="目标-4"><a href="#目标-4" class="headerlink" title="目标"></a>目标</h2><p>在本章中， - 我们将看到GrabCut算法来提取图像中的前景 - 我们将为此创建一个交互式应用程序。</p><h2 id="理论-4"><a href="#理论-4" class="headerlink" title="理论"></a>理论</h2><p>GrabCut算法由英国微软研究院的Carsten Rother，Vladimir Kolmogorov和Andrew Blake设计。</p><p>在他们的论文“GrabCut”中：使用迭代图割的交互式前景提取。需要用最少的用户交互进行前景提取的算法，结果是GrabCut。</p><p>从用户角度来看，它是如何工作的？</p><p>最初，用户在前景区域周围绘制一个矩形（前景区域应完全位于矩形内部）。</p><p>然后，算法会对其进行迭代分割，以获得最佳结果。</p><p>做完了但在某些情况下，分割可能不会很好，例如，可能已将某些前景区域标记为背景，反之亦然。在这种情况下，需要用户进行精修。</p><p>只需在图像错误分割区域上画些笔画。笔画基本上说 “嘿，该区域应该是前景，你将其标记为背景，在下一次迭代中对其进行校正”或与背景相反。</p><p>然后在下一次迭代中，你将获得更好的结果。</p><p>参见下图。</p><p>第一名球员和橄榄球被封闭在一个蓝色矩形中。然后用白色笔划（表示前景）和黑色笔划（表示背景）进行最后的修饰。而且我们得到了不错的结果。</p><p><img src="http://qiniu.aihubs.net/grabcut_output1.jpg" alt></p><p>那么背景发生了什么呢？ </p><ul><li>用户输入矩形。此矩形外部的所有内容都将作为背景（这是在矩形应包含所有对象之前提到的原因）。矩形内的所有内容都是未知的。同样，任何指定前景和背景的用户输入都被视为硬标签，这意味着它们在此过程中不会更改。 </li><li>计算机根据我们提供的数据进行初始标记。它标记前景和背景像素（或对其进行硬标记），现在使用高斯混合模型(GMM)对前景和背景进行建模。 </li><li>根据我们提供的数据，GMM可以学习并创建新的像素分布。也就是说，未知像素根据颜色统计上与其他硬标记像素的关系而被标记为可能的前景或可能的背景（就像聚类一样）。 </li><li>根据此像素分布构建图形。图中的节点为像素。添加了另外两个节点，即“源”节点和“接收器”节点。每个前景像素都连接到源节点，每个背景像素都连接到接收器节点。 </li><li>通过像素是前景/背景的概率来定义将像素连接到源节点/末端节点的边缘的权重。像素之间的权重由边缘信息或像素相似度定义。如果像素颜色差异很大，则它们之间的边缘将变低。 </li><li>然后使用mincut算法对图进行分割。它将图切成具有最小成本函数的两个分离的源节点和宿节点。成本函数是被切割边缘的所有权重的总和。剪切后，连接到“源”节点的所有像素都变为前景，而连接到“接收器”节点的像素都变为背景。 </li><li>继续该过程，直到分类收敛为止。</li></ul><p>如下图所示（图片提供：<a href="http://www.cs.ru.ac.za/research/g02m1682/）" target="_blank" rel="noopener">http://www.cs.ru.ac.za/research/g02m1682/）</a><br><img src="http://qiniu.aihubs.net/grabcut_scheme.jpg" alt></p><p>示例<br>现在我们使用OpenCV进行抓取算法。OpenCV为此具有功能<strong>cv.grabCut</strong>()，我们将首先看到其参数： </p><ul><li>img - 输入图像 </li><li>mask - 这是一个掩码图像，在其中我们指定哪些区域是背景，前景或可能的背景/前景等。这是通过以下标志完成的：cv.GC_BGD,cv.GC_FGD, cv.GC_PR_BGD,cv.GC_PR_FGD，或直接将0,1,2,3传递给图像。 </li><li>rect - 它是矩形的坐标，其中包括前景对象，格式为(x,y,w,h) - bdgModel, fgdModel - 这些是算法内部使用的数组。你只需创建两个大小为(1,65)的np.float64类型零数组。 </li><li>iterCount - 算法应运行的迭代次数。 </li><li>model - 应该是<strong>cv.GC_INIT_WITH_RECT</strong>或<strong>cv.GC_INIT_WITH_MASK</strong>或两者结合，决定我们要绘制矩形还是最终的修饰笔触。</li></ul><p>首先让我们看看矩形模式。我们加载图像，创建类似的mask图像。 </p><p>我们创建<em>fgdModel</em>和<em>bgdModel</em>。我们给出矩形参数。一切都是直截了当的。</p><p>让算法运行5次迭代。模式应为<strong>cv.GC_INIT_WITH_RECT</strong>, 因为我们使用的是矩形。 </p><p>然后运行grabcut。修改mask图像。在新的mask图像中，像素将被标记有四个标记，分别表示上面指定的背景/前景。</p><p>因此，我们修改mask，使所有0像素和2像素都置为0（即背景），而所有1像素和3像素均置为1（即前景像素）。</p><p>现在，我们的最终mask已经准备就绪。只需将其与输入图像相乘即可得到分割的图像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;messi5.jpg&#39;)</span><br><span class="line">mask &#x3D; np.zeros(img.shape[:2],np.uint8)</span><br><span class="line">bgdModel &#x3D; np.zeros((1,65),np.float64)</span><br><span class="line">fgdModel &#x3D; np.zeros((1,65),np.float64)</span><br><span class="line">rect &#x3D; (50,50,450,290)</span><br><span class="line">cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)</span><br><span class="line">mask2 &#x3D; np.where((mask&#x3D;&#x3D;2)|(mask&#x3D;&#x3D;0),0,1).astype(&#39;uint8&#39;)</span><br><span class="line">img &#x3D; img*mask2[:,:,np.newaxis]</span><br><span class="line">plt.imshow(img),plt.colorbar(),plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/grabcut_rect.jpg" alt></p><p>糟糕，梅西的头发不见了。谁会喜欢没有头发的梅西？我们需要把它找回来。</p><p>因此，我们将使用1像素（确保前景）进行精细修饰。</p><p>同时，一些不需要的地面也出现在图片里。我们需要删除它们。</p><p>在那里，我们给出了一些0像素的修饰（确保背景）。</p><p>因此，如现在所说，我们在以前的情况下修改生成的mask。</p><p>我实际上所做的是，我在paint应用程序中打开了输入图像，并在图像中添加了另一层。</p><p>使用画笔中的画笔工具，我在新图层上用白色标记了错过的前景（头发，鞋子，球等），而用白色标记了不需要的背景（例如logo，地面等）。</p><p>然后用灰色填充剩余的背景。</p><p>然后将该mask图像加载到OpenCV中，编辑我们在新添加的mask图像中具有相应值的原始mask图像。</p><p>检查以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">＃newmask是我手动标记过的mask图像</span><br><span class="line">newmask &#x3D; cv.imread(&#39;newmask.png&#39;,0)</span><br><span class="line"># 标记为白色（确保前景）的地方，更改mask &#x3D; 1</span><br><span class="line"># 标记为黑色（确保背景）的地方，更改mask &#x3D; 0</span><br><span class="line">mask[newmask &#x3D;&#x3D; 0] &#x3D; 0</span><br><span class="line">mask[newmask &#x3D;&#x3D; 255] &#x3D; 1</span><br><span class="line">mask, bgdModel, fgdModel &#x3D; cv.grabCut(img,mask,None,bgdModel,fgdModel,5,cv.GC_INIT_WITH_MASK)</span><br><span class="line">mask &#x3D; np.where((mask&#x3D;&#x3D;2)|(mask&#x3D;&#x3D;0),0,1).astype(&#39;uint8&#39;)</span><br><span class="line">img &#x3D; img*mask[:,:,np.newaxis]</span><br><span class="line">plt.imshow(img),plt.colorbar(),plt.show()</span><br></pre></td></tr></table></figure><p>就是这样了。在这里，你无需直接在rect模式下初始化，而可以直接进入mask模式。</p><p>只需用2像素或3像素（可能的背景/前景）标记mask图像中的矩形区域。</p><p>然后像在第二个示例中一样，将我们的sure_foreground标记为1像素。然后直接在mask模式下应用grabCut功能。<br><img src="http://qiniu.aihubs.net/grabcut_mask.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;11.&lt;a href=&quot;#header1&quot;&gt;傅里叶变换&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;12.&lt;a href=&quot;#header2&quot;&gt;模板匹配&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;13.&lt;a href=&quot;#header3&quot;&gt;霍夫线变换&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;14.&lt;a href=&quot;#header4&quot;&gt;霍夫圈变换&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;15.&lt;a href=&quot;#header5&quot;&gt;图像分割与Watershed算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;16.&lt;a href=&quot;#header6&quot;&gt;交互式前景提取使用GrabCut算法&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv中的图像处理4-直方图</title>
    <link href="http://yoursite.com/2020/07/14/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%864-%E7%9B%B4%E6%96%B9%E5%9B%BE/"/>
    <id>http://yoursite.com/2020/07/14/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%864-%E7%9B%B4%E6%96%B9%E5%9B%BE/</id>
    <published>2020-07-14T02:45:13.000Z</published>
    <updated>2020-07-14T02:48:51.079Z</updated>
    
    <content type="html"><![CDATA[<ul><li>10.1.<a href="#header1">直方图-1：查找、绘制和分析</a></li><li>10.2.<a href="#header2">直方图-2：直方图均衡</a></li><li>10.3.<a href="#header3">直方图-3：二维直方图</a></li><li>10.4.<a href="#header4">直方图4：直方图反投影</a><a id="more"></a></li></ul><h1 id="直方图-1：查找、绘制和分析"><a href="#直方图-1：查找、绘制和分析" class="headerlink" title="直方图-1：查找、绘制和分析"></a><span id="header1">直方图-1：查找、绘制和分析</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>学会 </p><ul><li>使用OpenCV和Numpy函数查找直方图 </li><li>使用OpenCV和Matplotlib函数绘制直方图 </li><li>你将看到以下函数：cv.calcHist()，np.histogram()等。</li></ul><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>那么直方图是什么？您可以将直方图视为图形或绘图，从而可以总体了解图像的强度分布。</p><p>它是在X轴上具有像素值（不总是从0到255的范围），在Y轴上具有图像中相应像素数的图。</p><p>这只是理解图像的另一种方式。通过查看图像的直方图，您可以直观地了解该图像的对比度，亮度，强度分布等。</p><p>当今几乎所有图像处理工具都提供直方图功能。以下是剑桥彩色网站的图片，我建议您访问该网站以获取更多详细信息。</p><p><img src="http://qiniu.aihubs.net/histogram_sample.jpg" alt></p><p>您可以看到图像及其直方图。（请记住，此直方图是针对灰度图像而非彩色图像绘制的）。</p><p>直方图的左侧区域显示图像中较暗像素的数量，而右侧区域则显示明亮像素的数量。</p><p>从直方图中，您可以看到暗区域多于亮区域，而中间调的数量（中间值的像素值，例如127附近）则非常少。</p><h2 id="寻找直方图"><a href="#寻找直方图" class="headerlink" title="寻找直方图"></a>寻找直方图</h2><p>现在我们有了一个关于直方图的想法，我们可以研究如何找到它。OpenCV和Numpy都为此内置了功能。</p><p>在使用这些功能之前，我们需要了解一些与直方图有关的术语。</p><p>BINS：上面的直方图显示每个像素值的像素数，即从0到255。即，您需要256个值来显示上面的直方图。但是考虑一下，如果您不需要分别找到所有像素值的像素数，而是找到像素值间隔中的像素数怎么办？ 例如，您需要找到介于0到15之间的像素数，然后找到16到31之间，…，240到255之间的像素数。只需要16个值即可表示直方图。这就是在OpenCV教程中有关直方图的示例中显示的内容。</p><p>因此，您要做的就是将整个直方图分成16个子部分，每个子部分的值就是其中所有像素数的总和。 每个子部分都称为“ BIN”。在第一种情况下，bin的数量为256个（每个像素一个），而在第二种情况下，bin的数量仅为16个。BINS由OpenCV文档中的<strong>histSize</strong>术语表示。</p><p>DIMS：这是我们为其收集数据的参数的数量。在这种情况下，我们仅收集关于强度值的一件事的数据。所以这里是1。</p><p>RANGE：这是您要测量的强度值的范围。通常，它是[0,256]，即所有强度值。</p><h2 id="1-OpenCV中的直方图计算"><a href="#1-OpenCV中的直方图计算" class="headerlink" title="1. OpenCV中的直方图计算"></a>1. OpenCV中的直方图计算</h2><p>因此，现在我们使用<strong>cv.calcHist</strong>()函数查找直方图。让我们熟悉一下该函数及其参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cv.calcHist（images，channels，mask，histSize，ranges [，hist [，accumulate]]）</span><br><span class="line">images：它是uint8或float32类型的源图像。它应该放在方括号中，即“ [img]”。</span><br><span class="line">channels：也以方括号给出。它是我们计算直方图的通道的索引。例如，如果输入为灰度图像，则其值为[0]。对于彩色图像，您可以传递[0]，[1]或[2]分别计算蓝色，绿色或红色通道的直方图。</span><br><span class="line">mask：图像掩码。为了找到完整图像的直方图，将其指定为“无”。但是，如果要查找图像特定区域的直方图，则必须为此创建一个掩码图像并将其作为掩码。（我将在后面显示一个示例。）</span><br><span class="line">histSize：这表示我们的BIN计数。需要放在方括号中。对于全尺寸，我们通过[256]。</span><br><span class="line">ranges：这是我们的RANGE。通常为[0,256]。</span><br></pre></td></tr></table></figure><p>因此，让我们从示例图像开始。只需以灰度模式加载图像并找到其完整直方图即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;,0)</span><br><span class="line">hist &#x3D; cv.calcHist([img],[0],None,[256],[0,256])</span><br></pre></td></tr></table></figure><p>hist是256x1的数组，每个值对应于该图像中具有相应像素值的像素数。</p><h2 id="2-numpy的直方图计算"><a href="#2-numpy的直方图计算" class="headerlink" title="2. numpy的直方图计算"></a>2. numpy的直方图计算</h2><p>Numpy还为您提供了一个函数<strong>np.histogram</strong>()。因此，除了<strong>calcHist</strong>()函数外，您可以尝试下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hist,bins &#x3D; np.histogram(img.ravel(),256,[0,256])</span><br></pre></td></tr></table></figure><p>hist与我们之前计算的相同。但是bin将具有257个元素，因为Numpy计算出bin的范围为0-0.99、1-1.99、2-2.99等。因此最终范围为255-255.99。为了表示这一点，他们还在最后添加了256。但是我们不需要256。最多255就足够了。</p><p>另外 Numpy还有另一个函数<strong>np.bincount</strong>()，它比np.histogram()快10倍左右。因此，对于一维直方图，您可以更好地尝试一下。不要忘记在np.bincount中设置minlength = 256。例如，hist = np.bincount(img.ravel()，minlength = 256)<br>注意 OpenCV函数比np.histogram()快大约40倍。因此，尽可能使用OpenCV函数。</p><p>现在我们应该绘制直方图，但是怎么绘制？</p><h2 id="绘制直方图"><a href="#绘制直方图" class="headerlink" title="绘制直方图"></a>绘制直方图</h2><p>有两种方法， 1. 简短的方法：使用Matplotlib绘图功能 2. 稍长的方法：使用OpenCV绘图功能</p><h2 id="1-使用Matplotlib"><a href="#1-使用Matplotlib" class="headerlink" title="1. 使用Matplotlib"></a>1. 使用Matplotlib</h2><p>Matplotlib带有直方图绘图功能：matplotlib.pyplot.hist() 它直接找到直方图并将其绘制。</p><p>您无需使用<strong>calcHist</strong>()或np.histogram()函数来查找直方图。请参见下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;,0)</span><br><span class="line">plt.hist(img.ravel(),256,[0,256]); plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/histogram_matplotlib.jpg" alt></p><p>或者，您可以使用matplotlib的法线图，这对于BGR图是很好的。为此，您需要首先找到直方图数据。试试下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;)</span><br><span class="line">color &#x3D; (&#39;b&#39;,&#39;g&#39;,&#39;r&#39;)</span><br><span class="line">for i,col in enumerate(color):</span><br><span class="line">    histr &#x3D; cv.calcHist([img],[i],None,[256],[0,256])</span><br><span class="line">    plt.plot(histr,color &#x3D; col)</span><br><span class="line">    plt.xlim([0,256])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/histogram_rgb_plot.jpg" alt><br>您可以从上图中得出，蓝色在图像中具有一些高值域（显然这应该是由于天空）</p><h2 id="2-使用-OpenCV"><a href="#2-使用-OpenCV" class="headerlink" title="2. 使用 OpenCV"></a>2. 使用 OpenCV</h2><p>好吧，在这里您可以调整直方图的值及其bin值，使其看起来像x，y坐标，</p><p>以便您可以使用<strong>cv.line</strong>()或cv.polyline()函数绘制它以生成与上述相同的图像。</p><p>OpenCV-Python2官方示例已经提供了此功能。检查示例/python/hist.py中的代码。</p><p>掩码的应用<br>我们使用了cv.calcHist()来查找整个图像的直方图。如果你想找到图像某些区域的直方图呢?只需创建一个掩码图像，在你要找到直方图为白色，否则黑色。然后把这个作为掩码传递。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;,0)</span><br><span class="line"># create a mask</span><br><span class="line">mask &#x3D; np.zeros(img.shape[:2], np.uint8)</span><br><span class="line">mask[100:300, 100:400] &#x3D; 255</span><br><span class="line">masked_img &#x3D; cv.bitwise_and(img,img,mask &#x3D; mask)</span><br><span class="line"># 计算掩码区域和非掩码区域的直方图</span><br><span class="line"># 检查作为掩码的第三个参数</span><br><span class="line">hist_full &#x3D; cv.calcHist([img],[0],None,[256],[0,256])</span><br><span class="line">hist_mask &#x3D; cv.calcHist([img],[0],mask,[256],[0,256])</span><br><span class="line">plt.subplot(221), plt.imshow(img, &#39;gray&#39;)</span><br><span class="line">plt.subplot(222), plt.imshow(mask,&#39;gray&#39;)</span><br><span class="line">plt.subplot(223), plt.imshow(masked_img, &#39;gray&#39;)</span><br><span class="line">plt.subplot(224), plt.plot(hist_full), plt.plot(hist_mask)</span><br><span class="line">plt.xlim([0,256])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>查看结果。在直方图中，蓝线表示完整图像的直方图，绿线表示掩码区域的直方图。<br><img src="http://qiniu.aihubs.net/histogram_masking.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="直方图-2：直方图均衡"><a href="#直方图-2：直方图均衡" class="headerlink" title="直方图-2：直方图均衡"></a><span id="header2">直方图-2：直方图均衡</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>在本节中, - 我们将学习直方图均衡化的概念,并利用它来提高图像的对比度。</p><h2 id="理论-1"><a href="#理论-1" class="headerlink" title="理论"></a>理论</h2><p>考虑这样一个图像，它的像素值仅局限于某个特定的值范围。</p><p>例如，较亮的图像将把所有像素限制在高值上。但是一幅好的图像会有来自图像所有区域的像素。</p><p>因此，您需要将这个直方图拉伸到两端(如下图所示，来自wikipedia)，这就是直方图均衡化的作用(简单来说)。这通常会提高图像的对比度。<br><img src="http://qiniu.aihubs.net/histogram_equalization.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;wiki.jpg&#39;,0)</span><br><span class="line">hist,bins &#x3D; np.histogram(img.flatten(),256,[0,256])</span><br><span class="line">cdf &#x3D; hist.cumsum()</span><br><span class="line">cdf_normalized &#x3D; cdf * float(hist.max()) &#x2F; cdf.max()</span><br><span class="line">plt.plot(cdf_normalized, color &#x3D; &#39;b&#39;)</span><br><span class="line">plt.hist(img.flatten(),256,[0,256], color &#x3D; &#39;r&#39;)</span><br><span class="line">plt.xlim([0,256])</span><br><span class="line">plt.legend((&#39;cdf&#39;,&#39;histogram&#39;), loc &#x3D; &#39;upper left&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/histeq_numpy1.jpg" alt></p><p>你可以看到直方图位于较亮的区域。我们需要全频谱。</p><p>为此，我们需要一个转换函数，将亮区域的输入像素映射到整个区域的输出像素。这就是直方图均衡化的作用。</p><p>现在我们找到最小的直方图值(不包括0)，并应用wiki页面中给出的直方图均衡化方程。</p><p>但我在这里用过，来自Numpy的掩码数组概念数组。对于掩码数组，所有操作都在非掩码元素上执行。您可以从Numpy文档中了解更多关于掩码数组的信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cdf_m &#x3D; np.ma.masked_equal(cdf,0)</span><br><span class="line">cdf_m &#x3D; (cdf_m - cdf_m.min())*255&#x2F;(cdf_m.max()-cdf_m.min())</span><br><span class="line">cdf &#x3D; np.ma.filled(cdf_m,0).astype(&#39;uint8&#39;)</span><br></pre></td></tr></table></figure><p>现在我们有了查找表，该表为我们提供了有关每个输入像素值的输出像素值是什么的信息。因此，我们仅应用变换。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img2 &#x3D; cdf[img]</span><br></pre></td></tr></table></figure><p>现在，我们像以前一样计算其直方图和cdf（您这样做），结果如下所示：<br><img src="http://qiniu.aihubs.net/histeq_numpy2.jpg" alt><br>另一个重要的特征是，即使图像是一个较暗的图像(而不是我们使用的一个较亮的图像)，经过均衡后，我们将得到几乎相同的图像。因此，这是作为一个“参考工具”，使所有的图像具有相同的照明条件。这在很多情况下都很有用。</p><p>例如，在人脸识别中，在对人脸数据进行训练之前，对人脸图像进行直方图均衡化处理，使其具有相同的光照条件。</p><h2 id="OpenCV中的直方图均衡"><a href="#OpenCV中的直方图均衡" class="headerlink" title="OpenCV中的直方图均衡"></a>OpenCV中的直方图均衡</h2><p>OpenCV具有执行此操作的功能cv.equalizeHist（）。</p><p>它的输入只是灰度图像，输出是我们的直方图均衡图像。 下面是一个简单的代码片段，显示了它与我们使用的同一图像的用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img &#x3D; cv.imread(&#39;wiki.jpg&#39;,0)</span><br><span class="line">equ &#x3D; cv.equalizeHist(img)</span><br><span class="line">res &#x3D; np.hstack((img,equ)) #stacking images side-by-side</span><br><span class="line">cv.imwrite(&#39;res.png&#39;,res)</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.aihubs.net/equalization_opencv.jpg" alt><br>因此，现在您可以在不同的光照条件下拍摄不同的图像，对其进行均衡并检查结果。</p><p>当图像的直方图限制在特定区域时，直方图均衡化效果很好。在直方图覆盖较大区域（即同时存在亮像素和暗像素）的强度变化较大的地方，效果不好。请检查其他资源中的SOF链接。</p><h2 id="CLAHE（对比度受限的自适应直方图均衡）"><a href="#CLAHE（对比度受限的自适应直方图均衡）" class="headerlink" title="CLAHE（对比度受限的自适应直方图均衡）"></a>CLAHE（对比度受限的自适应直方图均衡）</h2><p>我们刚刚看到的第一个直方图均衡化考虑了图像的整体对比度。</p><p>在许多情况下，这不是一个好主意。例如，下图显示了输入图像及其在全局直方图均衡后的结果。<br><img src="http://qiniu.aihubs.net/clahe_1.jpg" alt></p><p>直方图均衡后，背景对比度确实得到了改善。但是在两个图像中比较雕像的脸。</p><p>由于亮度过高，我们在那里丢失了大多数信息。</p><p>这是因为它的直方图不像我们在前面的案例中所看到的那样局限于特定区域（尝试绘制输入图像的直方图，您将获得更多的直觉）。</p><p>因此，为了解决这个问题，使用了<strong>自适应直方图均衡</strong>。</p><p>在这种情况下，图像被分成称为“tiles”的小块（在OpenCV中，tileSize默认为8x8）。</p><p>然后，像往常一样对这些块中的每一个进行直方图均衡。</p><p>因此，在较小的区域中，直方图将限制在一个较小的区域中（除非存在噪声）。</p><p>如果有噪音，它将被放大。为了避免这种情况，应用了对比度限制。</p><p>如果任何直方图bin超出指定的对比度限制（在OpenCV中默认为40），则在应用直方图均衡之前，将这些像素裁剪并均匀地分布到其他bin。</p><p>均衡后，要消除图块边界中的伪影，请应用双线性插值。</p><p>下面的代码片段显示了如何在OpenCV中应用CLAHE：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">img &#x3D; cv.imread(&#39;tsukuba_l.png&#39;,0)</span><br><span class="line"># create a CLAHE object (Arguments are optional).</span><br><span class="line">clahe &#x3D; cv.createCLAHE(clipLimit&#x3D;2.0, tileGridSize&#x3D;(8,8))</span><br><span class="line">cl1 &#x3D; clahe.apply(img)</span><br><span class="line">cv.imwrite(&#39;clahe_2.jpg&#39;,cl1)</span><br></pre></td></tr></table></figure><p>查看下面的结果，并将其与上面的结果进行比较，尤其是雕像区域：<br><img src="http://qiniu.aihubs.net/clahe_2.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="直方图-3：二维直方图"><a href="#直方图-3：二维直方图" class="headerlink" title="直方图-3：二维直方图"></a><span id="header3">直方图-3：二维直方图</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><p>在本章中，我们将学习查找和绘制2D直方图。这将在以后的章节中有所帮助。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在第一篇文章中，我们计算并绘制了一维直方图。 之所以称为一维，是因为我们仅考虑一个特征，即像素的灰度强度值。 </p><p>但是在二维直方图中，您要考虑两个特征。 通常，它用于查找颜色直方图，其中两个特征是每个像素的色相和饱和度值。</p><p>我们将尝试了解如何创建这种颜色直方图，这对于理解诸如直方图反向投影之类的更多主题将很有用。</p><h2 id="OpenCV中的二维直方图"><a href="#OpenCV中的二维直方图" class="headerlink" title="OpenCV中的二维直方图"></a>OpenCV中的二维直方图</h2><p>它非常简单，并且使用相同的函数<strong>cv.calcHist</strong>()进行计算。 </p><p>对于颜色直方图，我们需要将图像从BGR转换为HSV。（请记住，对于一维直方图，我们从BGR转换为灰度）。对于二维直方图，其参数将进行如下修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">channel &#x3D; [0,1]，因为我们需要同时处理H和S平面。</span><br><span class="line">bins &#x3D; [180,256] 对于H平面为180，对于S平面为256。</span><br><span class="line">range &#x3D; [0,180,0,256] 色相值介于0和180之间，饱和度介于0和256之间。</span><br></pre></td></tr></table></figure><p>现在检查以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;)</span><br><span class="line">hsv &#x3D; cv.cvtColor(img,cv.COLOR_BGR2HSV)</span><br><span class="line">hist &#x3D; cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])</span><br></pre></td></tr></table></figure><p>就是这样。</p><h2 id="Numpy中的二维直方图"><a href="#Numpy中的二维直方图" class="headerlink" title="Numpy中的二维直方图"></a>Numpy中的二维直方图</h2><p>Numpy还为此提供了一个特定的函数:np.histogram2d()。(记住，对于一维直方图我们使用了<strong>np.histogram</strong>())。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;)</span><br><span class="line">hsv &#x3D; cv.cvtColor(img,cv.COLOR_BGR2HSV)</span><br><span class="line">hist, xbins, ybins &#x3D; np.histogram2d(h.ravel(),s.ravel(),[180,256],[[0,180],[0,256]])</span><br></pre></td></tr></table></figure><p>第一个参数是H平面，第二个是S平面，第三个是每个箱子的数量，第四个是它们的范围。</p><p>现在我们可以检查如何绘制这个颜色直方图。</p><h2 id="绘制二维直方图"><a href="#绘制二维直方图" class="headerlink" title="绘制二维直方图"></a>绘制二维直方图</h2><h2 id="方法1：使用-cv-imshow"><a href="#方法1：使用-cv-imshow" class="headerlink" title="方法1：使用 cv.imshow()"></a>方法1：使用 cv.imshow()</h2><p>我们得到的结果是尺寸为80x256的二维数组。因此，可以使用<strong>cv.imshow</strong>()函数像平常一样显示它们。</p><p>它将是一幅灰度图像，除非您知道不同颜色的色相值，否则不会对其中的颜色有太多了解。</p><h2 id="方法2：使用Matplotlib"><a href="#方法2：使用Matplotlib" class="headerlink" title="方法2：使用Matplotlib"></a>方法2：使用Matplotlib</h2><p>我们可以使用matplotlib.pyplot.imshow()函数绘制具有不同颜色图的2D直方图。</p><p>它使我们对不同的像素密度有了更好的了解。但是，除非您知道不同颜色的色相值，否则乍一看并不能使我们知道到底是什么颜色。</p><p>注意 使用此功能时，请记住，插值法应采用最近邻以获得更好的结果。</p><p>考虑下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">img &#x3D; cv.imread(&#39;home.jpg&#39;)</span><br><span class="line">hsv &#x3D; cv.cvtColor(img,cv.COLOR_BGR2HSV)</span><br><span class="line">hist &#x3D; cv.calcHist( [hsv], [0, 1], None, [180, 256], [0, 180, 0, 256] )</span><br><span class="line">plt.imshow(hist,interpolation &#x3D; &#39;nearest&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>下面是输入图像及其颜色直方图。X轴显示S值，Y轴显示色相。<br><img src="http://qiniu.aihubs.net/2dhist_matplotlib.jpg" alt></p><p>在直方图中，您可以在H = 100和S = 200附近看到一些较高的值。</p><p>它对应于天空的蓝色。同样，在H = 25和S = 100附近可以看到另一个峰值。它对应于宫殿的黄色。您可以使用GIMP等任何图像编辑工具进行验证。</p><h2 id="方法3：OpenCV示例样式"><a href="#方法3：OpenCV示例样式" class="headerlink" title="方法3：OpenCV示例样式"></a>方法3：OpenCV示例样式</h2><p>OpenCV-Python2示例中有一个颜色直方图的示例代码(samples / python / color_histogram.py)。</p><p>如果运行代码，则可以看到直方图也显示了相应的颜色。或者简单地，它输出颜色编码的直方图。其结果非常好（尽管您需要添加额外的线束）。</p><p>在该代码中，作者在HSV中创建了一个颜色图。然后将其转换为BGR。将所得的直方图图像与此颜色图相乘。他还使用一些预处理步骤来删除小的孤立像素，从而获得良好的直方图。</p><p>我将其留给读者来运行代码，对其进行分析并拥有自己的解决方法。下面是与上面相同的图像的代码输出：<br><img src="http://qiniu.aihubs.net/2dhist_opencv.jpg" alt></p><p>您可以在直方图中清楚地看到存在什么颜色，那里是蓝色，那里是黄色，并且由于棋盘的存在而有些白色。很好！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="直方图4：直方图反投影"><a href="#直方图4：直方图反投影" class="headerlink" title="直方图4：直方图反投影"></a><span id="header4">直方图4：直方图反投影</span></h1><h2 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h2><p>在本章中，我们将学习直方图反投影。</p><h2 id="理论-2"><a href="#理论-2" class="headerlink" title="理论"></a>理论</h2><p>这是由<strong>Michael J. Swain</strong>和<strong>Dana H. Ballard</strong>在他们的论文《通过颜色直方图索引》中提出的。</p><p>用简单的话说是什么意思？它用于图像分割或在图像中查找感兴趣的对象。</p><p>简而言之，它创建的图像大小与输入图像相同（但只有一个通道），其中每个像素对应于该像素属于我们物体的概率。</p><p>用更简单的话来说，与其余部分相比，输出图像将在可能有对象的区域具有更多的白色值。</p><p>好吧，这是一个直观的解释。（我无法使其更简单）。直方图反投影与camshift算法等配合使用。</p><p>我们该怎么做呢？我们创建一个图像的直方图，其中包含我们感兴趣的对象（在我们的示例中是背景，离开播放器等）。</p><p>对象应尽可能填充图像以获得更好的效果。而且颜色直方图比灰度直方图更可取，因为对象的颜色对比灰度强度是定义对象的好方法。</p><p>然后，我们将该直方图“反投影”到需要找到对象的测试图像上，</p><p>换句话说，我们计算出属于背景的每个像素的概率并将其显示出来。在适当的阈值下产生的输出使我们仅获得背景。</p><h2 id="Numpy中的算法"><a href="#Numpy中的算法" class="headerlink" title="Numpy中的算法"></a>Numpy中的算法</h2><p>首先，我们需要计算我们要查找的对象（使其为“ M”）和要搜索的图像（使其为“ I”）的颜色直方图。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cvfrom matplotlib import pyplot as plt</span><br><span class="line">#roi是我们需要找到的对象或对象区域</span><br><span class="line">roi &#x3D; cv.imread(&#39;rose_red.png&#39;)</span><br><span class="line">hsv &#x3D; cv.cvtColor(roi,cv.COLOR_BGR2HSV)</span><br><span class="line">#目标是我们搜索的图像</span><br><span class="line">target &#x3D; cv.imread(&#39;rose.png&#39;)</span><br><span class="line">hsvt &#x3D; cv.cvtColor(target,cv.COLOR_BGR2HSV)</span><br><span class="line"># 使用calcHist查找直方图。也可以使用np.histogram2d完成</span><br><span class="line">M &#x3D; cv.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )</span><br><span class="line">I &#x3D; cv.calcHist([hsvt],[0, 1], None, [180, 256], [0, 180, 0, 256] )</span><br></pre></td></tr></table></figure><p>求出比值R=$\frac{M}{I}$。然后反向投影R，即使用R作为调色板，并以每个像素作为其对应的目标概率创建一个新图像。即B(x,y) = R[h(x,y),s(x,y)] 其中h是色调，s是像素在(x，y)的饱和度。之后，应用条件B(x,y)=min[B(x,y),1]。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">h,s,v &#x3D; cv.split(hsvt)</span><br><span class="line">B &#x3D; R[h.ravel(),s.ravel()]</span><br><span class="line">B &#x3D; np.minimum(B,1)</span><br><span class="line">B &#x3D; B.reshape(hsvt.shape[:2])</span><br></pre></td></tr></table></figure><p>现在对圆盘应用卷积，B=D∗B，其中D是圆盘内核。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">disc &#x3D; cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))</span><br><span class="line">cv.filter2D(B,-1,disc,B)</span><br><span class="line">B &#x3D; np.uint8(B)</span><br><span class="line">cv.normalize(B,B,0,255,cv.NORM_MINMAX)</span><br></pre></td></tr></table></figure><p>现在最大强度的位置给了我们物体的位置。如果我们期望图像中有一个区域，则对合适的值进行阈值处理将获得不错的结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ret,thresh &#x3D; cv.threshold(B,50,255,0)</span><br></pre></td></tr></table></figure><p>就是这样</p><h2 id="OpenCV的反投影"><a href="#OpenCV的反投影" class="headerlink" title="OpenCV的反投影"></a>OpenCV的反投影</h2><p>OpenCV提供了一个内建的函数<strong>cv.calcBackProject</strong>()。</p><p>它的参数几乎与<strong>cv.calchist</strong>()函数相同。它的一个参数是直方图，也就是物体的直方图，我们必须找到它。</p><p>另外，在传递给backproject函数之前，应该对对象直方图进行归一化。它返回概率图像。</p><p>然后我们用圆盘内核对图像进行卷积并应用阈值。下面是我的代码和结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import cv2 as cv</span><br><span class="line">roi &#x3D; cv.imread(&#39;rose_red.png&#39;)</span><br><span class="line">hsv &#x3D; cv.cvtColor(roi,cv.COLOR_BGR2HSV)</span><br><span class="line">target &#x3D; cv.imread(&#39;rose.png&#39;)</span><br><span class="line">hsvt &#x3D; cv.cvtColor(target,cv.COLOR_BGR2HSV)</span><br><span class="line"># 计算对象的直方图</span><br><span class="line">roihist &#x3D; cv.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )</span><br><span class="line"># 直方图归一化并利用反传算法</span><br><span class="line">cv.normalize(roihist,roihist,0,255,cv.NORM_MINMAX)</span><br><span class="line">dst &#x3D; cv.calcBackProject([hsvt],[0,1],roihist,[0,180,0,256],1)</span><br><span class="line"># 用圆盘进行卷积</span><br><span class="line">disc &#x3D; cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))</span><br><span class="line">cv.filter2D(dst,-1,disc,dst)</span><br><span class="line"># 应用阈值作与操作</span><br><span class="line">ret,thresh &#x3D; cv.threshold(dst,50,255,0)</span><br><span class="line">thresh &#x3D; cv.merge((thresh,thresh,thresh))</span><br><span class="line">res &#x3D; cv.bitwise_and(target,thresh)</span><br><span class="line">res &#x3D; np.vstack((target,thresh,res))</span><br><span class="line">cv.imwrite(&#39;res.jpg&#39;,res)</span><br></pre></td></tr></table></figure><p>以下是我处理过的一个示例。我将蓝色矩形内的区域用作示例对象，我想提取整个地面。<br><img src="http://qiniu.aihubs.net/backproject_opencv.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;10.1.&lt;a href=&quot;#header1&quot;&gt;直方图-1：查找、绘制和分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.2.&lt;a href=&quot;#header2&quot;&gt;直方图-2：直方图均衡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.3.&lt;a href=&quot;#header3&quot;&gt;直方图-3：二维直方图&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10.4.&lt;a href=&quot;#header4&quot;&gt;直方图4：直方图反投影&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv中的图像处理3-轮廓</title>
    <link href="http://yoursite.com/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%863-%E8%BD%AE%E5%BB%93/"/>
    <id>http://yoursite.com/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%863-%E8%BD%AE%E5%BB%93/</id>
    <published>2020-07-13T08:31:05.000Z</published>
    <updated>2020-07-13T08:35:09.501Z</updated>
    
    <content type="html"><![CDATA[<ul><li>9.1.<a href="#header1">轮廓入门</a></li><li>9.2.<a href="#header2">轮廓特征</a></li><li>9.3.<a href="#header3">轮廓属性</a></li><li>9.4.<a href="#header4">轮廓更多属性</a></li><li>9.5.<a href="#header5">轮廓分层</a><a id="more"></a></li></ul><h1 id="轮廓：入门"><a href="#轮廓：入门" class="headerlink" title="轮廓：入门"></a><span id="header1">轮廓：入门</span></h1><p>##目标<br>了解轮廓是什么。</p><p>学习查找轮廓，绘制轮廓等。</p><p>你将看到以下功能：cv.findContours()，cv.drawContours()</p><h2 id="什么是轮廓"><a href="#什么是轮廓" class="headerlink" title="什么是轮廓?"></a>什么是轮廓?</h2><p>轮廓可以简单地解释为连接具有相同颜色或强度的所有连续点（沿边界）的曲线。</p><p>轮廓是用于形状分析以及对象检测和识别的有用工具。</p><p>为了获得更高的准确性，请使用二进制图像。因此，在找到轮廓之前，请应用阈值或canny边缘检测。</p><p>从OpenCV 3.2开始，findContours()不再修改源图像。</p><p>在OpenCV中，找到轮廓就像从黑色背景中找到白色物体。因此请记住，要找到的对象应该是白色，背景应该是黑色。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>)</span><br><span class="line">imgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv.threshold(imgray, <span class="number">127</span>, <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">unknown,contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)</span><br></pre></td></tr></table></figure><p>findcontour()函数中有三个参数，</p><p>第一个是源图像，</p><p>第二个是轮廓检索模式，</p><p>第三个是轮廓逼近方法。</p><p>输出未知量,等高线和层次结构。</p><p>轮廓是图像中所有轮廓的Python列表。</p><p>每个单独的轮廓是一个(x,y)坐标的Numpy数组的边界点的对象。</p><p>注意 稍后我们将详细讨论第二和第三个参数以及有关层次结构。</p><p>在此之前，代码示例中赋予它们的值将适用于所有图像。</p><h2 id="如何绘制轮廓"><a href="#如何绘制轮廓" class="headerlink" title="如何绘制轮廓?"></a>如何绘制轮廓?</h2><p>要绘制轮廓，请使用<strong>cv.drawContours</strong>函数。只要有边界点，它也可以用来绘制任何形状。</p><p>它的第一个参数是源图像，</p><p>第二个参数是应该作为Python列表传递的轮廓，</p><p>第三个参数是轮廓的索引（在绘制单个轮廓时有用。要绘制所有轮廓，请传递-1），其余参数是颜色，厚度等等</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在图像中绘制所有轮廓：</span></span><br><span class="line">cv.drawContours(img, contours, <span class="number">-1</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">3</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制单个轮廓，如第四个轮廓：</span></span><br><span class="line">cnt = contours[<span class="number">4</span>]</span><br><span class="line">cv.drawContours(img, [cnt], <span class="number">0</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">3</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 但是在大多数情况下，以下方法会很有用：</span></span><br><span class="line">cnt = contours[<span class="number">4</span>]</span><br><span class="line">cv.drawContours(img, [cnt], <span class="number">0</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">3</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>轮廓近似方法<br>这是<strong>cv.findContours</strong>函数中的第三个参数。它实际上表示什么？</p><p>上面我们告诉我们轮廓是强度相同的形状的边界。</p><p>它存储形状边界的(x,y)坐标。但是它存储所有坐标吗？这是通过这种轮廓近似方法指定的。</p><p>如果传递<strong>cv.CHAIN_APPROX_NONE</strong>，则将存储所有边界点。</p><p>但是实际上我们需要所有这些要点吗？</p><p>例如，您找到了一条直线的轮廓。您是否需要线上的所有点来代表该线？</p><p>不，我们只需要该线的两个端点即可。</p><p>这就是<strong>cv.CHAIN_APPROX_SIMPLE</strong>所做的。它删除所有冗余点并压缩轮廓，从而节省内存。</p><p>下面的矩形图像演示了此技术。</p><p>只需在轮廓数组中的所有坐标上绘制一个圆（以蓝色绘制）。</p><p>第一幅图像显示了我用<strong>cv.CHAIN_APPROX_NONE</strong>获得的积分（734个点），</p><p>第二幅图像显示了我用<strong>cv.CHAIN_APPROX_SIMPLE</strong>获得的效果（只有4个点）。</p><p>看，它可以节省多少内存！！！</p><p><img src="http://qiniu.aihubs.net/none.jpg" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="轮廓特征"><a href="#轮廓特征" class="headerlink" title="轮廓特征"></a><span id="header2">轮廓特征</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>在本文中，我们将学习 - 如何找到轮廓的不同特征，</p><p>例如面积，周长，质心，边界框等。 - 您将看到大量与轮廓有关的功能。</p><h2 id="1-特征矩"><a href="#1-特征矩" class="headerlink" title="1. 特征矩"></a>1. 特征矩</h2><p>特征矩可以帮助您计算一些特征，例如物体的质心，物体的面积等。</p><p>请查看特征矩上的维基百科页面。</p><p>函数<strong>cv.moments</strong>()提供了所有计算出的矩值的字典。见下文：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">ret,thresh = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">unknown,contours,hierarchy = cv.findContours(thresh, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">cnt = contours[<span class="number">0</span>]</span><br><span class="line">M = cv.moments(cnt)</span><br><span class="line">print( M )</span><br></pre></td></tr></table></figure><pre><code>{&apos;m00&apos;: 2.0, &apos;m10&apos;: 536.0, &apos;m01&apos;: 1272.0, &apos;m20&apos;: 143648.3333333333, &apos;m11&apos;: 340896.0, &apos;m02&apos;: 808992.3333333333, &apos;m30&apos;: 38497932.0, &apos;m21&apos;: 91360340.0, &apos;m12&apos;: 216809945.33333334, &apos;m03&apos;: 514519548.0, &apos;mu20&apos;: 0.3333333333139308, &apos;mu11&apos;: 0.0, &apos;mu02&apos;: 0.3333333332557231, &apos;mu30&apos;: 1.4901161193847656e-08, &apos;mu21&apos;: 1.234002411365509e-08, &apos;mu12&apos;: 3.073364496231079e-08, &apos;mu03&apos;: 1.1920928955078125e-07, &apos;nu20&apos;: 0.0833333333284827, &apos;nu11&apos;: 0.0, &apos;nu02&apos;: 0.08333333331393078, &apos;nu30&apos;: 2.634178031930877e-09, &apos;nu21&apos;: 2.1814286826927578e-09, &apos;nu12&apos;: 5.432992190857434e-09, &apos;nu03&apos;: 2.1073424255447017e-08}</code></pre><p>从这一刻起，您可以提取有用的数据，<br>例如面积，质心等。质心由关系给出，$C_x\frac{M_{10}}{M_{00}}$ 和 $C_y\frac{M_{01}}{M_{00}}$。可以按照以下步骤进行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cx = int(M[<span class="string">'m10'</span>]/M[<span class="string">'m00'</span>])</span><br><span class="line">cy = int(M[<span class="string">'m01'</span>]/M[<span class="string">'m00'</span>])</span><br></pre></td></tr></table></figure><h2 id="2-轮廓面积"><a href="#2-轮廓面积" class="headerlink" title="2. 轮廓面积"></a>2. 轮廓面积</h2><p>轮廓区域由函数<strong>cv.contourArea</strong>()或从矩M[‘m00’]中给出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">area = cv.contourArea(cnt) </span><br><span class="line">print(area)</span><br><span class="line">print(M[<span class="string">'m00'</span>])</span><br></pre></td></tr></table></figure><pre><code>2.02.0</code></pre><h2 id="3-轮廓周长"><a href="#3-轮廓周长" class="headerlink" title="3. 轮廓周长"></a>3. 轮廓周长</h2><p>也称为弧长。可以使用<strong>cv.arcLength</strong>()函数找到它。第二个参数指定形状是闭合轮廓(True)还是曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perimeter = cv.arcLength(cnt,<span class="literal">True</span>)</span><br><span class="line">perimeter</span><br></pre></td></tr></table></figure><pre><code>5.656854152679443</code></pre><h2 id="4-轮廓近似"><a href="#4-轮廓近似" class="headerlink" title="4. 轮廓近似"></a>4. 轮廓近似</h2><p>根据我们指定的精度，它可以将轮廓形状近似为顶点数量较少的其他形状。</p><p>它是Douglas-Peucker算法的实现。检查维基百科页面上的算法和演示。</p><p>为了理解这一点，假设您试图在图像中找到一个正方形，但是由于图像中的某些问题，您没有得到一个完美的正方形，而是一个“坏形状”（如下图所示）。</p><p>现在，您可以使用此功能来近似形状。在这种情况下，第二个参数称为epsilon，它是从轮廓到近似轮廓的最大距离。</p><p>它是一个精度参数。需要正确选择epsilon才能获得正确的输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">0.1</span>*cv.arcLength(cnt,<span class="literal">True</span>) </span><br><span class="line">approx = cv.approxPolyDP(cnt,epsilon,<span class="literal">True</span>)</span><br><span class="line">print(epsilon)</span><br><span class="line">print(approx)</span><br></pre></td></tr></table></figure><pre><code>0.5656854152679444[[[267 636]] [[268 635]] [[269 636]] [[268 637]]]</code></pre><p>下面，在第二张图片中，绿线显示了ε=弧长的10％时的近似曲线。第三幅图显示了ε=弧长度的1％时的情况。第三个参数指定曲线是否闭合。<br><img src="http://qiniu.aihubs.net/approx.jpg" alt></p><h2 id="5-轮廓凸包"><a href="#5-轮廓凸包" class="headerlink" title="5. 轮廓凸包"></a>5. 轮廓凸包</h2><p>凸包外观看起来与轮廓逼近相似，但不相似（在某些情况下两者可能提供相同的结果）。</p><p>在这里，cv.convexHull()函数检查曲线是否存在凸凹缺陷并对其进行校正。</p><p>一般而言，凸曲线是始终凸出或至少平坦的曲线。如果在内部凸出，则称为凸度缺陷。</p><p>例如，检查下面的手的图像。红线显示手的凸包。双向箭头标记显示凸度缺陷，这是凸包与轮廓线之间的局部最大偏差。</p><p><img src="http://qiniu.aihubs.net/convexitydefects.jpg" alt></p><p>关于它的语法，有一些需要讨论：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hull &#x3D; cv.convexHull(points[, hull[, clockwise[, returnPoints]]</span><br></pre></td></tr></table></figure><p>参数详细信息： </p><ul><li>点**是我们传递到的轮廓。 </li><li><strong>凸包</strong>是输出，通常我们忽略它。 </li><li>**顺时针方向：方向标记。如果为True，则输出凸包为顺时针方向。否则，其方向为逆时针方向。 </li><li>returnPoints：默认情况下为True。然后返回凸包的坐标。如果为False，则返回与凸包点相对应的轮廓点的索引。</li></ul><p>因此，要获得如上图所示的凸包，以下内容就足够了：<br>``<br>hull = cv.convexHull(cnt) </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">但是，如果要查找凸度缺陷，则需要传递returnPoints &#x3D; False。</span><br><span class="line"></span><br><span class="line">为了理解它，我们将拍摄上面的矩形图像。</span><br><span class="line"></span><br><span class="line">首先，我发现它的轮廓为cnt。现在，我发现它的带有returnPoints &#x3D; True的凸包，</span><br><span class="line"></span><br><span class="line">得到以下值：[[[234 202]]，[[51 202]]，[[51 79]]，[[234 79]]]，它们是四个角 矩形的点。</span><br><span class="line"></span><br><span class="line">现在，如果对returnPoints &#x3D; False执行相同的操作，</span><br><span class="line"></span><br><span class="line">则会得到以下结果：[[129]，[67]，[0]，[142]]。这些是轮廓中相应点的索引。</span><br><span class="line"></span><br><span class="line">例如，检查第一个值：cnt [129] &#x3D; [[234，202]]与第一个结果相同（对于其他结果依此类推）。</span><br><span class="line"></span><br><span class="line">当我们讨论凸度缺</span><br><span class="line"></span><br><span class="line">## 6. 检查凸度</span><br><span class="line">cv.isContourConvex()具有检查曲线是否凸出的功能。它只是返回True还是False。没什么大不了的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">k &#x3D; cv.isContourConvex(cnt) </span><br><span class="line">k</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><h2 id="7-边界矩形"><a href="#7-边界矩形" class="headerlink" title="7. 边界矩形"></a>7. 边界矩形</h2><p>有两种类型的边界矩形。</p><h3 id="7-a-直角矩形"><a href="#7-a-直角矩形" class="headerlink" title="7.a.直角矩形"></a>7.a.直角矩形</h3><p>它是一个矩形，不考虑物体的旋转。所以边界矩形的面积不是最小的。</p><p>它是由函数<strong>cv.boundingRect</strong>()找到的。</p><p>令(x，y)为矩形的左上角坐标，而(w，h)为矩形的宽度和高度。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x,y,w,h &#x3D; cv.boundingRect(cnt)</span><br><span class="line">cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)</span><br></pre></td></tr></table></figure><h3 id="7-b-旋转矩形"><a href="#7-b-旋转矩形" class="headerlink" title="7.b. 旋转矩形"></a>7.b. 旋转矩形</h3><p>这里，边界矩形是用最小面积绘制的，所以它也考虑了旋转。</p><p>使用的函数是<strong>cv.minAreaRect</strong>()。</p><p>它返回一个Box2D结构，其中包含以下细节 -(中心(x,y)，(宽度，高度)，旋转角度)。</p><p>但要画出这个矩形，我们需要矩形的四个角。</p><p>它由函数<strong>cv.boxPoints</strong>()获得</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rect &#x3D; cv.minAreaRect(cnt)</span><br><span class="line">box &#x3D; cv.boxPoints(rect)</span><br><span class="line">box &#x3D; np.int0(box)</span><br><span class="line">cv.drawContours(img,[box],0,(0,0,255),2)</span><br></pre></td></tr></table></figure><p>两个矩形都显示在一张单独的图像中。绿色矩形显示正常的边界矩形。红色矩形是旋转后的矩形。</p><p><img src="http://qiniu.aihubs.net/boundingrect.png" alt></p><h2 id="8-最小闭合圈"><a href="#8-最小闭合圈" class="headerlink" title="8. 最小闭合圈"></a>8. 最小闭合圈</h2><p>接下来，使用函数<em>*cv.minEnclosingCircle(</em>()查找对象的圆周。它是一个以最小面积完全覆盖物体的圆。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(x,y),radius &#x3D; cv.minEnclosingCircle(cnt)</span><br><span class="line">center &#x3D; (int(x),int(y))</span><br><span class="line">radius &#x3D; int(radius)</span><br><span class="line">cv.circle(img,center,radius,(0,255,0),2)</span><br><span class="line">&#96;&#96;&#96;                            </span><br><span class="line">![](http:&#x2F;&#x2F;qiniu.aihubs.net&#x2F;circumcircle.png)</span><br><span class="line"></span><br><span class="line">## 9. 拟合一个椭圆</span><br><span class="line">下一个是把一个椭圆拟合到一个物体上。它返回内接椭圆的旋转矩形。</span><br></pre></td></tr></table></figure><p>ellipse = cv.fitEllipse(cnt)<br>cv.ellipse(img,ellipse,(0,255,0),2)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">![](http:&#x2F;&#x2F;qiniu.aihubs.net&#x2F;fitellipse.png)</span><br><span class="line"></span><br><span class="line">## 10. 拟合直线</span><br><span class="line">同样，我们可以将一条直线拟合到一组点。下图包含一组白点。我们可以近似一条直线。</span><br></pre></td></tr></table></figure><p>rows,cols = img.shape[:2]<br>[vx,vy,x,y] = cv.fitLine(cnt, cv.DIST_L2,0,0.01,0.01)<br>lefty = int((-x<em>vy/vx) + y)<br>righty = int(((cols-x)</em>vy/vx)+y)<br>cv.line(img,(cols-1,righty),(0,lefty),(0,255,0),2)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># &lt;span id&#x3D;&quot;header3&quot;&gt;轮廓属性&lt;&#x2F;span&gt;</span><br><span class="line">在这里，我们将学习提取一些常用的物体属性，</span><br><span class="line"></span><br><span class="line">如坚实度，等效直径，掩模图像，平均强度等。更多的功能可以在Matlab regionprops文档中找到。</span><br><span class="line"></span><br><span class="line">(注:质心、面积、周长等也属于这一类，但我们在上一章已经见过)</span><br><span class="line"></span><br><span class="line">## 1. 长宽比</span><br><span class="line">它是对象边界矩形的宽度与高度的比值。</span><br><span class="line"></span><br><span class="line">Aspect Ratio&#x3D;$\frac&#123;Width&#125;&#123;Height&#125;$</span><br></pre></td></tr></table></figure><p>x,y,w,h = cv.boundingRect(cnt)<br>aspect_ratio = float(w)/h</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 2. 范围</span><br><span class="line">范围是轮廓区域与边界矩形区域的比值。</span><br><span class="line"></span><br><span class="line">Extent&#x3D;$\frac&#123;Object Area&#125;&#123;Bounding Rectangle Area&#125;$</span><br></pre></td></tr></table></figure><p>area = cv.contourArea(cnt)<br>x,y,w,h = cv.boundingRect(cnt)<br>rect_area = w*h<br>extent = float(area)/rect_area</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 3. 坚实度</span><br><span class="line">坚实度是等高线面积与其凸包面积之比。</span><br><span class="line"></span><br><span class="line">Solidity&#x3D;$\frac&#123;Contour Area&#125;&#123;ConvexHull Area&#125;$</span><br></pre></td></tr></table></figure><p>area = cv.contourArea(cnt)<br>hull = cv.convexHull(cnt)<br>hull_area = cv.contourArea(hull)<br>solidity = float(area)/hull_area</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 4. 等效直径</span><br><span class="line">等效直径是面积与轮廓面积相同的圆的直径。</span><br><span class="line"></span><br><span class="line">EquivalentDiameter&#x3D;$\sqrt&#123;\frac&#123;4×ContourArea&#125;&#123;\Pi&#125;&#125;$</span><br></pre></td></tr></table></figure><p>area = cv.contourArea(cnt)<br>equi_diameter = np.sqrt(4*area/np.pi)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 5. 取向</span><br><span class="line">取向是物体指向的角度。以下方法还给出了主轴和副轴的长度。</span><br></pre></td></tr></table></figure><p>(x,y),(MA,ma),angle = cv.fitEllipse(cnt)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 6. 掩码和像素点</span><br><span class="line">在某些情况下，我们可能需要构成该对象的所有点。可以按照以下步骤完成：</span><br></pre></td></tr></table></figure><p>mask = np.zeros(imgray.shape,np.uint8)<br>cv.drawContours(mask,[cnt],0,255,-1)<br>pixelpoints = np.transpose(np.nonzero(mask))<br>#pixelpoints = cv.findNonZero(mask)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">这里提供了两个方法，一个使用Numpy函数，另一个使用OpenCV函数(最后的注释行)。结果也是一样的，只是略有不同。</span><br><span class="line"></span><br><span class="line">Numpy给出的坐标是(行、列)格式，</span><br><span class="line"></span><br><span class="line">而OpenCV给出的坐标是(x,y)格式。所以基本上答案是可以互换的。注意，row &#x3D; x, column &#x3D; y。</span><br><span class="line"></span><br><span class="line">## 7. 最大值，最小值和它们的位置</span><br><span class="line">我们可以使用掩码图像找到这些参数。</span><br></pre></td></tr></table></figure><p>min_val, max_val, min_loc, max_loc = cv.minMaxLoc(imgray,mask = mask)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 8. 平均颜色或平均强度</span><br><span class="line">在这里，我们可以找到对象的平均颜色。或者可以是灰度模式下物体的平均强度。我们再次使用相同的掩码进行此操作。</span><br></pre></td></tr></table></figure><p>mean_val = cv.mean(im,mask = mask)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 9. 极端点</span><br><span class="line">极点是指对象的最顶部，最底部，最右侧和最左侧的点。</span><br></pre></td></tr></table></figure><p>leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])<br>rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])<br>topmost = tuple(cnt[cnt[:,:,1].argmin()][0])<br>bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">例如，如果我将其应用于印度地图，则会得到以下结果：</span><br><span class="line">![](http:&#x2F;&#x2F;qiniu.aihubs.net&#x2F;extremepoints.jpg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br></pre></td></tr></table></figure><h1 id="轮廓：更多属性"><a href="#轮廓：更多属性" class="headerlink" title="轮廓：更多属性"></a><span id="header4">轮廓：更多属性</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>在本章中，我们将学习 - 凸性缺陷以及如何找到它们 - 查找点到多边形的最短距离 - 匹配不同的形状</p><h2 id="理论和代码"><a href="#理论和代码" class="headerlink" title="理论和代码"></a>理论和代码</h2><h3 id="1-凸性缺陷"><a href="#1-凸性缺陷" class="headerlink" title="1. 凸性缺陷"></a>1. 凸性缺陷</h3><p>我们看到了关于轮廓的第二章的凸包。从这个凸包上的任何偏差都可以被认为是凸性缺陷。 OpenCV有一个函数来找到这个,cv.convexityDefects()。一个基本的函数调用如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hull &#x3D; cv.convexHull(cnt,returnPoints &#x3D; False)</span><br><span class="line">defects &#x3D; cv.convexityDefects(cnt,hull)</span><br></pre></td></tr></table></figure><p>注意 记住,我们必须在发现凸包时,传递returnPoints= False,以找到凸性缺陷。</p><p>它返回一个数组，其中每行包含这些值—[起点、终点、最远点、到最远点的近似距离]。我们可以用图像把它形象化。我们画一条连接起点和终点的线，然后在最远处画一个圆。记住，返回的前三个值是cnt的索引。所以我们必须从cnt中获取这些值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">img &#x3D; cv.imread(&#39;star.jpg&#39;)</span><br><span class="line">img_gray &#x3D; cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line">ret,thresh &#x3D; cv.threshold(img_gray, 127, 255,0)</span><br><span class="line">contours,hierarchy &#x3D; cv.findContours(thresh,2,1)</span><br><span class="line">cnt &#x3D; contours[0]</span><br><span class="line">hull &#x3D; cv.convexHull(cnt,returnPoints &#x3D; False)</span><br><span class="line">defects &#x3D; cv.convexityDefects(cnt,hull)</span><br><span class="line">for i in range(defects.shape[0]):</span><br><span class="line">    s,e,f,d &#x3D; defects[i,0]</span><br><span class="line">    start &#x3D; tuple(cnt[s][0])</span><br><span class="line">    end &#x3D; tuple(cnt[e][0])</span><br><span class="line">    far &#x3D; tuple(cnt[f][0])</span><br><span class="line">    cv.line(img,start,end,[0,255,0],2)</span><br><span class="line">    cv.circle(img,far,5,[0,0,255],-1)</span><br><span class="line">cv.imshow(&#39;img&#39;,img)</span><br><span class="line">cv.waitKey(0)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>查看结果：<br><img src="http://qiniu.aihubs.net/defects.jpg" alt></p><h3 id="2-点多边形测试"><a href="#2-点多边形测试" class="headerlink" title="2. 点多边形测试"></a>2. 点多边形测试</h3><p>这个函数找出图像中一点到轮廓线的最短距离。它返回的距离，点在轮廓线外时为负，点在轮廓线内时为正，点在轮廓线上时为零。</p><p>例如，我们可以检查点(50,50)如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist &#x3D; cv.pointPolygonTest(cnt,(50,50),True)</span><br></pre></td></tr></table></figure><p>在函数中，第三个参数是measureDist。如果它是真的，它会找到有符号的距离。如果为假，则查找该点是在轮廓线内部还是外部(分别返回+1、-1和0)。</p><p>注意 如果您不想找到距离，请确保第三个参数为False，因为这是一个耗时的过程。因此，将其设置为False可使速度提高2-3倍。</p><h3 id="3-形状匹配"><a href="#3-形状匹配" class="headerlink" title="3. 形状匹配"></a>3. 形状匹配</h3><p>OpenCV附带一个函数<strong>cv.matchShapes</strong>()，该函数使我们能够比较两个形状或两个轮廓，并返回一个显示相似性的度量。结果越低，匹配越好。它是根据矩值计算出来的。不同的测量方法在文档中有解释。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import cv2 as cv</span><br><span class="line">import numpy as np</span><br><span class="line">img1 &#x3D; cv.imread(&#39;star.jpg&#39;,0)</span><br><span class="line">img2 &#x3D; cv.imread(&#39;star2.jpg&#39;,0)</span><br><span class="line">ret, thresh &#x3D; cv.threshold(img1, 127, 255,0)</span><br><span class="line">ret, thresh2 &#x3D; cv.threshold(img2, 127, 255,0)</span><br><span class="line">contours,hierarchy &#x3D; cv.findContours(thresh,2,1)</span><br><span class="line">cnt1 &#x3D; contours[0]</span><br><span class="line">contours,hierarchy &#x3D; cv.findContours(thresh2,2,1)</span><br><span class="line">cnt2 &#x3D; contours[0]</span><br><span class="line">ret &#x3D; cv.matchShapes(cnt1,cnt2,1,0.0)</span><br><span class="line">print( ret )</span><br></pre></td></tr></table></figure><p>我尝试过匹配下面给出的不同形状的形状：<br><img src="http://qiniu.aihubs.net/matchshapes.jpg" alt></p><p>我得到以下结果: - 匹配的图像A与本身= 0.0 - 匹配图像A与图像B = 0.001946 - 匹配图像A与图像C = 0.326911</p><p>看,即使是图像旋转也不会对这个比较产生很大的影响。</p><p>参考 Hu矩是平移、旋转和比例不变的七个矩。第七个是无偏斜量。这些值可以使用<strong>cpu.HuMoments</strong>()函数找到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="轮廓分层"><a href="#轮廓分层" class="headerlink" title="轮廓分层"></a><span id="header5">轮廓分层</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><p>这次我们学习轮廓的层次，即轮廓中的父子关系。</p><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>在前几篇关于轮廓的文章中，我们已经讨论了与OpenCV提供的轮廓相关的几个函数。</p><p>但是当我们使用<strong>cv.findcontour</strong>()函数在图像中找到轮廓时，我们已经传递了一个参数，轮廓检索模式。</p><p>我们通常通过了<strong>cv.RETR_LIST</strong>或<strong>cv.RETR_TREE</strong>，效果很好。但这到底意味着什么呢?</p><p>另外，在输出中，我们得到了三个数组，第一个是图像，第二个是轮廓，还有一个我们命名为<strong>hierarchy</strong>的输出(请检查前面文章中的代码)。</p><p>但我们从未在任何地方使用过这种层次结构。那么这个层级是什么?它是用来做什么的?它与前面提到的函数参数有什么关系?</p><p>这就是我们在本文中要讨论的内容。</p><h2 id="层次结构是什么？"><a href="#层次结构是什么？" class="headerlink" title="层次结构是什么？"></a>层次结构是什么？</h2><p>通常我们使用<strong>cv.findcontour</strong>()函数来检测图像中的对象，对吧？</p><p>有时对象在不同的位置。但在某些情况下，某些形状在其他形状中。</p><p>就像嵌套的图形一样。在这种情况下，我们把外部的称为<strong>父类</strong>，把内部的称为<strong>子类</strong>。</p><p>这样，图像中的轮廓就有了一定的相互关系。</p><p>我们可以指定一个轮廓是如何相互连接的，比如，它是另一个轮廓的子轮廓，还是父轮廓等等。这种关系的表示称为<strong>层次结构</strong>。</p><p><img src="http://qiniu.aihubs.net/hierarchy.png" alt><br>在这张图中，有一些形状我已经从<strong>0-5</strong>开始编号。<em>2</em>和<em>2a</em>表示最外层盒子的外部和内部轮廓。</p><p>这里，等高线0,1,2在<strong>外部或最外面</strong>。我们可以说，它们在<strong>层级-0</strong>中，或者简单地说，它们在<strong>同一个层级</strong>中。</p><p>其次是<strong>contour-2a</strong>。它可以被认为是<strong>contour-2的子级</strong>(或者反过来，contour-2是contour-2a的父级)。</p><p>假设它在<strong>层级-1</strong>中。类似地，contour-3是contour-2的子级，它位于下一个层次结构中。</p><p>最后，轮廓4,5是contour-3a的子级，他们在最后一个层级。</p><p>从对方框的编号来看，我认为contour-4是contour-3a的第一个子级(它也可以是contour-5)。</p><p>我提到这些是为了理解一些术语，比如<strong>相同层级</strong>，外部轮廓，子轮廓，父轮廓，<strong>第一个子轮廓</strong>等等。现在让我们进入OpenCV。</p><h2 id="OpenCV中的分级表示"><a href="#OpenCV中的分级表示" class="headerlink" title="OpenCV中的分级表示"></a>OpenCV中的分级表示</h2><p>所以每个轮廓都有它自己的信息关于它是什么层次，谁是它的孩子，谁是它的父母等等。</p><p>OpenCV将它表示为一个包含四个值的数组:[Next, Previous, First_Child, Parent]</p><p>“Next表示同一层次的下一个轮廓。”</p><p>例如，在我们的图片中取contour-0。谁是下一个同级别的等高线?这是contour-1。</p><p>简单地令Next = 1。类似地，Contour-1也是contour-2。所以Next = 2。 contour-2呢?同一水平线上没有下一条等高线。</p><p>简单地，让Next = -1。contour-4呢?它与contour-5处于同一级别。它的下一条等高线是contour-5，所以next = 5。</p><p>“Previous表示同一层次上的先前轮廓。”</p><p>和上面一样。contour-1之前的等值线为同级别的contour-0。</p><p>类似地，contour-2也是contour-1。对于contour-0，没有前项，所以设为-1。</p><p>“First_Child表示它的第一个子轮廓。”</p><p>没有必要作任何解释。对于contour-2, child是contour-2a。从而得到contour-2a对应的指标值。</p><p>contour-3a呢?它有两个孩子。但我们只关注第一个孩子。它是contour-4。那么First_Child = 4 对contour-3a而言。</p><p>“Parent表示其父轮廓的索引。”</p><p>它与<strong>First_Child</strong>相反。对于轮廓线-4和轮廓线-5，父轮廓线都是轮廓线-3a。对于轮廓3a，它是轮廓-3，以此类推。</p><p>注意 如果没有子元素或父元素，则该字段被视为-1</p><p>现在我们已经了解了OpenCV中使用的层次样式，我们可以借助上面给出的相同图像来检查OpenCV中的轮廓检索模式。</p><p>一些标志如 cv.RETR_LIST, cv.RETR_TREE,cv.RETR_CCOMP, <strong>cv.RETR_EXTERNAL</strong>等等的含义。</p><h2 id="轮廓检索模式"><a href="#轮廓检索模式" class="headerlink" title="轮廓检索模式"></a>轮廓检索模式</h2><h3 id="1-RETR-LIST"><a href="#1-RETR-LIST" class="headerlink" title="1. RETR_LIST"></a>1. RETR_LIST</h3><p>这是四个标志中最简单的一个(从解释的角度来看)。它只是检索所有的轮廓，但不创建任何亲子关系。</p><p>在这个规则下，父轮廓和子轮廓是平等的，他们只是轮廓。他们都属于同一层级。</p><p>这里，第3和第4项总是-1。但是很明显，下一项和上一项都有对应的值。你自己检查一下就可以了。</p><p>下面是我得到的结果，每一行是对应轮廓的层次细节。例如，第一行对应于轮廓0。下一条轮廓是轮廓1。所以Next = 1。</p><p>没有先前的轮廓，所以Previous=-1。剩下的两个，如前所述，是-1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; hierarchy</span><br><span class="line">array([[[ 1, -1, -1, -1],</span><br><span class="line">        [ 2,  0, -1, -1],</span><br><span class="line">        [ 3,  1, -1, -1],</span><br><span class="line">        [ 4,  2, -1, -1],</span><br><span class="line">        [ 5,  3, -1, -1],</span><br><span class="line">        [ 6,  4, -1, -1],</span><br><span class="line">        [ 7,  5, -1, -1],</span><br><span class="line">        [-1,  6, -1, -1]]])</span><br></pre></td></tr></table></figure><p>如果您没有使用任何层次结构特性，那么这是在您的代码中使用的最佳选择。</p><h3 id="2-RETR-EXTERNAL"><a href="#2-RETR-EXTERNAL" class="headerlink" title="2. RETR_EXTERNAL"></a>2. RETR_EXTERNAL</h3><p>如果使用此标志，它只返回极端外部标志。所有孩子的轮廓都被留下了。</p><p>我们可以说，根据这项规则，每个家庭只有长子得到关注。它不关心家庭的其他成员:)。</p><p>所以在我们的图像中，有多少个极端的外轮廓?在等级0级?有3个，即等值线是0 1 2，对吧?</p><p>现在试着用这个标志找出等高线。这里，给每个元素的值与上面相同。并与上述结果进行了比较。以下是我得到的:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; hierarchy</span><br><span class="line">array([[[ 1, -1, -1, -1],</span><br><span class="line">        [ 2,  0, -1, -1],</span><br><span class="line">        [-1,  1, -1, -1]]])</span><br></pre></td></tr></table></figure><p>如果只想提取外部轮廓，可以使用此标志。它在某些情况下可能有用。</p><h3 id="3-RETR-CCOMP"><a href="#3-RETR-CCOMP" class="headerlink" title="3. RETR_CCOMP"></a>3. RETR_CCOMP</h3><p>此标志检索所有轮廓并将其排列为2级层次结构。物体的外部轮廓(即物体的边界)放在层次结构-1中。</p><p>对象内部孔洞的轮廓(如果有)放在层次结构-2中。如果其中有任何对象，则其轮廓仅在层次结构1中重新放置。以及它在层级2中的漏洞等等。</p><p>只需考虑在黑色背景上的“白色的零”图像。零的外圆属于第一级，零的内圆属于第二级。</p><p>我们可以用一个简单的图像来解释它。这里我用红色标注了等高线的顺序和它们所属的层次，用绿色标注(1或2)，顺序与OpenCV检测等高线的顺序相同。<br><img src="http://qiniu.aihubs.net/ccomp_hierarchy.png" alt><br>考虑第一个轮廓，即contour-0。这是hierarchy-1。它有两个孔，分别是等高线1和2，属于第二级。</p><p>因此，对于轮廓-0，在同一层次的下一个轮廓是轮廓-3。previous也没有。在hierarchy-2中，它的第一个子结点是contour-1。</p><p>它没有父类，因为它在hierarchy-1中。所以它的层次数组是[3，-1,1，-1]</p><p>现在contour-1。它在层级-2中。相同层次结构中的下一个(在contour-1的父母关系下)是contour-2。</p><p>没有previous。没有child，但是parent是contour-0。所以数组是[2，-1，-1,0]</p><p>类似的contour-2:它在hierarchy-2中。在contour-0下，同一层次结构中没有下一个轮廓。</p><p>所以没有Next。previous是contour-1。没有child，parent是contour0。所以数组是[-1,1，-1,0]</p><p>contour-3:层次-1的下一个是轮廓-5。以前是contour-0。child是contour4，没有parent。所以数组是[5,0,4，-1]</p><p>contour-4:它在contour-3下的层次结构2中，它没有兄弟姐妹。没有next，没有previous，没有child，parent是contour-3。</p><p>所以数组是[-1，-1，-1,3]</p><p>剩下的你可以补充。这是我得到的最终答案:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; hierarchy</span><br><span class="line">array([[[ 3, -1,  1, -1],</span><br><span class="line">        [ 2, -1, -1,  0],</span><br><span class="line">        [-1,  1, -1,  0],</span><br><span class="line">        [ 5,  0,  4, -1],</span><br><span class="line">        [-1, -1, -1,  3],</span><br><span class="line">        [ 7,  3,  6, -1],</span><br><span class="line">        [-1, -1, -1,  5],</span><br><span class="line">        [ 8,  5, -1, -1],</span><br><span class="line">        [-1,  7, -1, -1]]])</span><br></pre></td></tr></table></figure><h3 id="4-RETR-TREE"><a href="#4-RETR-TREE" class="headerlink" title="4. RETR_TREE"></a>4. RETR_TREE</h3><p>这是最后一个家伙，完美先生。它检索所有的轮廓并创建一个完整的家族层次结构列表。它甚至告诉，谁是爷爷，父亲，儿子，孙子，甚至更多…:)。</p><p>例如，我拿上面的图片，重写了cv的代码。RETR_TREE，根据OpenCV给出的结果重新排序等高线并进行分析。</p><p>同样，红色的字母表示轮廓数，绿色的字母表示层次顺序。<br><img src="http://qiniu.aihubs.net/tree_hierarchy.png" alt><br>取contour-0:它在hierarchy-0中。同一层次结构的next轮廓是轮廓-7。没有previous的轮廓。child是contour-1，没有parent。所以数组是[7，-1,1，-1]</p><p>以contour-2为例:它在hierarchy-1中。没有轮廓在同一水平。没有previous。child是contour-3。父母是contour-1。所以数组是[-1，-1,3,1]</p><p>剩下的，你自己试试。以下是完整答案:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; hierarchy</span><br><span class="line">array([[[ 7, -1,  1, -1],</span><br><span class="line">        [-1, -1,  2,  0],</span><br><span class="line">        [-1, -1,  3,  1],</span><br><span class="line">        [-1, -1,  4,  2],</span><br><span class="line">        [-1, -1,  5,  3],</span><br><span class="line">        [ 6, -1, -1,  4],</span><br><span class="line">        [-1,  5, -1,  4],</span><br><span class="line">        [ 8,  0, -1, -1],</span><br><span class="line">        [-1,  7, -1, -1]]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;9.1.&lt;a href=&quot;#header1&quot;&gt;轮廓入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.2.&lt;a href=&quot;#header2&quot;&gt;轮廓特征&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.3.&lt;a href=&quot;#header3&quot;&gt;轮廓属性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.4.&lt;a href=&quot;#header4&quot;&gt;轮廓更多属性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;9.5.&lt;a href=&quot;#header5&quot;&gt;轮廓分层&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv中的图像处理2</title>
    <link href="http://yoursite.com/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%862/"/>
    <id>http://yoursite.com/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%862/</id>
    <published>2020-07-13T02:11:43.000Z</published>
    <updated>2020-07-13T02:16:51.763Z</updated>
    
    <content type="html"><![CDATA[<ul><li>5.<a href="#header1">形态转换</a></li><li>6.<a href="#header2">图像梯度</a></li><li>7.<a href="#header3">Canny边缘检测</a></li><li>8.<a href="#header4">图像金字塔</a><a id="more"></a></li></ul><h1 id="形态学转换"><a href="#形态学转换" class="headerlink" title="形态学转换"></a><span id="header1">形态学转换</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>在这一章当中， 我们将学习不同的形态学操作，例如侵蚀，膨胀，开运算，闭运算等。<br>我们将看到不同的功能，</p><p>例如：cv.erode(),cv.dilate(), cv.morphologyEx()等。</p><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>形态变换是一些基于图像形状的简单操作。通常在二进制图像上执行。</p><p>它需要两个输入，一个是我们的原始图像，第二个是决定<strong>操作性质的结构元素</strong>或<strong>内核</strong>。</p><p>两种基本的形态学算子是侵蚀和膨胀。</p><p>然后，它的变体形式（如“打开”，“关闭”，“渐变”等）也开始起作用。在下图的帮助下，我们将一一看到它们：</p><h2 id="1-侵蚀"><a href="#1-侵蚀" class="headerlink" title="1. 侵蚀"></a>1. 侵蚀</h2><p>侵蚀的基本思想就像土壤侵蚀一样，它侵蚀前景物体的边界(尽量使前景保持白色)。</p><p>它是做什么的呢?内核滑动通过图像(在2D卷积中)。</p><p>原始图像中的一个像素(无论是1还是0)只有当内核下的所有像素都是1时才被认为是1，否则它就会被侵蚀(变成0)。</p><p>结果是，根据内核的大小，边界附近的所有像素都会被丢弃。</p><p>因此，前景物体的厚度或大小减小，或只是图像中的白色区域减小。</p><p>它有助于去除小的白色噪声(正如我们在颜色空间章节中看到的)，分离两个连接的对象等。</p><p>在这里，作为一个例子，我将使用一个5x5内核，它包含了所有的1。</p><h2 id="2-扩张"><a href="#2-扩张" class="headerlink" title="2. 扩张"></a>2. 扩张</h2><p>它与侵蚀正好相反。如果内核下的至少一个像素为“ 1”，则像素元素为“ 1”。</p><p>因此，它会增加图像中的白色区域或增加前景对象的大小。</p><p>通常，在消除噪音的情况下，腐蚀后会膨胀。因为腐蚀会消除白噪声，但也会缩小物体。</p><p>因此，我们对其进行了扩展。由于噪音消失了，它们不会回来，但是我们的目标区域增加了。在连接对象的损坏部分时也很有用。</p><h2 id="3-开运算"><a href="#3-开运算" class="headerlink" title="3. 开运算"></a>3. 开运算</h2><p>开放只是<strong>侵蚀然后扩张</strong>的另一个名称。</p><p>如上文所述，它对于消除噪音很有用。在这里，我们使用函数<strong>cv.morphologyEx</strong>()</p><h2 id="4-闭运算"><a href="#4-闭运算" class="headerlink" title="4. 闭运算"></a>4. 闭运算</h2><p>闭运算与开运算相反，先扩张然后再侵蚀。</p><p>在关闭前景对象内部的小孔或对象上的小黑点时很有用。</p><h2 id="5-形态学梯度"><a href="#5-形态学梯度" class="headerlink" title="5. 形态学梯度"></a>5. 形态学梯度</h2><p>这是图像扩张和侵蚀之间的区别。</p><p>结果将看起来像对象的轮廓。</p><h2 id="6-顶帽"><a href="#6-顶帽" class="headerlink" title="6. 顶帽"></a>6. 顶帽</h2><p>它是输入图像和图像开运算之差。下面的示例针对9x9内核完成。</p><h2 id="7-黑帽"><a href="#7-黑帽" class="headerlink" title="7. 黑帽"></a>7. 黑帽</h2><p>这是输入图像和图像闭运算之差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl </span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'FangSong'</span>] <span class="comment"># 指定默认字体 </span></span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span> <span class="comment"># 解决保存图像是负号'-'显示为方块的问题</span></span><br><span class="line">img = cv.imread(<span class="string">'j.png'</span>,<span class="number">0</span>)</span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>),np.uint8)</span><br><span class="line">erosion = cv.erode(img,kernel,iterations = <span class="number">1</span>)</span><br><span class="line">dilation = cv.dilate(img,kernel,iterations = <span class="number">1</span>) </span><br><span class="line">opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel) </span><br><span class="line">closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel) </span><br><span class="line">gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel) </span><br><span class="line">tophat = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel) </span><br><span class="line">blackhat = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel) </span><br><span class="line">imgs = [img,erosion,dilation,opening,closing,gradient,tophat,blackhat]</span><br><span class="line">titles = [<span class="string">'原图'</span>,<span class="string">'侵蚀'</span>,<span class="string">'膨胀'</span>,<span class="string">'开运算'</span>,<span class="string">'闭运算'</span>,<span class="string">'形态学梯度'</span>,<span class="string">'顶帽'</span>,<span class="string">'黑帽'</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(imgs)):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">4</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(imgs[i])</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%862/output_9_0.png" alt="png"></p><h2 id="结构元素"><a href="#结构元素" class="headerlink" title="结构元素"></a>结构元素</h2><p>在Numpy的帮助下，我们在前面的示例中手动创建了一个结构元素。</p><p>它是矩形。但是在某些情况下，您可能需要椭圆形/圆形的内核。</p><p>因此，为此，OpenCV具有一个函数<strong>cv.getStructuringElement</strong>()。</p><p>您只需传递内核的形状和大小，即可获得所需的内核</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩形</span></span><br><span class="line">cv.getStructuringElement(cv.MORPH_RECT,(<span class="number">5</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>array([[1, 1, 1, 1, 1],       [1, 1, 1, 1, 1],       [1, 1, 1, 1, 1],       [1, 1, 1, 1, 1],       [1, 1, 1, 1, 1]], dtype=uint8)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 椭圆内核</span></span><br><span class="line">cv.getStructuringElement(cv.MORPH_ELLIPSE,(<span class="number">5</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>array([[0, 0, 1, 0, 0],       [1, 1, 1, 1, 1],       [1, 1, 1, 1, 1],       [1, 1, 1, 1, 1],       [0, 0, 1, 0, 0]], dtype=uint8)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 十字内核</span></span><br><span class="line">cv.getStructuringElement(cv.MORPH_CROSS,(<span class="number">5</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>array([[0, 0, 1, 0, 0],       [0, 0, 1, 0, 0],       [1, 1, 1, 1, 1],       [0, 0, 1, 0, 0],       [0, 0, 1, 0, 0]], dtype=uint8)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="图像梯度"><a href="#图像梯度" class="headerlink" title="图像梯度"></a><span id="header2">图像梯度</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>在本章中，我们将学习： - 查找图像梯度，边缘等 - </p><p>我们将看到以下函数：cv.Sobel()，cv.Scharr()，cv.Laplacian()等</p><h2 id="理论-1"><a href="#理论-1" class="headerlink" title="理论"></a>理论</h2><p>OpenCV提供三种类型的梯度滤波器或高通滤波器，即Sobel，Scharr和Laplacian。我们将看到他们每一种。</p><h2 id="1-Sobel-和-Scharr-算子"><a href="#1-Sobel-和-Scharr-算子" class="headerlink" title="1. Sobel 和 Scharr 算子"></a>1. Sobel 和 Scharr 算子</h2><p>Sobel算子是高斯平滑加微分运算的联合运算，因此它更抗噪声。逆可以指定要采用的导数方向，垂直或水平（分别通过参数yorder和xorder）。逆还可以通过参数ksize指定内核的大小。如果ksize = -1，则使用3x3 Scharr滤波器，比3x3 Sobel滤波器具有更好的结果。请参阅文档以了解所使用的内核。</p><h2 id="2-Laplacian-算子"><a href="#2-Laplacian-算子" class="headerlink" title="2. Laplacian 算子"></a>2. Laplacian 算子</h2><p>它计算了由关系Δsrc=$\frac{\delta^2 src}{\delta x^2}+\frac{\delta^2 src}{\delta y^2}$给出的图像的拉普拉斯图,它是每一阶导数通过Sobel算子计算。如果ksize = 1,然后使用以下内核用于过滤:</p><p>kernel=$$<br> \left[<br> \begin{matrix}<br>   0 &amp; 1 &amp; 0 \<br>   1 &amp; -4 &amp; 1 \<br>   0 &amp; 1 &amp; 0<br>  \end{matrix}<br>  \right] <br>$$<br>代码<br>下面的代码显示了单个图表中的所有算子。所有内核都是5x5大小。输出图像的深度通过-1得到结果的np.uint8型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'dave.png'</span>,<span class="number">0</span>)</span><br><span class="line">laplacian = cv.Laplacian(img,cv.CV_64F)</span><br><span class="line">sobelx = cv.Sobel(img,cv.CV_64F,<span class="number">1</span>,<span class="number">0</span>,ksize=<span class="number">5</span>)</span><br><span class="line">sobely = cv.Sobel(img,cv.CV_64F,<span class="number">0</span>,<span class="number">1</span>,ksize=<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Original'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>),plt.imshow(laplacian,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Laplacian'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>),plt.imshow(sobelx,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Sobel X'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>),plt.imshow(sobely,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Sobel Y'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%862/output_1_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Canny边缘检测"><a href="#Canny边缘检测" class="headerlink" title="Canny边缘检测"></a><span id="header3">Canny边缘检测</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><p>在本章中，我们将学习 - Canny边缘检测的概念 - OpenCV函数: cv.Canny()</p><h2 id="理论-2"><a href="#理论-2" class="headerlink" title="理论"></a>理论</h2><p>Canny Edge Detection是一种流行的边缘检测算法。它由John F. Canny发明</p><p>这是一个多阶段算法，我们将经历每个阶段。</p><h2 id="降噪"><a href="#降噪" class="headerlink" title="降噪"></a>降噪</h2><p>由于边缘检测容易受到图像中噪声的影响，因此第一步是使用5x5高斯滤波器消除图像中的噪声。我们已经在前面的章节中看到了这一点。</p><p>查找图像的强度梯度<br>然后使用Sobel核在水平和垂直方向上对平滑的图像进行滤波，以在水平方向(Gx)和垂直方向(Gy)上获得一阶导数。从这两张图片中，我们可以找到每个像素的边缘渐变和方向，如下所示：</p><p>$$<br>Edge_Gradient ; (G) = \sqrt{G_x^2 + G_y^2} \ Angle ; (\theta) = \tan^{-1} \bigg(\frac{G_y}{G_x}\bigg)<br>$$<br>渐变方向始终垂直于边缘。将其舍入为代表垂直，水平和两个对角线方向的四个角度之一。</p><p>非极大值抑制 在获得梯度大小和方向后，将对图像进行全面扫描，以去除可能不构成边缘的所有不需要的像素。</p><p>为此，在每个像素处，检查像素是否是其在梯度方向上附近的局部最大值。查看下面的图片：<br><img src="http://qiniu.aihubs.net/nms.jpg" alt></p><p>点A在边缘（垂直方向）上。渐变方向垂直于边缘。点B和C在梯度方向上。因此，将A点与B点和C点进行检查，看是否形成局部最大值。如果是这样，则考虑将其用于下一阶段，否则将其抑制（置为零）。 简而言之，你得到的结果是带有“细边”的二进制图像。</p><h2 id="磁滞阈值"><a href="#磁滞阈值" class="headerlink" title="磁滞阈值"></a>磁滞阈值</h2><p>该阶段确定哪些边缘全部是真正的边缘，哪些不是。为此，我们需要两个阈值minVal和maxVal。强度梯度大于maxVal的任何边缘必定是边缘，而小于minVal的那些边缘必定是非边缘，因此将其丢弃。介于这两个阈值之间的对象根据其连通性被分类为边缘或非边缘。如果将它们连接到“边缘”像素，则将它们视为边缘的一部分。否则，它们也将被丢弃。见下图：</p><p><img src="http://qiniu.aihubs.net/hysteresis.jpg" alt><br>边缘A在maxVal之上，因此被视为“确定边缘”。尽管边C低于maxVal，但它连接到边A，因此也被视为有效边，我们得到了完整的曲线。但是边缘B尽管在minVal之上并且与边缘C处于同一区域，但是它没有连接到任何“确保边缘”，因此被丢弃。因此，非常重要的一点是我们必须相应地选择minVal和maxVal以获得正确的结果。</p><p>在边缘为长线的假设下，该阶段还消除了小像素噪声。</p><p>因此，我们最终得到的是图像中的强边缘。</p><h2 id="OpenCV中的Canny-Edge检测"><a href="#OpenCV中的Canny-Edge检测" class="headerlink" title="OpenCV中的Canny Edge检测"></a>OpenCV中的Canny Edge检测</h2><p>OpenCV将以上所有内容放在单个函数<strong>cv.Canny</strong>()中。我们将看到如何使用它。</p><p>第一个参数是我们的输入图像。</p><p>第二个和第三个参数分别是我们的minVal和maxVal。</p><p>第三个参数是perture_size。它是用于查找图像渐变的Sobel内核的大小。默认情况下为3。</p><p>最后一个参数是L2gradient，它指定用于查找梯度幅度的方程式。</p><p>如果为True，则使用上面提到的更精确的公式，否则使用以下函数：Edge_Gradient(G)=|Gx|+|Gy|。默认情况下，它为False。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">edges = cv.Canny(img,<span class="number">100</span>,<span class="number">200</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Original Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(edges,cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'Edge Image'</span>), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/13/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%862/output_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a><span id="header4">图像金字塔</span></h1><h1 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h1><p>在本章中， - 我们将学习图像金字塔 - 我们将使用图像金字塔创建一个新的水果“Orapple” - </p><p>我们将看到以下功能：cv.pyrUp()，cv.pyrDown()</p><h2 id="理论-3"><a href="#理论-3" class="headerlink" title="理论"></a>理论</h2><p>通常，我们过去使用的是恒定大小的图像。但是在某些情况下，我们需要使用不同分辨率的（相同）图像。</p><p>例如，当在图像中搜索某些东西（例如人脸）时，我们不确定对象将以多大的尺寸显示在图像中。</p><p>在这种情况下，我们将需要创建一组具有不同分辨率的相同图像，并在所有图像中搜索对象。</p><p>这些具有不同分辨率的图像集称为“图像金字塔”（因为当它们堆叠在底部时，最高分辨率的图像位于底部，最低分辨率的图像位于顶部时，看起来像金字塔）。</p><p>有两种图像金字塔。1）高斯金字塔<strong>和2）</strong>拉普拉斯金字塔</p><p>高斯金字塔中的较高级别（低分辨率）是通过删除较低级别（较高分辨率）图像中的连续行和列而形成的。</p><p>然后，较高级别的每个像素由基础级别的5个像素的贡献与高斯权重形成。</p><p>通过这样做，M×N图像变成M/2×N/2图像。因此面积减少到原始面积的四分之一。</p><p>它称为Octave。当我们在金字塔中越靠上时（即分辨率下降），这种模式就会继续。</p><p>同样，在扩展时，每个级别的面积变为4倍。</p><p>我们可以使用<strong>cv.pyrDown</strong>()和<strong>cv.pyrUp</strong>()函数找到高斯金字塔</p><p>以下是图像金字塔中的4个级别。<br><img src="http://qiniu.aihubs.net/messipyr.jpg" alt><br>现在，您可以使用<strong>cv.pyrUp</strong>()函数查看图像金字塔。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">higher_reso2 &#x3D; cv.pyrUp(lower_reso)</span><br></pre></td></tr></table></figure><p>记住，higher_reso2不等于higher_reso，因为一旦降低了分辨率，就会丢失信息。下面的图像是3层的金字塔从最小的图像在前面的情况下创建。与原图对比:<br><img src="http://qiniu.aihubs.net/messiup.jpg" alt></p><p>拉普拉斯金字塔由高斯金字塔形成。没有专用功能。</p><p>拉普拉斯金字塔图像仅像边缘图像。它的大多数元素为零。它们用于图像压缩。</p><p>拉普拉斯金字塔的层由高斯金字塔的层与高斯金字塔的高层的扩展版本之间的差形成。</p><p>拉普拉斯等级的三个等级如下所示（调整对比度以增强内容）：<br><img src="http://qiniu.aihubs.net/lap.jpg" alt></p><h2 id="使用金字塔进行图像融合"><a href="#使用金字塔进行图像融合" class="headerlink" title="使用金字塔进行图像融合"></a>使用金字塔进行图像融合</h2><p>金字塔的一种应用是图像融合。</p><p>例如，在图像拼接中，您需要将两个图像堆叠在一起，但是由于图像之间的不连续性，可能看起来不太好。</p><p>在这种情况下，使用金字塔混合图像可以无缝混合，而不会在图像中保留大量数据。</p><p>一个经典的例子是将两种水果，橙和苹果混合在一起</p><p>只需完成以下步骤即可：</p><ul><li>加载苹果和橙子的两个图像</li><li>查找苹果和橙子的高斯金字塔（在此示例中， 级别数为6）</li><li>在高斯金字塔中，找到其拉普拉斯金字塔</li><li>然后在每个拉普拉斯金字塔级别中加入苹果的左半部分和橙子的右半部分</li><li>最后从此联合图像金字塔中重建原始图像。<br><img src="http://qiniu.aihubs.net/orapple.jpg" alt></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np,sys</span><br><span class="line">A = cv.imread(<span class="string">'apple.png'</span>)</span><br><span class="line">B = cv.imread(<span class="string">'orange.png'</span>)</span><br><span class="line"><span class="comment"># 生成A的高斯金字塔</span></span><br><span class="line">G = A.copy()</span><br><span class="line">gpA = [G]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    G = cv.pyrDown(G)</span><br><span class="line">    gpA.append(G)</span><br><span class="line"><span class="comment"># 生成B的高斯金字塔</span></span><br><span class="line">G = B.copy()</span><br><span class="line">gpB = [G]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    G = cv.pyrDown(G)</span><br><span class="line">    gpB.append(G)</span><br><span class="line"><span class="comment"># 生成A的拉普拉斯金字塔</span></span><br><span class="line">lpA = [gpA[<span class="number">5</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>,<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">    GE = cv.pyrUp(gpA[i])</span><br><span class="line">    L = cv.subtract(gpA[i<span class="number">-1</span>],GE)</span><br><span class="line">    lpA.append(L)</span><br><span class="line"><span class="comment"># 生成B的拉普拉斯金字塔</span></span><br><span class="line">lpB = [gpB[<span class="number">5</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>,<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">    GE = cv.pyrUp(gpB[i])</span><br><span class="line">    L = cv.subtract(gpB[i<span class="number">-1</span>],GE)</span><br><span class="line">    lpB.append(L)</span><br><span class="line"><span class="comment"># 现在在每个级别中添加左右两半图像 </span></span><br><span class="line">LS = []</span><br><span class="line"><span class="keyword">for</span> la,lb <span class="keyword">in</span> zip(lpA,lpB):</span><br><span class="line">    rows,cols,dpt = la.shape</span><br><span class="line">    ls = np.hstack((la[:,<span class="number">0</span>:cols/<span class="number">2</span>], lb[:,cols/<span class="number">2</span>:]))</span><br><span class="line">    LS.append(ls)</span><br><span class="line"><span class="comment"># 现在重建</span></span><br><span class="line">ls_ = LS[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    ls_ = cv.pyrUp(ls_)</span><br><span class="line">    ls_ = cv.add(ls_, LS[i])</span><br><span class="line"><span class="comment"># 图像与直接连接的每一半</span></span><br><span class="line">real = np.hstack((A[:,:cols/<span class="number">2</span>],B[:,cols/<span class="number">2</span>:]))</span><br><span class="line">cv.imwrite(<span class="string">'Pyramid_blending2.jpg'</span>,ls_)</span><br><span class="line">cv.imwrite(<span class="string">'Direct_blending.jpg'</span>,real)</span><br><span class="line"><span class="comment">##</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;5.&lt;a href=&quot;#header1&quot;&gt;形态转换&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;6.&lt;a href=&quot;#header2&quot;&gt;图像梯度&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;7.&lt;a href=&quot;#header3&quot;&gt;Canny边缘检测&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8.&lt;a href=&quot;#header4&quot;&gt;图像金字塔&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv中的图像处理1</title>
    <link href="http://yoursite.com/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/"/>
    <id>http://yoursite.com/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/</id>
    <published>2020-07-12T13:11:51.000Z</published>
    <updated>2020-07-12T13:18:26.333Z</updated>
    
    <content type="html"><![CDATA[<ul><li>1.<a href="#header1">改变颜色空间</a></li><li>2.<a href="#header2">图像几何变换</a></li><li>3.<a href="#header3">图像阈值</a></li><li>4.<a href="#header4">图像平滑</a><a id="more"></a></li></ul><h1 id="改变颜色空间"><a href="#改变颜色空间" class="headerlink" title="改变颜色空间"></a><span id="header1">改变颜色空间</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul><li>在本教程中，你将学习如何将图像从一个色彩空间转换到另一个，像BGR↔灰色，BGR↔HSV等</li><li>除此之外，我们还将创建一个应用程序，以提取视频中的彩色对象</li><li>你将学习以下功能：cv.cvtColor，<strong>cv.inRange</strong>等。</li></ul><h2 id="改变颜色空间-1"><a href="#改变颜色空间-1" class="headerlink" title="改变颜色空间"></a>改变颜色空间</h2><p>OpenCV中有超过150种颜色空间转换方法。但是我们将研究只有两个最广泛使用的,BGR↔灰色和BGR↔HSV。</p><p>对于颜色转换，我们使用cv函数。cvtColor(input_image, flag)，其中flag决定转换的类型。</p><p>对于BGR→灰度转换，我们使用标志cv.COLOR_BGR2GRAY。类似地，对于BGR→HSV，我们使用标志cv.COLOR_BGR2HSV。</p><p>要获取其他标记，只需在Python终端中运行以下命令</p><p>注意 HSV的色相范围为[0,179]，饱和度范围为[0,255]，值范围为[0,255]。不同的软件使用不同的规模。</p><p>因此，如果你要将OpenCV值和它们比较，你需要将这些范围标准化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">flags = [i <span class="keyword">for</span> i <span class="keyword">in</span> dir(cv) <span class="keyword">if</span> i.startswith(<span class="string">'COLOR_'</span>)]</span><br><span class="line">flags</span><br></pre></td></tr></table></figure><pre><code>[&apos;COLOR_BAYER_BG2BGR&apos;, &apos;COLOR_BAYER_BG2BGRA&apos;, &apos;COLOR_BAYER_BG2BGR_EA&apos;, &apos;COLOR_BAYER_BG2BGR_VNG&apos;, &apos;COLOR_BAYER_BG2GRAY&apos;, &apos;COLOR_BAYER_BG2RGB&apos;, &apos;COLOR_BAYER_BG2RGBA&apos;, &apos;COLOR_BAYER_BG2RGB_EA&apos;, &apos;COLOR_BAYER_BG2RGB_VNG&apos;, &apos;COLOR_BAYER_GB2BGR&apos;, &apos;COLOR_BAYER_GB2BGRA&apos;, &apos;COLOR_BAYER_GB2BGR_EA&apos;, &apos;COLOR_BAYER_GB2BGR_VNG&apos;, &apos;COLOR_BAYER_GB2GRAY&apos;, &apos;COLOR_BAYER_GB2RGB&apos;, &apos;COLOR_BAYER_GB2RGBA&apos;, &apos;COLOR_BAYER_GB2RGB_EA&apos;, &apos;COLOR_BAYER_GB2RGB_VNG&apos;, &apos;COLOR_BAYER_GR2BGR&apos;, &apos;COLOR_BAYER_GR2BGRA&apos;, &apos;COLOR_BAYER_GR2BGR_EA&apos;, &apos;COLOR_BAYER_GR2BGR_VNG&apos;, &apos;COLOR_BAYER_GR2GRAY&apos;, &apos;COLOR_BAYER_GR2RGB&apos;, &apos;COLOR_BAYER_GR2RGBA&apos;, &apos;COLOR_BAYER_GR2RGB_EA&apos;, &apos;COLOR_BAYER_GR2RGB_VNG&apos;, &apos;COLOR_BAYER_RG2BGR&apos;, &apos;COLOR_BAYER_RG2BGRA&apos;, &apos;COLOR_BAYER_RG2BGR_EA&apos;, &apos;COLOR_BAYER_RG2BGR_VNG&apos;, &apos;COLOR_BAYER_RG2GRAY&apos;, &apos;COLOR_BAYER_RG2RGB&apos;, &apos;COLOR_BAYER_RG2RGBA&apos;, &apos;COLOR_BAYER_RG2RGB_EA&apos;, &apos;COLOR_BAYER_RG2RGB_VNG&apos;, &apos;COLOR_BGR2BGR555&apos;, &apos;COLOR_BGR2BGR565&apos;, &apos;COLOR_BGR2BGRA&apos;, &apos;COLOR_BGR2GRAY&apos;, &apos;COLOR_BGR2HLS&apos;, &apos;COLOR_BGR2HLS_FULL&apos;, &apos;COLOR_BGR2HSV&apos;, &apos;COLOR_BGR2HSV_FULL&apos;, &apos;COLOR_BGR2LAB&apos;, &apos;COLOR_BGR2LUV&apos;, &apos;COLOR_BGR2Lab&apos;, &apos;COLOR_BGR2Luv&apos;, &apos;COLOR_BGR2RGB&apos;, &apos;COLOR_BGR2RGBA&apos;, &apos;COLOR_BGR2XYZ&apos;, &apos;COLOR_BGR2YCR_CB&apos;, &apos;COLOR_BGR2YCrCb&apos;, &apos;COLOR_BGR2YUV&apos;, &apos;COLOR_BGR2YUV_I420&apos;, &apos;COLOR_BGR2YUV_IYUV&apos;, &apos;COLOR_BGR2YUV_YV12&apos;, &apos;COLOR_BGR5552BGR&apos;, &apos;COLOR_BGR5552BGRA&apos;, &apos;COLOR_BGR5552GRAY&apos;, &apos;COLOR_BGR5552RGB&apos;, &apos;COLOR_BGR5552RGBA&apos;, &apos;COLOR_BGR5652BGR&apos;, &apos;COLOR_BGR5652BGRA&apos;, &apos;COLOR_BGR5652GRAY&apos;, &apos;COLOR_BGR5652RGB&apos;, &apos;COLOR_BGR5652RGBA&apos;, &apos;COLOR_BGRA2BGR&apos;, &apos;COLOR_BGRA2BGR555&apos;, &apos;COLOR_BGRA2BGR565&apos;, &apos;COLOR_BGRA2GRAY&apos;, &apos;COLOR_BGRA2RGB&apos;, &apos;COLOR_BGRA2RGBA&apos;, &apos;COLOR_BGRA2YUV_I420&apos;, &apos;COLOR_BGRA2YUV_IYUV&apos;, &apos;COLOR_BGRA2YUV_YV12&apos;, &apos;COLOR_BayerBG2BGR&apos;, &apos;COLOR_BayerBG2BGRA&apos;, &apos;COLOR_BayerBG2BGR_EA&apos;, &apos;COLOR_BayerBG2BGR_VNG&apos;, &apos;COLOR_BayerBG2GRAY&apos;, &apos;COLOR_BayerBG2RGB&apos;, &apos;COLOR_BayerBG2RGBA&apos;, &apos;COLOR_BayerBG2RGB_EA&apos;, &apos;COLOR_BayerBG2RGB_VNG&apos;, &apos;COLOR_BayerGB2BGR&apos;, &apos;COLOR_BayerGB2BGRA&apos;, &apos;COLOR_BayerGB2BGR_EA&apos;, &apos;COLOR_BayerGB2BGR_VNG&apos;, &apos;COLOR_BayerGB2GRAY&apos;, &apos;COLOR_BayerGB2RGB&apos;, &apos;COLOR_BayerGB2RGBA&apos;, &apos;COLOR_BayerGB2RGB_EA&apos;, &apos;COLOR_BayerGB2RGB_VNG&apos;, &apos;COLOR_BayerGR2BGR&apos;, &apos;COLOR_BayerGR2BGRA&apos;, &apos;COLOR_BayerGR2BGR_EA&apos;, &apos;COLOR_BayerGR2BGR_VNG&apos;, &apos;COLOR_BayerGR2GRAY&apos;, &apos;COLOR_BayerGR2RGB&apos;, &apos;COLOR_BayerGR2RGBA&apos;, &apos;COLOR_BayerGR2RGB_EA&apos;, &apos;COLOR_BayerGR2RGB_VNG&apos;, &apos;COLOR_BayerRG2BGR&apos;, &apos;COLOR_BayerRG2BGRA&apos;, &apos;COLOR_BayerRG2BGR_EA&apos;, &apos;COLOR_BayerRG2BGR_VNG&apos;, &apos;COLOR_BayerRG2GRAY&apos;, &apos;COLOR_BayerRG2RGB&apos;, &apos;COLOR_BayerRG2RGBA&apos;, &apos;COLOR_BayerRG2RGB_EA&apos;, &apos;COLOR_BayerRG2RGB_VNG&apos;, &apos;COLOR_COLORCVT_MAX&apos;, &apos;COLOR_GRAY2BGR&apos;, &apos;COLOR_GRAY2BGR555&apos;, &apos;COLOR_GRAY2BGR565&apos;, &apos;COLOR_GRAY2BGRA&apos;, &apos;COLOR_GRAY2RGB&apos;, &apos;COLOR_GRAY2RGBA&apos;, &apos;COLOR_HLS2BGR&apos;, &apos;COLOR_HLS2BGR_FULL&apos;, &apos;COLOR_HLS2RGB&apos;, &apos;COLOR_HLS2RGB_FULL&apos;, &apos;COLOR_HSV2BGR&apos;, &apos;COLOR_HSV2BGR_FULL&apos;, &apos;COLOR_HSV2RGB&apos;, &apos;COLOR_HSV2RGB_FULL&apos;, &apos;COLOR_LAB2BGR&apos;, &apos;COLOR_LAB2LBGR&apos;, &apos;COLOR_LAB2LRGB&apos;, &apos;COLOR_LAB2RGB&apos;, &apos;COLOR_LBGR2LAB&apos;, &apos;COLOR_LBGR2LUV&apos;, &apos;COLOR_LBGR2Lab&apos;, &apos;COLOR_LBGR2Luv&apos;, &apos;COLOR_LRGB2LAB&apos;, &apos;COLOR_LRGB2LUV&apos;, &apos;COLOR_LRGB2Lab&apos;, &apos;COLOR_LRGB2Luv&apos;, &apos;COLOR_LUV2BGR&apos;, &apos;COLOR_LUV2LBGR&apos;, &apos;COLOR_LUV2LRGB&apos;, &apos;COLOR_LUV2RGB&apos;, &apos;COLOR_Lab2BGR&apos;, &apos;COLOR_Lab2LBGR&apos;, &apos;COLOR_Lab2LRGB&apos;, &apos;COLOR_Lab2RGB&apos;, &apos;COLOR_Luv2BGR&apos;, &apos;COLOR_Luv2LBGR&apos;, &apos;COLOR_Luv2LRGB&apos;, &apos;COLOR_Luv2RGB&apos;, &apos;COLOR_M_RGBA2RGBA&apos;, &apos;COLOR_RGB2BGR&apos;, &apos;COLOR_RGB2BGR555&apos;, &apos;COLOR_RGB2BGR565&apos;, &apos;COLOR_RGB2BGRA&apos;, &apos;COLOR_RGB2GRAY&apos;, &apos;COLOR_RGB2HLS&apos;, &apos;COLOR_RGB2HLS_FULL&apos;, &apos;COLOR_RGB2HSV&apos;, &apos;COLOR_RGB2HSV_FULL&apos;, &apos;COLOR_RGB2LAB&apos;, &apos;COLOR_RGB2LUV&apos;, &apos;COLOR_RGB2Lab&apos;, &apos;COLOR_RGB2Luv&apos;, &apos;COLOR_RGB2RGBA&apos;, &apos;COLOR_RGB2XYZ&apos;, &apos;COLOR_RGB2YCR_CB&apos;, &apos;COLOR_RGB2YCrCb&apos;, &apos;COLOR_RGB2YUV&apos;, &apos;COLOR_RGB2YUV_I420&apos;, &apos;COLOR_RGB2YUV_IYUV&apos;, &apos;COLOR_RGB2YUV_YV12&apos;, &apos;COLOR_RGBA2BGR&apos;, &apos;COLOR_RGBA2BGR555&apos;, &apos;COLOR_RGBA2BGR565&apos;, &apos;COLOR_RGBA2BGRA&apos;, &apos;COLOR_RGBA2GRAY&apos;, &apos;COLOR_RGBA2M_RGBA&apos;, &apos;COLOR_RGBA2RGB&apos;, &apos;COLOR_RGBA2YUV_I420&apos;, &apos;COLOR_RGBA2YUV_IYUV&apos;, &apos;COLOR_RGBA2YUV_YV12&apos;, &apos;COLOR_RGBA2mRGBA&apos;, &apos;COLOR_XYZ2BGR&apos;, &apos;COLOR_XYZ2RGB&apos;, &apos;COLOR_YCR_CB2BGR&apos;, &apos;COLOR_YCR_CB2RGB&apos;, &apos;COLOR_YCrCb2BGR&apos;, &apos;COLOR_YCrCb2RGB&apos;, &apos;COLOR_YUV2BGR&apos;, &apos;COLOR_YUV2BGRA_I420&apos;, &apos;COLOR_YUV2BGRA_IYUV&apos;, &apos;COLOR_YUV2BGRA_NV12&apos;, &apos;COLOR_YUV2BGRA_NV21&apos;, &apos;COLOR_YUV2BGRA_UYNV&apos;, &apos;COLOR_YUV2BGRA_UYVY&apos;, &apos;COLOR_YUV2BGRA_Y422&apos;, &apos;COLOR_YUV2BGRA_YUNV&apos;, &apos;COLOR_YUV2BGRA_YUY2&apos;, &apos;COLOR_YUV2BGRA_YUYV&apos;, &apos;COLOR_YUV2BGRA_YV12&apos;, &apos;COLOR_YUV2BGRA_YVYU&apos;, &apos;COLOR_YUV2BGR_I420&apos;, &apos;COLOR_YUV2BGR_IYUV&apos;, &apos;COLOR_YUV2BGR_NV12&apos;, &apos;COLOR_YUV2BGR_NV21&apos;, &apos;COLOR_YUV2BGR_UYNV&apos;, &apos;COLOR_YUV2BGR_UYVY&apos;, &apos;COLOR_YUV2BGR_Y422&apos;, &apos;COLOR_YUV2BGR_YUNV&apos;, &apos;COLOR_YUV2BGR_YUY2&apos;, &apos;COLOR_YUV2BGR_YUYV&apos;, &apos;COLOR_YUV2BGR_YV12&apos;, &apos;COLOR_YUV2BGR_YVYU&apos;, &apos;COLOR_YUV2GRAY_420&apos;, &apos;COLOR_YUV2GRAY_I420&apos;, &apos;COLOR_YUV2GRAY_IYUV&apos;, &apos;COLOR_YUV2GRAY_NV12&apos;, &apos;COLOR_YUV2GRAY_NV21&apos;, &apos;COLOR_YUV2GRAY_UYNV&apos;, &apos;COLOR_YUV2GRAY_UYVY&apos;, &apos;COLOR_YUV2GRAY_Y422&apos;, &apos;COLOR_YUV2GRAY_YUNV&apos;, &apos;COLOR_YUV2GRAY_YUY2&apos;, &apos;COLOR_YUV2GRAY_YUYV&apos;, &apos;COLOR_YUV2GRAY_YV12&apos;, &apos;COLOR_YUV2GRAY_YVYU&apos;, &apos;COLOR_YUV2RGB&apos;, &apos;COLOR_YUV2RGBA_I420&apos;, &apos;COLOR_YUV2RGBA_IYUV&apos;, &apos;COLOR_YUV2RGBA_NV12&apos;, &apos;COLOR_YUV2RGBA_NV21&apos;, &apos;COLOR_YUV2RGBA_UYNV&apos;, &apos;COLOR_YUV2RGBA_UYVY&apos;, &apos;COLOR_YUV2RGBA_Y422&apos;, &apos;COLOR_YUV2RGBA_YUNV&apos;, &apos;COLOR_YUV2RGBA_YUY2&apos;, &apos;COLOR_YUV2RGBA_YUYV&apos;, &apos;COLOR_YUV2RGBA_YV12&apos;, &apos;COLOR_YUV2RGBA_YVYU&apos;, &apos;COLOR_YUV2RGB_I420&apos;, &apos;COLOR_YUV2RGB_IYUV&apos;, &apos;COLOR_YUV2RGB_NV12&apos;, &apos;COLOR_YUV2RGB_NV21&apos;, &apos;COLOR_YUV2RGB_UYNV&apos;, &apos;COLOR_YUV2RGB_UYVY&apos;, &apos;COLOR_YUV2RGB_Y422&apos;, &apos;COLOR_YUV2RGB_YUNV&apos;, &apos;COLOR_YUV2RGB_YUY2&apos;, &apos;COLOR_YUV2RGB_YUYV&apos;, &apos;COLOR_YUV2RGB_YV12&apos;, &apos;COLOR_YUV2RGB_YVYU&apos;, &apos;COLOR_YUV420P2BGR&apos;, &apos;COLOR_YUV420P2BGRA&apos;, &apos;COLOR_YUV420P2GRAY&apos;, &apos;COLOR_YUV420P2RGB&apos;, &apos;COLOR_YUV420P2RGBA&apos;, &apos;COLOR_YUV420SP2BGR&apos;, &apos;COLOR_YUV420SP2BGRA&apos;, &apos;COLOR_YUV420SP2GRAY&apos;, &apos;COLOR_YUV420SP2RGB&apos;, &apos;COLOR_YUV420SP2RGBA&apos;, &apos;COLOR_YUV420p2BGR&apos;, &apos;COLOR_YUV420p2BGRA&apos;, &apos;COLOR_YUV420p2GRAY&apos;, &apos;COLOR_YUV420p2RGB&apos;, &apos;COLOR_YUV420p2RGBA&apos;, &apos;COLOR_YUV420sp2BGR&apos;, &apos;COLOR_YUV420sp2BGRA&apos;, &apos;COLOR_YUV420sp2GRAY&apos;, &apos;COLOR_YUV420sp2RGB&apos;, &apos;COLOR_YUV420sp2RGBA&apos;, &apos;COLOR_mRGBA2RGBA&apos;]</code></pre><h2 id="如何找到要追踪的HSV值？"><a href="#如何找到要追踪的HSV值？" class="headerlink" title="如何找到要追踪的HSV值？"></a>如何找到要追踪的HSV值？</h2><p>这是在stackoverflow.com上发现的一个常见问题。它非常简单，你可以使用相同的函数<strong>cv.cvtColor()</strong>。</p><p>你只需传递你想要的BGR值，而不是传递图像。例如，要查找绿色的HSV值，请在Python终端中尝试以下命令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">green = np.uint8([[[<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>]]])</span><br><span class="line">hsv_green = cv.cvtColor(green,cv.COLOR_BGR2HSV)</span><br><span class="line">hsv_green</span><br></pre></td></tr></table></figure><pre><code>array([[[ 60, 255, 255]]], dtype=uint8)</code></pre><h1 id="图像的几何变换"><a href="#图像的几何变换" class="headerlink" title="图像的几何变换"></a><span id="header2">图像的几何变换</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>学习将不同的几何变换应用到图像上，如平移、旋转、仿射变换等。</p><p>你会看到这些函数: cv.getPerspectiveTransform</p><h2 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h2><p>OpenCV提供了两个转换函数<strong>cv.warpAffine</strong>和<strong>cv.warpPerspective</strong>，您可以使用它们进行各种转换。</p><p><strong>cv.warpAffine</strong>采用2x3转换矩阵，而<strong>cv.warpPerspective</strong>采用3x3转换矩阵作为输入。</p><h2 id="缩放"><a href="#缩放" class="headerlink" title="缩放"></a>缩放</h2><p>缩放只是调整图像的大小。为此，OpenCV带有一个函数**cv.resize()。图像的大小可以手动指定，也可以指定缩放比例。</p><p>也可使用不同的插值方法。首选的插值方法是<strong>cv.INTER_AREA</strong>用于缩小，<strong>cv.INTER_CUBIC（慢）和</strong>cv.INTER_LINEAR**用于缩放。</p><p>默认情况下，出于所有调整大小的目的，使用的插值方法为<strong>cv.INTER_LINEAR</strong>。您可以使用以下方法调整输入图像的大小</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line">res = cv.resize(img,<span class="literal">None</span>,fx=<span class="number">2</span>, fy=<span class="number">2</span>, interpolation = cv.INTER_AREA)</span><br><span class="line">cv.imshow(<span class="string">'res1'</span>,res)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">height, width = img.shape[:<span class="number">2</span>]</span><br><span class="line">res = cv.resize(img,(<span class="number">2</span>*width, <span class="number">2</span>*height), interpolation = cv.INTER_CUBIC)</span><br><span class="line">cv.imshow(<span class="string">'res2'</span>,res)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="平移"><a href="#平移" class="headerlink" title="平移"></a>平移</h2><p>平移是物体位置的移动。如果您知道在(x,y)方向上的位移，则将其设为(tx,ty)，你可以创建转换矩阵M，如下所示：</p><p>M = $$<br> \left[<br> \begin{matrix}<br>   1 &amp; 0 &amp; tx \<br>   0 &amp; 1 &amp; ty<br>  \end{matrix}<br>  \right] <br>$$<br>您可以将其放入<strong>np.float32</strong>类型的Numpy数组中，并将其传递给<strong>cv.warpAffine</strong>函数。</p><p>参见下面偏移为(100, 50)的示例：</p><p><strong>cv.warpAffine</strong>函数的第三个参数是输出图像的大小，其形式应为(width，height)。记住width =列数，height =行数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">rows,cols = img.shape</span><br><span class="line">M = np.float32([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">100</span>],[<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>]])</span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,dst)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h2><p>图像旋转角度为θ是通过以下形式的变换矩阵实现的：</p><p>M=$$<br> \left[<br> \begin{matrix}<br>   \cos \theta &amp; \sin \theta  \<br>   \sin \theta &amp; \cos \theta<br>  \end{matrix}<br>  \right] <br>$$<br>但是OpenCV提供了可缩放的旋转以及可调整的旋转中心，因此您可以在自己喜欢的任何位置旋转。修改后的变换矩阵为</p><p>$$<br> \left[<br> \begin{matrix}<br>   \alpha &amp; \beta &amp; (1-\alpha)·center·x-\beta·center·y \<br>   -\beta &amp; \alpha &amp; \beta·center·x+(1-\alpha)·center·y<br>  \end{matrix}<br>  \right] <br>$$<br>其中：</p><p>$$α=scale⋅\cos \theta,β=scale⋅\sin \theta $$</p><p>为了找到此转换矩阵，OpenCV提供了一个函数<strong>cv.getRotationMatrix2D</strong>。</p><p>请检查以下示例，该示例将图像相对于中心旋转90度而没有任何缩放比例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">rows,cols = img.shape</span><br><span class="line"><span class="comment"># cols-1 和 rows-1 是坐标限制</span></span><br><span class="line">M = cv.getRotationMatrix2D(((cols<span class="number">-1</span>)/<span class="number">2.0</span>,(rows<span class="number">-1</span>)/<span class="number">2.0</span>),<span class="number">90</span>,<span class="number">2</span>)</span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,dst)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><p>在仿射变换中，原始图像中的所有平行线在输出图像中仍将平行。</p><p>为了找到变换矩阵，我们需要输入图像中的三个点及其在输出图像中的对应位置。</p><p>然后<strong>cv.getAffineTransform</strong>将创建一个2x3矩阵，该矩阵将传递给<strong>cv.warpAffine</strong>。</p><p>查看以下示例，并查看我选择的点（以绿色标记）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'drawing.png'</span>)</span><br><span class="line">rows,cols,ch = img.shape</span><br><span class="line">pts1 = np.float32([[<span class="number">50</span>,<span class="number">50</span>],[<span class="number">200</span>,<span class="number">50</span>],[<span class="number">50</span>,<span class="number">200</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">10</span>,<span class="number">100</span>],[<span class="number">200</span>,<span class="number">50</span>],[<span class="number">100</span>,<span class="number">250</span>]])</span><br><span class="line">M = cv.getAffineTransform(pts1,pts2)</span><br><span class="line">dst = cv.warpAffine(img,M,(cols,rows))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Input'</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Output'</span>)</span><br></pre></td></tr></table></figure><pre><code>(&lt;matplotlib.axes._subplots.AxesSubplot at 0x1bb7651dcc0&gt;, &lt;matplotlib.image.AxesImage at 0x1bb76bc5c18&gt;, Text(0.5, 1.0, &apos;Output&apos;))</code></pre><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_9_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'sudoku.png'</span>)</span><br><span class="line">rows,cols,ch = img.shape</span><br><span class="line">pts1 = np.float32([[<span class="number">56</span>,<span class="number">65</span>],[<span class="number">368</span>,<span class="number">52</span>],[<span class="number">28</span>,<span class="number">387</span>],[<span class="number">389</span>,<span class="number">390</span>]])</span><br><span class="line">pts2 = np.float32([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">300</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">300</span>],[<span class="number">300</span>,<span class="number">300</span>]])</span><br><span class="line">M = cv.getPerspectiveTransform(pts1,pts2)</span><br><span class="line">dst = cv.warpPerspective(img,M,(<span class="number">300</span>,<span class="number">300</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Input'</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Output'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_10_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="图像阈值"><a href="#图像阈值" class="headerlink" title="图像阈值"></a><span id="header3">图像阈值</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><p>在本教程中，您将学习简单阈值，自适应阈值和Otsu阈值。</p><p>你将学习函数<strong>cv.threshold</strong>和<strong>cv.adaptiveThreshold</strong>。</p><h2 id="简单阈值"><a href="#简单阈值" class="headerlink" title="简单阈值"></a>简单阈值</h2><p>在这里，问题直截了当。对于每个像素，应用相同的阈值。</p><p>如果像素值小于阈值，则将其设置为0，否则将其设置为最大值。函数<strong>cv.threshold</strong>用于应用阈值。</p><ul><li>第一个参数是源图像，它<strong>应该是灰度图像</strong>。</li><li>第二个参数是阈值，用于对像素值进行分类。</li><li>第三个参数是分配给超过阈值的像素值的最大值。</li><li>第四个参数OpenCV提供了不同类型的阈值,通过使用<strong>cv.THRESH_BINARY</strong>类型。所有简单的阈值类型为：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cv.THRESH_BINARY</span><br><span class="line">cv.THRESH_BINARY_INV</span><br><span class="line">cv.THRESH_TRUNC</span><br><span class="line">cv.THRESH_TOZERO</span><br><span class="line">cv.THRESH_TOZERO_INV</span><br></pre></td></tr></table></figure></li></ul><p>该方法返回两个输出。第一个是使用的阈值，第二个输出是<strong>阈值后的图像</strong>。</p><p>此代码比较了不同的简单阈值类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'gradient.png'</span>,<span class="number">0</span>)</span><br><span class="line">ret,thresh1 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line">ret,thresh2 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY_INV)</span><br><span class="line">ret,thresh3 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TRUNC)</span><br><span class="line">ret,thresh4 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TOZERO)</span><br><span class="line">ret,thresh5 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TOZERO_INV)</span><br><span class="line">titles = [<span class="string">'Original Image'</span>,<span class="string">'BINARY'</span>,<span class="string">'BINARY_INV'</span>,<span class="string">'TRUNC'</span>,<span class="string">'TOZERO'</span>,<span class="string">'TOZERO_INV'</span>]</span><br><span class="line">images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>),plt.imshow(images[i],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.xticks([]),plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_2_1.png" alt="png"></p><h2 id="自适应阈值"><a href="#自适应阈值" class="headerlink" title="自适应阈值"></a>自适应阈值</h2><p>在上一节中，我们使用一个全局值作为阈值。但这可能并非在所有情况下都很好，例如，如果图像在不同区域具有不同的光照条件。在这种情况下，自适应阈值阈值化可以提供帮助。在此，算法基于像素周围的小区域确定像素的阈值。因此，对于同一图像的不同区域，我们获得了不同的阈值，这为光照度变化的图像提供了更好的结果。</p><p>除上述参数外，方法<strong>cv.adaptiveThreshold</strong>还包含三个输入参数：</p><p>该<strong>adaptiveMethod</strong>决定阈值是如何计算的：</p><p>cv.ADAPTIVE_THRESH_MEAN_C::阈值是邻近区域的平均值减去常数<strong>C</strong>。 </p><p>cv.ADAPTIVE_THRESH_GAUSSIAN_C:阈值是邻域值的高斯加权总和减去常数<strong>C</strong>。</p><p>该<strong>BLOCKSIZE</strong>确定附近区域的大小，<strong>C</strong>是从邻域像素的平均或加权总和中减去的一个常数。</p><p>下面的代码比较了光照变化的图像的全局阈值和自适应阈值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'sudoku.png'</span>,<span class="number">0</span>)</span><br><span class="line">ret,th1 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line">th2 = cv.adaptiveThreshold(img,<span class="number">255</span>,cv.ADAPTIVE_THRESH_MEAN_C,\</span><br><span class="line">            cv.THRESH_BINARY,<span class="number">11</span>,<span class="number">2</span>)</span><br><span class="line">th3 = cv.adaptiveThreshold(img,<span class="number">255</span>,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\</span><br><span class="line">            cv.THRESH_BINARY,<span class="number">11</span>,<span class="number">2</span>)</span><br><span class="line">titles = [<span class="string">'Original Image'</span>, <span class="string">'Global Thresholding (v = 127)'</span>,</span><br><span class="line">            <span class="string">'Adaptive Mean Thresholding'</span>, <span class="string">'Adaptive Gaussian Thresholding'</span>]</span><br><span class="line">images = [img, th1, th2, th3]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,i+<span class="number">1</span>),plt.imshow(images[i],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.xticks([]),plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_4_0.png" alt="png"></p><h2 id="Otsu的二值化"><a href="#Otsu的二值化" class="headerlink" title="Otsu的二值化"></a>Otsu的二值化</h2><p>在全局阈值化中，我们使用任意选择的值作为阈值。相反，Otsu的方法避免了必须选择一个值并自动确定它的情况。</p><p>考虑仅具有两个不同图像值的图像（双峰图像），其中直方图将仅包含两个峰。一个好的阈值应该在这两个值的中间。类似地，Otsu的方法从图像直方图中确定最佳全局阈值。</p><p>为此，使用了<strong>cv.threshold</strong>作为附加标志传递。阈值可以任意选择。然后，算法找到最佳阈值，该阈值作为第一输出返回。</p><p>查看以下示例。输入图像为噪点图像。</p><p>在第一种情况下，采用值为127的全局阈值。</p><p>在第二种情况下，直接采用Otsu阈值法。</p><p>在第三种情况下，首先使用5x5高斯核对图像进行滤波以去除噪声，然后应用Otsu阈值处理。了解噪声滤波如何改善结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'sudoku.png'</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 全局阈值</span></span><br><span class="line">ret1,th1 = cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY)</span><br><span class="line"><span class="comment"># Otsu阈值</span></span><br><span class="line">ret2,th2 = cv.threshold(img,<span class="number">0</span>,<span class="number">255</span>,cv.THRESH_BINARY+cv.THRESH_OTSU)</span><br><span class="line"><span class="comment"># 高斯滤波后再采用Otsu阈值</span></span><br><span class="line">blur = cv.GaussianBlur(img,(<span class="number">5</span>,<span class="number">5</span>),<span class="number">0</span>)</span><br><span class="line">ret3,th3 = cv.threshold(blur,<span class="number">0</span>,<span class="number">255</span>,cv.THRESH_BINARY+cv.THRESH_OTSU)</span><br><span class="line"><span class="comment"># 绘制所有图像及其直方图</span></span><br><span class="line">images = [img, <span class="number">0</span>, th1,</span><br><span class="line">          img, <span class="number">0</span>, th2,</span><br><span class="line">          blur, <span class="number">0</span>, th3]</span><br><span class="line">titles = [<span class="string">'Original Noisy Image'</span>,<span class="string">'Histogram'</span>,<span class="string">'Global Thresholding (v=127)'</span>,</span><br><span class="line">          <span class="string">'Original Noisy Image'</span>,<span class="string">'Histogram'</span>,<span class="string">"Otsu's Thresholding"</span>,</span><br><span class="line">          <span class="string">'Gaussian filtered Image'</span>,<span class="string">'Histogram'</span>,<span class="string">"Otsu's Thresholding"</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i*<span class="number">3</span>+<span class="number">1</span>),plt.imshow(images[i*<span class="number">3</span>],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i*<span class="number">3</span>]), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i*<span class="number">3</span>+<span class="number">2</span>),plt.hist(images[i*<span class="number">3</span>].ravel(),<span class="number">256</span>)</span><br><span class="line">    plt.title(titles[i*<span class="number">3</span>+<span class="number">1</span>]), plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i*<span class="number">3</span>+<span class="number">3</span>),plt.imshow(images[i*<span class="number">3</span>+<span class="number">2</span>],<span class="string">'gray'</span>)</span><br><span class="line">    plt.title(titles[i*<span class="number">3</span>+<span class="number">2</span>]), plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_6_0.png" alt="png"></p><h2 id="Otsu的二值化如何实现？"><a href="#Otsu的二值化如何实现？" class="headerlink" title="Otsu的二值化如何实现？"></a>Otsu的二值化如何实现？</h2><p>本节演示了Otsu二值化的Python实现，以展示其实际工作方式。</p><p>由于我们正在处理双峰图像，因此Otsu的算法尝试找到一个阈值(t)，该阈值将由关系式给出的<strong>加权类内方差</strong>最小化：</p><p><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/Otsu.png" alt></p><p>实际上，它找到位于两个峰值之间的t值，以使两个类别的差异最小</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'sudoku.png'</span>,<span class="number">0</span>)</span><br><span class="line">blur = cv.GaussianBlur(img,(<span class="number">5</span>,<span class="number">5</span>),<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 寻找归一化直方图和对应的累积分布函数</span></span><br><span class="line">hist = cv.calcHist([blur],[<span class="number">0</span>],<span class="literal">None</span>,[<span class="number">256</span>],[<span class="number">0</span>,<span class="number">256</span>])</span><br><span class="line">hist_norm = hist.ravel()/hist.max()</span><br><span class="line">Q = hist_norm.cumsum()</span><br><span class="line">bins = np.arange(<span class="number">256</span>)</span><br><span class="line">fn_min = np.inf</span><br><span class="line">thresh = <span class="number">-1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">256</span>):</span><br><span class="line">    p1,p2 = np.hsplit(hist_norm,[i]) <span class="comment"># 概率</span></span><br><span class="line">    q1,q2 = Q[i],Q[<span class="number">255</span>]-Q[i] <span class="comment"># 对类求和</span></span><br><span class="line">    b1,b2 = np.hsplit(bins,[i]) <span class="comment"># 权重</span></span><br><span class="line">    <span class="comment"># 寻找均值和方差</span></span><br><span class="line">    m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2</span><br><span class="line">    v1,v2 = np.sum(((b1-m1)**<span class="number">2</span>)*p1)/q1,np.sum(((b2-m2)**<span class="number">2</span>)*p2)/q2</span><br><span class="line">    <span class="comment"># 计算最小化函数</span></span><br><span class="line">    fn = v1*q1 + v2*q2</span><br><span class="line">    <span class="keyword">if</span> fn &lt; fn_min:</span><br><span class="line">        fn_min = fn</span><br><span class="line">        thresh = i</span><br><span class="line"><span class="comment"># 使用OpenCV函数找到otsu的阈值</span></span><br><span class="line">ret, otsu = cv.threshold(blur,<span class="number">0</span>,<span class="number">255</span>,cv.THRESH_BINARY+cv.THRESH_OTSU)</span><br><span class="line">print( <span class="string">"&#123;&#125; &#123;&#125;"</span>.format(thresh,ret) )</span><br></pre></td></tr></table></figure><pre><code>101 100.0c:\users\18025\appdata\local\programs\python\python37\lib\site-packages\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars  from ipykernel import kernelapp as appc:\users\18025\appdata\local\programs\python\python37\lib\site-packages\ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in double_scalars  from ipykernel import kernelapp as appc:\users\18025\appdata\local\programs\python\python37\lib\site-packages\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in multiply  app.launch_new_instance()</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="图像平滑"><a href="#图像平滑" class="headerlink" title="图像平滑"></a><span id="header4">图像平滑</span></h1><h2 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h2><p>学会： - 使用各种低通滤镜模糊图像 - 将定制的滤镜应用于图像（2D卷积）</p><h2 id="2D卷积（图像过滤）"><a href="#2D卷积（图像过滤）" class="headerlink" title="2D卷积（图像过滤）"></a>2D卷积（图像过滤）</h2><p>与一维信号一样，还可以使用各种低通滤波器（LPF），高通滤波器（HPF）等对图像进行滤波。LPF有助于消除噪声，使图像模糊等。HPF滤波器有助于在图像中找到边缘。</p><p>OpenCV提供了一个函数<strong>cv.filter2D</strong>来将内核与图像进行卷积。例如，我们将尝试对图像进行平均滤波。5x5平均滤波器内核如下所示：</p><p>K=$$\frac{1}{25}<br> \left[<br> \begin{matrix}<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1<br>  \end{matrix}<br>  \right] <br>$$<br>操作如下:保持这个内核在一个像素上，将所有低于这个内核的25个像素相加，取其平均值，然后用新的平均值替换中心像素。它将对图像中的所有像素继续此操作。试试这个代码，并检查结果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line">kernel = np.ones((<span class="number">5</span>,<span class="number">5</span>),np.float32)/<span class="number">25</span></span><br><span class="line">dst = cv.filter2D(img,<span class="number">-1</span>,kernel)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(dst),plt.title(<span class="string">'Averaging'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_2_0.png" alt="png"></p><h2 id="图像模糊（图像平滑）"><a href="#图像模糊（图像平滑）" class="headerlink" title="图像模糊（图像平滑）"></a>图像模糊（图像平滑）</h2><p>通过将图像与低通滤波器内核进行卷积来实现图像模糊。这对于消除噪音很有用。它实际上从图像中消除了高频部分（例如噪声，边缘）。</p><p>因此，在此操作中边缘有些模糊。（有一些模糊技术也可以不模糊边缘）。OpenCV主要提供四种类型的模糊技术。</p><h3 id="1-平均"><a href="#1-平均" class="headerlink" title="1.平均"></a>1.平均</h3><p>这是通过将图像与归一化框滤镜进行卷积来完成的。它仅获取内核区域下所有像素的平均值，并替换中心元素。这是通过功能<strong>cv.blur()或</strong>cv.boxFilter()完成的。检查文档以获取有关内核的更多详细信息。我们应该指定内核的宽度和高度。3x3归一化框式过滤器如下所示：</p><p>K=$$\frac{1}{9}<br> \left[<br> \begin{matrix}<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\<br>    1 &amp; 1 &amp; 1 &amp; 1 &amp; 1<br>  \end{matrix}<br>  \right] <br>$$<br>注意 如果您不想使用标准化的框式过滤器，请使用<strong>cv.boxFilter()</strong>。将参数normalize = False传递给函数。</p><p>查看下面的示例演示，其内核大小为5x5：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line">blur = cv.blur(img,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur),plt.title(<span class="string">'Blurred'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_5_0.png" alt="png"></p><h3 id="2-高斯模糊"><a href="#2-高斯模糊" class="headerlink" title="2.高斯模糊"></a>2.高斯模糊</h3><p>在这种情况下，代替盒式滤波器，使用了高斯核。</p><p>这是通过功能<strong>cv.GaussianBlur()</strong> 完成的。我们应指定内核的宽度和高度，该宽度和高度应为正数和奇数。</p><p>我们还应指定X和Y方向的标准偏差，分别为sigmaX和sigmaY。如果仅指定sigmaX，则将sigmaY与sigmaX相同。</p><p>如果两个都为零，则根据内核大小进行计算。高斯模糊对于从图像中去除高斯噪声非常有效。</p><p>如果需要，可以使用函数<strong>cv.getGaussianKernel()</strong> 创建高斯内核。</p><p>可以修改以上代码以实现高斯模糊：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line">blur = cv.GaussianBlur(img,(<span class="number">5</span>,<span class="number">5</span>),<span class="number">0</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur),plt.title(<span class="string">'Blurred'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_7_0.png" alt="png"></p><h3 id="3-中位模糊"><a href="#3-中位模糊" class="headerlink" title="3.中位模糊"></a>3.中位模糊</h3><p>在这里，函数<strong>cv.medianBlur()</strong> 提取内核区域下所有像素的中值，并将中心元素替换为该中值。</p><p>这对于消除图像中的椒盐噪声非常有效。有趣的是，在上述过滤器中，中心元素是新计算的值，该值可以是图像中的像素值或新值。</p><p>但是在中值模糊中，中心元素总是被图像中的某些像素值代替。有效降低噪音。其内核大小应为正奇数整数。</p><p>在此演示中，我向原始图像添加了50％的噪声并应用了中值模糊。检查结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line">median = cv.medianBlur(img,<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(median),plt.title(<span class="string">'Blurred'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_9_0.png" alt="png"></p><h3 id="4-双边滤波"><a href="#4-双边滤波" class="headerlink" title="4.双边滤波"></a>4.双边滤波</h3><p>cv.bilateralFilter() 在去除噪声的同时保持边缘清晰锐利非常有效。</p><p>但是，与其他过滤器相比，该操作速度较慢。我们已经看到，高斯滤波器采用像素周围的邻域并找到其高斯加权平均值。</p><p>高斯滤波器仅是空间的函数，也就是说，滤波时会考虑附近的像素。它不考虑像素是否具有几乎相同的强度。它不考虑像素是否是边缘像素。因此它也模糊了边缘，这是我们不想做的。</p><p>双边滤波器在空间中也采用高斯滤波器，但是又有一个高斯滤波器，它是像素差的函数。</p><p>空间的高斯函数确保仅考虑附近像素的模糊，而强度差的高斯函数确保仅考虑强度与中心像素相似的那些像素的模糊。由于边缘的像素强度变化较大，因此可以保留边缘。</p><p>以下示例显示了使用双边过滤器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">img = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line">blur = cv.bilateralFilter(img,<span class="number">9</span>,<span class="number">75</span>,<span class="number">75</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>),plt.imshow(img),plt.title(<span class="string">'Original'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.subplot(<span class="number">122</span>),plt.imshow(blur),plt.title(<span class="string">'Blurred'</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861/output_11_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;1.&lt;a href=&quot;#header1&quot;&gt;改变颜色空间&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2.&lt;a href=&quot;#header2&quot;&gt;图像几何变换&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.&lt;a href=&quot;#header3&quot;&gt;图像阈值&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.&lt;a href=&quot;#header4&quot;&gt;图像平滑&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv图像核心操作</title>
    <link href="http://yoursite.com/2020/07/12/opencv%E5%9B%BE%E5%83%8F%E6%A0%B8%E5%BF%83%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2020/07/12/opencv%E5%9B%BE%E5%83%8F%E6%A0%B8%E5%BF%83%E6%93%8D%E4%BD%9C/</id>
    <published>2020-07-12T09:02:28.000Z</published>
    <updated>2020-07-12T10:58:18.311Z</updated>
    
    <content type="html"><![CDATA[<ul><li>1.<a href="#header1">图片的基本操作</a></li><li>2.<a href="#header2">图片的算法操作</a></li><li>3.<a href="#header3">性能衡量和提升技术</a><a id="more"></a></li></ul><h1 id="图像的基本操作"><a href="#图像的基本操作" class="headerlink" title="图像的基本操作"></a><span id="header1">图像的基本操作</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>学会： - 访问像素值并修改它们 - 访问图像属性 - 设置感兴趣区域(ROI) - 分割和合并图像</p><p>本节中的几乎所有操作都主要与Numpy相关，而不是与OpenCV相关。要使用OpenCV编写更好的优化代码，需要Numpy的丰富知识。</p><h2 id="访问和修改像素值"><a href="#访问和修改像素值" class="headerlink" title="访问和修改像素值"></a>访问和修改像素值</h2><p>对于 BGR 图像，它返回一个由蓝色、绿色和红色值组成的数组。对于灰度图像，只返回相应的灰度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>) <span class="comment"># 载入彩色图像</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">px = img[<span class="number">210</span>,<span class="number">490</span>] <span class="comment"># 访问210,490点处的全部元素</span></span><br><span class="line">px</span><br></pre></td></tr></table></figure><pre><code>array([237, 189, 147], dtype=uint8)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blue = img[<span class="number">210</span>,<span class="number">490</span>,<span class="number">0</span>] <span class="comment"># 仅访问蓝色元素</span></span><br><span class="line">blue</span><br></pre></td></tr></table></figure><pre><code>237</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img[<span class="number">100</span>,<span class="number">100</span>] = [<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>]<span class="comment"># 修改像素值</span></span><br><span class="line">img[<span class="number">100</span>,<span class="number">100</span>]</span><br></pre></td></tr></table></figure><pre><code>array([255, 255, 255], dtype=uint8)</code></pre><h3 id="警告"><a href="#警告" class="headerlink" title="警告"></a>警告</h3><p>Numpy是用于快速数组计算的优化库。因此，简单地访问每个像素值并对其进行修改将非常缓慢，因此不建议使用。</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>上面的方法通常用于选择数组的区域，例如前5行和后3列。</p><p>对于单个像素访问，Numpy数组方法array.item()和array.itemset())被认为更好，但是它们始终返回标量。</p><p>如果要访问所有B，G，R值，则需要分别调用所有的array.item()。</p><p>下面是更好的像素访问和编辑方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">red = img.item(<span class="number">100</span>,<span class="number">100</span>,<span class="number">2</span>)</span><br><span class="line">red</span><br></pre></td></tr></table></figure><pre><code>255</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img.itemset((<span class="number">100</span>,<span class="number">100</span>,<span class="number">2</span>),<span class="number">222</span>)</span><br><span class="line">red = img.item(<span class="number">100</span>,<span class="number">100</span>,<span class="number">2</span>)</span><br><span class="line">red</span><br></pre></td></tr></table></figure><pre><code>222</code></pre><h2 id="访问图像属性"><a href="#访问图像属性" class="headerlink" title="访问图像属性"></a>访问图像属性</h2><p>图像属性包括行数，列数和通道数，图像数据类型，像素数等。</p><p>图像的形状可通过img.shape访问。它返回行，列和通道数的元组（如果图像是彩色的）：</p><p>注意 如果图像是灰度的，则返回的元组仅包含行数和列数，因此这是检查加载的图像是灰度还是彩色的好方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img.shape</span><br></pre></td></tr></table></figure><pre><code>(640, 640, 3)</code></pre><p>像素总数可通过访问img.size：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img.size</span><br></pre></td></tr></table></figure><pre><code>1228800</code></pre><p>图像数据类型通过img.dtype获得：</p><p>注意 img.dtype在调试时非常重要，因为OpenCV-Python代码中的大量错误是由无效的数据类型引起的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img.dtype</span><br></pre></td></tr></table></figure><pre><code>dtype(&apos;uint8&apos;)</code></pre><h2 id="图像感兴趣区域ROI"><a href="#图像感兴趣区域ROI" class="headerlink" title="图像感兴趣区域ROI"></a>图像感兴趣区域ROI</h2><p>有时候，你不得不处理一些特定区域的图像。</p><p>对于图像中的眼睛检测，首先对整个图像进行人脸检测。</p><p>在获取人脸图像时，我们只选择人脸区域，搜索其中的眼睛，而不是搜索整个图像。</p><p>它提高了准确性(因为眼睛总是在面部上:D )和性能(因为我们搜索的区域很小)。</p><p>使用Numpy索引再次获得ROI。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ball = img[<span class="number">180</span>:<span class="number">240</span>, <span class="number">230</span>:<span class="number">290</span>]</span><br><span class="line">img[<span class="number">273</span>:<span class="number">333</span>, <span class="number">100</span>:<span class="number">160</span>] = ball </span><br><span class="line">cv.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="拆分和合并图像通道"><a href="#拆分和合并图像通道" class="headerlink" title="拆分和合并图像通道"></a>拆分和合并图像通道</h2><p>有时你需要分别处理图像的B，G，R通道。在这种情况下，你需要将BGR图像拆分为单个通道。</p><p>在其他情况下，你可能需要将这些单独的频道加入BGR图片。你可以通过以下方式简单地做到这一点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b,g,r = cv.split(img)</span><br><span class="line">img = cv.merge((b,g,r))</span><br></pre></td></tr></table></figure><p>假设你要将所有红色像素都设置为零，则无需先拆分通道。numpy索引更快</p><p>警告</p><p>cv.split()是一项耗时的操作（就时间而言）。因此，仅在必要时才这样做。否则请进行Numpy索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img [:, :, <span class="number">2</span>] = <span class="number">0</span></span><br><span class="line">cv.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="为图像设置边框（填充）"><a href="#为图像设置边框（填充）" class="headerlink" title="为图像设置边框（填充）"></a>为图像设置边框（填充）</h2><p>如果要在图像周围创建边框（如相框），则可以使用cv.copyMakeBorder()。但是它在卷积运算，零填充等方面有更多应用。此函数采用以下参数：</p><p>src - 输入图像</p><p>top，bottom，left，right 边界宽度（以相应方向上的像素数为单位）</p><p>borderType - 定义要添加哪种边框的标志。它可以是以下类型：</p><ul><li>cv.BORDER_CONSTANT - 添加恒定的彩色边框。该值应作为下一个参数给出。</li><li>cv.BORDER_REFLECT - 边框将是边框元素的镜像，如下所示： fedcba | abcdefgh | hgfedcb</li><li>cv.BORDER_REFLECT_101或 cv.BORDER_DEFAULT与上述相同，但略有变化，例如： gfedcb | abcdefgh | gfedcba</li><li>cv.BORDER_REPLICATE最后一个元素被复制，像这样： aaaaaa | abcdefgh | hhhhhhh</li><li>cv.BORDER_WRAP难以解释，它看起来像这样： cdefgh | abcdefgh | abcdefg</li></ul><p>value -边框的颜色，如果边框类型为<strong>cv.BORDER_CONSTANT</strong></p><p>下面是一个示例代码，演示了所有这些边框类型，以便更好地理解：<br>(图像与matplotlib一起显示。因此红色和蓝色通道将互换)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">BLUE = [<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">img1 = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line">replicate = cv.copyMakeBorder(img1,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,cv.BORDER_REPLICATE)</span><br><span class="line">reflect = cv.copyMakeBorder(img1,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,cv.BORDER_REFLECT)</span><br><span class="line">reflect101 = cv.copyMakeBorder(img1,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,cv.BORDER_REFLECT_101)</span><br><span class="line">wrap = cv.copyMakeBorder(img1,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,cv.BORDER_WRAP)</span><br><span class="line">constant= cv.copyMakeBorder(img1,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>,cv.BORDER_CONSTANT,value=BLUE)</span><br><span class="line">plt.subplot(<span class="number">231</span>),plt.imshow(img1,<span class="string">'gray'</span>),plt.title(<span class="string">'ORIGINAL'</span>)</span><br><span class="line">plt.subplot(<span class="number">232</span>),plt.imshow(replicate,<span class="string">'gray'</span>),plt.title(<span class="string">'REPLICATE'</span>)</span><br><span class="line">plt.subplot(<span class="number">233</span>),plt.imshow(reflect,<span class="string">'gray'</span>),plt.title(<span class="string">'REFLECT'</span>)</span><br><span class="line">plt.subplot(<span class="number">234</span>),plt.imshow(reflect101,<span class="string">'gray'</span>),plt.title(<span class="string">'REFLECT_101'</span>)</span><br><span class="line">plt.subplot(<span class="number">235</span>),plt.imshow(wrap,<span class="string">'gray'</span>),plt.title(<span class="string">'WRAP'</span>)</span><br><span class="line">plt.subplot(<span class="number">236</span>),plt.imshow(constant,<span class="string">'gray'</span>),plt.title(<span class="string">'CONSTANT'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv%E5%9B%BE%E5%83%8F%E6%A0%B8%E5%BF%83%E6%93%8D%E4%BD%9C/output_21_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="图像上的算术运算"><a href="#图像上的算术运算" class="headerlink" title="图像上的算术运算"></a><span id="header2">图像上的算术运算</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><p>学习图像的几种算术运算，例如加法，减法，按位运算等。</p><p>您将学习以下功能：cv.add，<strong>cv.addWeighted</strong>等。</p><h2 id="图像加法"><a href="#图像加法" class="headerlink" title="图像加法"></a>图像加法</h2><p>您可以通过OpenCV函数cv.add()或仅通过numpy操作res = img1 + img2添加两个图像。</p><p>两个图像应具有相同的深度和类型，或者第二个图像可以只是一个标量值。</p><p>注意 OpenCV加法和Numpy加法之间有区别。OpenCV加法是饱和运算，而Numpy加法是模运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.uint8([<span class="number">250</span>])</span><br><span class="line">y = np.uint8([<span class="number">10</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x+y  <span class="comment"># 250+10 = 260 % 256 = 4</span></span><br></pre></td></tr></table></figure><pre><code>array([4], dtype=uint8)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.add(x,y) <span class="comment"># 250+10 = 260 =&gt; 255</span></span><br></pre></td></tr></table></figure><pre><code>array([[255]], dtype=uint8)</code></pre><h2 id="图像融合"><a href="#图像融合" class="headerlink" title="图像融合"></a>图像融合</h2><p>这也是图像加法，但是对图像赋予不同的权重，以使其具有融合或透明的感觉。根据以下等式添加图像：</p><p>G(x)=(1−α)f0(x)+αf1(x)<br>通过从 α 从 0→1 更改，您可以在一个图像到另一个图像之间执行很酷的过渡。</p><p>将两幅图像合在一起。第一幅图像的权重为0.7，第二幅图像的权重为0.3。</p><p>cv.addWeighted()在图像上应用以下公式。</p><p>dst=α⋅img1+β⋅img2+γ<br>在这里，γ 被视为零。</p><p>先保存一个和avatar1大小一样上下相反的图像avatar2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">'avatar1.jpg'</span>)</span><br><span class="line">newImg = img.copy() <span class="comment"># 深拷贝</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(img.shape[<span class="number">0</span>]):</span><br><span class="line">    newImg[img.shape[<span class="number">0</span>]<span class="number">-1</span>-i] = img[i]</span><br><span class="line">cv.imshow(<span class="string">'x'</span>,newImg)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line">cv.imwrite(<span class="string">'avatar2.jpg'</span>,newImg)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img1 = cv.imread(<span class="string">'avatar1.jpg'</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">'avatar2.jpg'</span>)</span><br><span class="line">dst = cv.addWeighted(img1,<span class="number">0.7</span>,img2,<span class="number">0.3</span>,<span class="number">0</span>)</span><br><span class="line">cv.imshow(<span class="string">'dst'</span>,dst)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="按位运算"><a href="#按位运算" class="headerlink" title="按位运算"></a>按位运算</h2><p>这包括按位 AND、 OR、NOT 和 XOR 操作。它们在提取图像的任何部分(我们将在后面的章节中看到)、定义和处理非矩形 ROI 等方面非常有用。 </p><p>下面我们将看到一个例子，如何改变一个图像的特定区域。 </p><p>我想把 OpenCV 的标志放在一个图像上面。如果我添加两个图像，它会改变颜色。如果我混合它，我得到一个透明的效果。</p><p>但我希望它是不透明的。如果是一个矩形区域，</p><p>我可以使用 ROI，就像我们在上一章中所做的那样。</p><p>但是 OpenCV 的 logo 不是长方形的。所以你可以使用如下的按位操作来实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载两张图片</span></span><br><span class="line">img1 = cv.imread(<span class="string">'avatar1.jpg'</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">'opencv-logo.png'</span>)</span><br><span class="line"><span class="comment"># 我想把logo放在左上角，所以我创建了ROI</span></span><br><span class="line">rows,cols,channels = img2.shape</span><br><span class="line">roi = img1[<span class="number">0</span>:rows, <span class="number">0</span>:cols ]</span><br><span class="line"><span class="comment"># 现在创建logo的掩码，并同时创建其相反掩码</span></span><br><span class="line">img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)</span><br><span class="line">ret, mask = cv.threshold(img2gray, <span class="number">10</span>, <span class="number">255</span>, cv.THRESH_BINARY)</span><br><span class="line">mask_inv = cv.bitwise_not(mask)</span><br><span class="line">cv.imshow(<span class="string">'img2gray'</span>,img2gray)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line">cv.imshow(<span class="string">'mask'</span>,mask)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line">cv.imshow(<span class="string">'mask_inv'</span>,mask_inv)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line"><span class="comment"># 现在将ROI中logo的区域涂黑</span></span><br><span class="line">img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)</span><br><span class="line"><span class="comment"># 仅从logo图像中提取logo区域</span></span><br><span class="line">img2_fg = cv.bitwise_and(img2,img2,mask = mask)</span><br><span class="line"><span class="comment"># 将logo放入ROI并修改主图像</span></span><br><span class="line">cv.imshow(<span class="string">'img1_bg'</span>,img1_bg)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line">cv.imshow(<span class="string">'img2_bg'</span>,img2_fg)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br><span class="line">dst = cv.add(img1_bg,img2_fg)</span><br><span class="line">img1[<span class="number">0</span>:rows, <span class="number">0</span>:cols ] = dst</span><br><span class="line">cv.imshow(<span class="string">'res'</span>,img1)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h1 id="性能衡量和提升技术"><a href="#性能衡量和提升技术" class="headerlink" title="性能衡量和提升技术"></a><span id="header3">性能衡量和提升技术</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><p>在图像处理中，由于每秒要处理大量操作，因此必须使代码不仅提供正确的解决方案，而且还必须以最快的方式提供。</p><p>将学习衡量代码的性能,一些提高代码性能的技巧。</p><p>你将看到以下功能：cv.getTickCount，<strong>cv.getTickFrequency</strong>等。</p><p>除了OpenCV，Python还提供了一个模块<strong>time</strong>，这有助于衡量执行时间。</p><p>另一个模块<strong>profile</strong>有助于获取有关代码的详细报告，例如代码中每个函数花费了多少时间，调用了函数的次数等。</p><p>但是，如果你使用的是IPython，则所有这些功能都集成在用户友好的界面中方式。</p><h2 id="使用OpenCV衡量性能"><a href="#使用OpenCV衡量性能" class="headerlink" title="使用OpenCV衡量性能"></a>使用OpenCV衡量性能</h2><p><strong>cv.getTickCount</strong>函数返回从参考事件（如打开机器的那一刻）到调用此函数那一刻之间的时钟周期数。因此，如果在函数执行之前和之后调用它，则会获得用于执行函数的时钟周期数。</p><p><strong>cv.getTickFrequency</strong>函数返回时钟周期的频率或每秒的时钟周期数。因此，要找到执行时间（以秒为单位），你可以执行以下操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img1 = cv.imread(<span class="string">'avatar2gray.jpg.jpg'</span>)</span><br><span class="line">e1 = cv.getTickCount()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>,<span class="number">49</span>,<span class="number">2</span>):</span><br><span class="line">    img1 = cv.medianBlur(img1,i)</span><br><span class="line">e2 = cv.getTickCount()</span><br><span class="line">t = (e2 - e1)/cv.getTickFrequency()</span><br><span class="line">t</span><br></pre></td></tr></table></figure><pre><code>0.0002413</code></pre><h2 id="OpenCV中的默认优化"><a href="#OpenCV中的默认优化" class="headerlink" title="OpenCV中的默认优化"></a>OpenCV中的默认优化</h2><p>许多 OpenCV 函数都是使用 SSE2、 AVX 等进行优化的。 它还包含未优化的代码。</p><p>因此，如果我们的系统支持这些特性，我们就应该利用它们(几乎所有现代的处理器都支持它们)。</p><p>在编译时默认启用它。因此，如果启用了 OpenCV，它将运行优化的代码，否则它将运行未优化的代码。</p><p>你可以使用 cvUseoptimized 检查是否启用 / 禁用和 cvSetuseoptimized 以启用 / 禁用它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.useOptimized() <span class="comment"># 检查是否启用了优化</span></span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit res = cv.medianBlur(img1,<span class="number">49</span>)</span><br></pre></td></tr></table></figure><pre><code>748 ns ± 45.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv.setUseOptimized(<span class="literal">False</span>)</span><br><span class="line">print(cv.useOptimized())</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit res = cv.medianBlur(img1,<span class="number">49</span>)</span><br></pre></td></tr></table></figure><pre><code>752 ns ± 34.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.setUseOptimized(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="在IPython中衡量性能"><a href="#在IPython中衡量性能" class="headerlink" title="在IPython中衡量性能"></a>在IPython中衡量性能</h2><p>有时你可能需要比较两个类似操作的性能。</p><p>IPython为你提供了一个神奇的命令计时器来执行此操作。它</p><p>会多次运行代码以获得更准确的结果。同样，它们适用于测量单行代码。</p><p>例如，你知道以下哪个加法运算更好，</p><p>x = 5 y = x**2, </p><p>x = 5  y = x*x, </p><p>x = np.uint8([5]) y = x*x或y = np.square(x)?我们将在IPython shell中使用timeit</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">5</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit y=x**<span class="number">2</span></span><br></pre></td></tr></table></figure><pre><code>515 ns ± 17 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit y=x*x</span><br></pre></td></tr></table></figure><pre><code>121 ns ± 5.63 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">z = np.uint8([<span class="number">5</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit y=z*z</span><br></pre></td></tr></table></figure><pre><code>1.04 µs ± 61.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit y=np.square(z)</span><br></pre></td></tr></table></figure><pre><code>1.04 µs ± 57.5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre><p>可以看到x = 5; y = x * x最快，比Numpy快20倍左右。如果你还考虑阵列的创建，它可能会快100倍。</p><p>注意 Python标量操作比Numpy标量操作快。</p><p>因此，对于包含一两个元素的运算，Python标量比Numpy数组好。</p><p>当数组大小稍大时，Numpy会占优势。</p><p>我们将比较<strong>cv.countNonZero</strong>和<strong>np.count_nonzero</strong>对于同一张图片的性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit z = np.count_nonzero(img1)</span><br></pre></td></tr></table></figure><pre><code>2.58 µs ± 321 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit z = cv.countNonZero(img1)</span><br></pre></td></tr></table></figure><pre><code>722 ns ± 25.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre><p>OpenCV 函数比 Numpy 函数快近25倍。</p><p>注意 </p><p>通常，OpenCV函数比Numpy函数要快。因此，对于相同的操作，首选OpenCV功能。</p><p>但是，可能会有例外，尤其是当Numpy处理视图而不是副本时。</p><h2 id="性能优化技术"><a href="#性能优化技术" class="headerlink" title="性能优化技术"></a>性能优化技术</h2><p>有几种技术和编码方法可以充分利用 Python 和 Numpy 的最大性能。</p><p>这里要注意的主要事情是，首先尝试以一种简单的方式实现算法。</p><p>一旦它运行起来，分析它，找到瓶颈并优化它们。</p><ul><li>尽量避免在Python中使用循环，尤其是双/三重循环等。它们本来就很慢。</li><li>由于Numpy和OpenCV已针对向量运算进行了优化，因此将算法/代码向量化到最大程度。</li><li>利用缓存一致性。</li><li>除非需要，否则切勿创建数组的副本。尝试改用视图。数组复制是一项昂贵的操作。</li><li>即使执行了所有这些操作后，如果你的代码仍然很慢，或者不可避免地需要使用大循环，请使用Cython等其他库来使其更快。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;1.&lt;a href=&quot;#header1&quot;&gt;图片的基本操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2.&lt;a href=&quot;#header2&quot;&gt;图片的算法操作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.&lt;a href=&quot;#header3&quot;&gt;性能衡量和提升技术&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>opencv-GUI特性</title>
    <link href="http://yoursite.com/2020/07/12/opencv-GUI%E7%89%B9%E6%80%A7/"/>
    <id>http://yoursite.com/2020/07/12/opencv-GUI%E7%89%B9%E6%80%A7/</id>
    <published>2020-07-12T03:20:35.000Z</published>
    <updated>2020-07-12T03:31:53.462Z</updated>
    
    <content type="html"><![CDATA[<ul><li>1.<a href="#header1">图像入门</a></li><li>2.<a href="#header2">视频入门</a></li><li>3.<a href="#header3">绘图</a></li><li>4.<a href="#header4">鼠标作为画笔</a></li><li>5.<a href="#header5">轨迹栏作为调色板</a></li></ul><h1 id="图像入门"><a href="#图像入门" class="headerlink" title="图像入门"></a><span id="header1">图像入门</span></h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul><li>在这里，你将学习如何读取图像，如何显示图像以及如何将其保存回去</li><li>你将学习以下功能：cv.imread()，cv.imshow()，cv.imwrite()</li><li>(可选)你将学习如何使用Matplotlib显示图像<a id="more"></a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="读取图像"><a href="#读取图像" class="headerlink" title="读取图像"></a>读取图像</h2><ul><li>使用<strong>cv.imread</strong>()函数读取图像。</li><li>图像应该在工作目录或图像的完整路径应给出。<br>第二个参数是一个标志，它指定了读取图像的方式。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cv.IMREAD_COLOR： 加载彩色图像。任何图像的透明度都会被忽视。它是默认标志。</span><br><span class="line">cv.IMREAD_GRAYSCALE：以灰度模式加载图像</span><br><span class="line">cv.IMREAD_UNCHANGED：加载图像，包括alpha通道</span><br></pre></td></tr></table></figure>注意 除了这三个标志，你可以分别简单地传递整数1、0或-1。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img=cv.imread(<span class="string">'1.jpg'</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img</span><br></pre></td></tr></table></figure><pre><code>array([[181, 247, 251, ..., 203, 177, 170],       [217, 255, 250, ..., 211, 178, 167],       [247, 255, 245, ..., 218, 180, 164],       ...,       [ 13,  13,  12, ...,   0,  16,   0],       [ 11,  10,  10, ...,   0,   0,   0],       [ 17,  17,  16, ...,   0,   4,   0]], dtype=uint8)</code></pre><h2 id="显示图像"><a href="#显示图像" class="headerlink" title="显示图像"></a>显示图像</h2><ul><li>使用函数<strong>cv.imshow()</strong>在窗口中显示图像。窗口自动适合图像尺寸。</li><li>第一个参数是窗口名称，它是一个字符串。</li><li>第二个参数是我们的对象。你可以根据需要创建任意多个窗口，但可以使用不同的窗口名称。</li></ul><p>cv.waitKey()是一个键盘绑定函数。其参数是以毫秒为单位的时间。</p><p>该函数等待任何键盘事件指定的毫秒。如果您在这段时间内按下任何键，程序将继续运行。</p><p>如果<strong>0</strong>被传递，它将无限期地等待一次敲击键。</p><p>它也可以设置为检测特定的按键，例如，如果按下键 a 等</p><p>cv.destroyAllWindows()只会破坏我们创建的所有窗口。</p><p>如果要销毁任何特定的窗口，请使用函数 cv.destroyWindow()在其中传递确切的窗口名称作为参数。</p><p>在特殊情况下，你可以创建一个空窗口，然后再将图像加载到该窗口。在这种情况下，你可以指定窗口是否可调整大小。</p><p>这是通过功能<strong>cv.namedWindow</strong>()完成的。默认情况下，该标志为<strong>cv.WINDOW_AUTOSIZE</strong>。</p><p>但是，如果将标志指定为<strong>cv.WINDOW_NORMAL</strong>，则可以调整窗口大小。当图像尺寸过大以及向窗口添加跟踪栏时，这将很有帮助。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cv.namedWindow(<span class="string">'image'</span>,cv.WINDOW_NORMAL)</span><br><span class="line">cv.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="写入图像"><a href="#写入图像" class="headerlink" title="写入图像"></a>写入图像</h2><p>使用函数<strong>cv.imwrite</strong>()保存图像。</p><p>第一个参数是文件名，第二个参数是要保存的图像。</p><p>cv.imwrite(‘messigray.png’，img)这会将图像以PNG格式保存在工作目录中。</p><p>在下面的程序中，以灰度加载图像，显示图像，按s保存图像并退出，或者按ESC键直接退出而不保存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'1.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">k =cv.waitKey(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> k == <span class="number">27</span>: <span class="comment"># 按下esc时</span></span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"><span class="keyword">elif</span> k == ord(<span class="string">'s'</span>): <span class="comment"># 按下s时</span></span><br><span class="line">    cv.imwrite(<span class="string">'copy1.jpg'</span>,img)</span><br><span class="line">    cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">img = cv.imread(<span class="string">'1.jpg'</span>,<span class="number">0</span>)</span><br><span class="line">plt.imshow(img, interpolation = <span class="string">'bicubic'</span>)</span><br><span class="line"><span class="comment"># plt.imshow(img)</span></span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/12/opencv-GUI%E7%89%B9%E6%80%A7/output_13_0.png" alt="png"></p><h1 id="视频入门"><a href="#视频入门" class="headerlink" title="视频入门"></a><span id="header2">视频入门</span></h1><h2 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h2><ul><li>学习读取视频，显示视频和保存视频。</li><li>学习从相机捕捉并显示它。</li><li>你将学习以下功能：cv.VideoCapture()，cv.VideoWriter()<!--more--></li></ul><p>要捕获视频，你需要创建一个 VideoCapture 对象。</p><p>它的参数可以是设备索引或视频文件的名称。设备索引就是指定哪个摄像头的数字。</p><p>正常情况下，一个摄像头会被连接(就像我的情况一样)。所以我简单地传0(或-1)。你可以通过传递1来选择第二个相机，以此类推。</p><p>在此之后，你可以逐帧捕获。但是在最后，不要忘记释放俘虏。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">cap = cv.VideoCapture(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> cap.isOpened():</span><br><span class="line">    print(<span class="string">"Cannot open camera"</span>)</span><br><span class="line">    exit()</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 逐帧捕获</span></span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="comment"># 如果正确读取帧，ret为True</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        print(<span class="string">"Can't receive frame (stream end?). Exiting ..."</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 我们在框架上的操作到这里</span></span><br><span class="line">    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># 显示结果帧e</span></span><br><span class="line">    cv.imshow(<span class="string">'frame'</span>, gray)</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">1</span>) == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="comment"># 完成所有操作后，释放捕获器</span></span><br><span class="line">cap.release()</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><pre><code>Cannot open cameraCan&apos;t receive frame (stream end?). Exiting ...</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">cap = cv.VideoCapture(<span class="string">'video1.flv'</span>)</span><br><span class="line"><span class="keyword">while</span> cap.isOpened():</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="comment"># 如果正确读取帧，ret为True</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        print(<span class="string">"Can't receive frame (stream end?). Exiting ..."</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)</span><br><span class="line">    cv.imshow(<span class="string">'frame'</span>, gray)</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">1</span>) == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cap.release()</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">cap = cv.VideoCapture(<span class="string">'video1.flv'</span>)</span><br><span class="line"><span class="comment"># 定义编解码器并创建VideoWriter对象</span></span><br><span class="line">fourcc = cv.VideoWriter_fourcc(*<span class="string">'DIVX'</span>)</span><br><span class="line">out = cv.VideoWriter(<span class="string">'output.flv'</span>, fourcc, <span class="number">20.0</span>, (<span class="number">640</span>,  <span class="number">480</span>))</span><br><span class="line"><span class="keyword">while</span> cap.isOpened():</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        print(<span class="string">"Can't receive frame (stream end?). Exiting ..."</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    frame = cv.flip(frame, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 写翻转的框架</span></span><br><span class="line">    out.write(frame)</span><br><span class="line">    cv.imshow(<span class="string">'frame'</span>, frame)</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">1</span>) == ord(<span class="string">'q'</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="comment"># 完成工作后释放所有内容</span></span><br><span class="line">cap.release()</span><br><span class="line">out.release()</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><pre><code>Can&apos;t receive frame (stream end?). Exiting ...</code></pre><h1 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a><span id="header3">绘图</span></h1><h2 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a>目标</h2><ul><li>学习使用OpenCV绘制不同的几何形状</li><li>您将学习以下功能：cv.line()，cv.circle()，cv.rectangle()，cv.ellipse()，cv.putText()等。</li><li>在上述所有功能中，您将看到一些常见的参数，如下所示：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img：您要绘制形状的图像</span><br><span class="line">color：形状的颜色。对于BGR，将其作为元组传递，例如：(255,0,0)对于蓝色。对于灰度，只需传递标量值即可。</span><br><span class="line">厚度：线或圆等的粗细。如果对闭合图形（如圆）传递-1 ，它将填充形状。默认厚度&#x3D; 1</span><br><span class="line">lineType：线的类型，是否为8连接线，抗锯齿线等。默认情况下，为8连接线。**cv.LINE_AA**给出了抗锯齿的线条，看起来非常适合曲线。</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制一条线，您需要传递线的开始和结束坐标。我们将创建一个黑色图像，并从左上角到右下角在其上绘制一条蓝线。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line"><span class="comment"># 绘制一条厚度为5的蓝色对角线</span></span><br><span class="line">cv.line(img,(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">511</span>,<span class="number">511</span>),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">5</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制矩形，您需要矩形的左上角和右下角。这次，我们将在图像的右上角绘制一个绿色矩形。</span></span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">cv.rectangle(img,(<span class="number">384</span>,<span class="number">0</span>),(<span class="number">510</span>,<span class="number">128</span>),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">3</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制一个圆，需要其中心坐标和半径。我们将在上面绘制的矩形内绘制一个圆。</span></span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">cv.circle(img,(<span class="number">447</span>,<span class="number">63</span>), <span class="number">63</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">-1</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制椭圆，我们需要传递几个参数。一个参数是中心位置（x，y）。</span></span><br><span class="line"><span class="comment"># 下一个参数是轴长度（长轴长度，短轴长度）。</span></span><br><span class="line"><span class="comment"># angle是椭圆沿逆时针方向旋转的角度。</span></span><br><span class="line"><span class="comment"># startAngle和endAngle表示从主轴沿顺时针方向测量的椭圆弧的开始和结束。即给出0和360给出完整的椭圆</span></span><br><span class="line"><span class="comment"># 下面的示例在图像的中心绘制一个椭圆形。</span></span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">cv.ellipse(img,(<span class="number">256</span>,<span class="number">256</span>),(<span class="number">100</span>,<span class="number">50</span>),<span class="number">0</span>,<span class="number">0</span>,<span class="number">180</span>,<span class="number">255</span>,<span class="number">-1</span>)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制多边形，首先需要顶点的坐标。将这些点组成形状为ROWSx1x2的数组，其中ROWS是顶点数，并且其类型应为int32。</span></span><br><span class="line"><span class="comment"># 在这里，我们绘制了一个带有四个顶点的黄色小多边形。</span></span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">pts = np.array([[<span class="number">10</span>,<span class="number">5</span>],[<span class="number">20</span>,<span class="number">30</span>],[<span class="number">270</span>,<span class="number">20</span>],[<span class="number">150</span>,<span class="number">5</span>]], np.int32)</span><br><span class="line">pts = pts.reshape((<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">cv.polylines(img,[pts],<span class="literal">True</span>,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果第三个参数为False，您将获得一条连接所有点的折线，而不是闭合形状。 </span></span><br><span class="line"><span class="comment"># cv.polylines()可用于绘制多条线。只需创建要绘制的所有线条的列表，然后将其传递给函数即可。</span></span><br><span class="line"><span class="comment"># 所有线条将单独绘制。与为每条线调用**cv.line**相比，绘制一组线是一种更好，更快的方法。</span></span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">pts = np.array([[<span class="number">10</span>,<span class="number">5</span>],[<span class="number">20</span>,<span class="number">30</span>],[<span class="number">270</span>,<span class="number">20</span>],[<span class="number">150</span>,<span class="number">5</span>]], np.int32)</span><br><span class="line">pts = pts.reshape((<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">cv.polylines(img,[pts],<span class="literal">False</span>,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要将文本放入图像中，需要指定以下内容。 </span></span><br><span class="line"><span class="comment"># - 您要写入的文字数据 </span></span><br><span class="line"><span class="comment"># - 您要放置它的位置坐标（即数据开始的左下角）。 </span></span><br><span class="line"><span class="comment"># - 字体类型（检查**cv.putText**文档以获取受支持的字体）</span></span><br><span class="line"><span class="comment"># - 字体比例（指定字体大小） </span></span><br><span class="line"><span class="comment"># - 常规的内容，例如颜色，厚度，线条类型等。为了获得更好的外观，建议使用lineType = cv.LINE_AA。</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">font = cv.FONT_HERSHEY_SIMPLEX</span><br><span class="line">cv.putText(img,<span class="string">'OpenCV'</span>,(<span class="number">10</span>,<span class="number">500</span>), font, <span class="number">4</span>,(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>),<span class="number">2</span>,cv.LINE_AA)</span><br><span class="line">cv.imshow(<span class="string">'img'</span>,img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h1 id="鼠标作为画笔"><a href="#鼠标作为画笔" class="headerlink" title="鼠标作为画笔"></a><span id="header4">鼠标作为画笔</span></h1><h2 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a>目标</h2><ul><li>了解如何在OpenCV中处理鼠标事件</li><li>您将学习以下功能：cv.setMouseCallback()</li></ul><p>简单演示<br>在这里，我们创建一个简单的应用程序，无论我们在哪里双击它，都可以在图像上绘制一个圆。</p><p>首先，我们创建一个鼠标回调函数，该函数在发生鼠标事件时执行。</p><p>鼠标事件可以是与鼠标相关的任何事物，例如左键按下，左键按下，左键双击等。</p><p>它为我们提供了每个鼠标事件的坐标(x，y)。通过此活动和地点，我们可以做任何我们喜欢的事情。</p><p>要列出所有可用的可用事件，请在Python终端中运行以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">events = [i <span class="keyword">for</span> i <span class="keyword">in</span> dir(cv) <span class="keyword">if</span> <span class="string">'EVENT'</span> <span class="keyword">in</span> i]</span><br><span class="line">print( events )</span><br></pre></td></tr></table></figure><pre><code>[&apos;EVENT_FLAG_ALTKEY&apos;, &apos;EVENT_FLAG_CTRLKEY&apos;, &apos;EVENT_FLAG_LBUTTON&apos;, &apos;EVENT_FLAG_MBUTTON&apos;, &apos;EVENT_FLAG_RBUTTON&apos;, &apos;EVENT_FLAG_SHIFTKEY&apos;, &apos;EVENT_LBUTTONDBLCLK&apos;, &apos;EVENT_LBUTTONDOWN&apos;, &apos;EVENT_LBUTTONUP&apos;, &apos;EVENT_MBUTTONDBLCLK&apos;, &apos;EVENT_MBUTTONDOWN&apos;, &apos;EVENT_MBUTTONUP&apos;, &apos;EVENT_MOUSEHWHEEL&apos;, &apos;EVENT_MOUSEMOVE&apos;, &apos;EVENT_MOUSEWHEEL&apos;, &apos;EVENT_RBUTTONDBLCLK&apos;, &apos;EVENT_RBUTTONDOWN&apos;, &apos;EVENT_RBUTTONUP&apos;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在我们双击的地方绘制一个圆圈</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="comment"># 鼠标回调函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_circle</span><span class="params">(event,x,y,flags,param)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> event == cv.EVENT_LBUTTONDBLCLK:</span><br><span class="line">        cv.circle(img,(x,y),<span class="number">100</span>,(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line"><span class="comment"># 创建一个黑色的图像，一个窗口，并绑定到窗口的功能</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">cv.namedWindow(<span class="string">'image'</span>)</span><br><span class="line">cv.setMouseCallback(<span class="string">'image'</span>,draw_circle)</span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    cv.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按m之前拖拽画青色矩形</span></span><br><span class="line"><span class="comment"># 按m之后拖拽画红色直线</span></span><br><span class="line"><span class="comment"># 按esc退出</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">drawing = <span class="literal">False</span> <span class="comment"># 如果按下鼠标，则为真</span></span><br><span class="line">mode = <span class="literal">True</span> <span class="comment"># 如果为真，绘制矩形。按 m 键可以切换到曲线</span></span><br><span class="line">ix,iy = <span class="number">-1</span>,<span class="number">-1</span></span><br><span class="line"><span class="comment"># 鼠标回调函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_circle</span><span class="params">(event,x,y,flags,param)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> ix,iy,drawing,mode</span><br><span class="line">    <span class="keyword">if</span> event == cv.EVENT_LBUTTONDOWN:</span><br><span class="line">        drawing = <span class="literal">True</span></span><br><span class="line">        ix,iy = x,y</span><br><span class="line">    <span class="keyword">elif</span> event == cv.EVENT_MOUSEMOVE:</span><br><span class="line">        <span class="keyword">if</span> drawing == <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="literal">True</span>:</span><br><span class="line">                cv.rectangle(img,(ix,iy),(x,y),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cv.circle(img,(x,y),<span class="number">25</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">elif</span> event == cv.EVENT_LBUTTONUP:</span><br><span class="line">        drawing = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="literal">True</span>:</span><br><span class="line">            cv.rectangle(img,(ix,iy),(x,y),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cv.circle(img,(x,y),<span class="number">25</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),<span class="number">-1</span>)</span><br><span class="line">            </span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">cv.namedWindow(<span class="string">'image'</span>)</span><br><span class="line">cv.setMouseCallback(<span class="string">'image'</span>,draw_circle)</span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    cv.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">20</span>) &amp; cv.waitKey(<span class="number">20</span>) == ord(<span class="string">'m'</span>):</span><br><span class="line">        mode = ~mode</span><br><span class="line">    <span class="keyword">if</span> cv.waitKey(<span class="number">20</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure><h1 id="轨迹栏作为调色板"><a href="#轨迹栏作为调色板" class="headerlink" title="轨迹栏作为调色板"></a><span id="header5">轨迹栏作为调色板</span></h1><h2 id="目标-4"><a href="#目标-4" class="headerlink" title="目标"></a>目标</h2><ul><li>了解将轨迹栏固定到OpenCV窗口</li><li>您将学习以下功能：cv.getTrackbarPos，<strong>cv.createTrackbar</strong>等。</li></ul><p>对于cv.getTrackbarPos()函数，</p><p>第一个参数是轨迹栏名称，</p><p>第二个参数是它附加到的窗口名称，</p><p>第三个参数是默认值，</p><p>第四个参数是最大值，</p><p>第五个是执行的回调函数每次跟踪栏值更改。</p><p>回调函数始终具有默认参数，即轨迹栏位置。</p><p>在我们的例子中，函数什么都不做，所以我们简单地通过。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在这里，我们将创建一个简单的应用程序，以显示您指定的颜色。</span></span><br><span class="line"><span class="comment"># 您有一个显示颜色的窗口，以及三个用于指定B、G、R颜色的跟踪栏。滑动轨迹栏，并相应地更改窗口颜色。</span></span><br><span class="line"><span class="comment"># 默认情况下，初始颜色将设置为黑色。只有在该开关为ON的情况下，该应用程序才能在其中运行，否则屏幕始终为黑色。</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nothing</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 创建一个黑色的图像，一个窗口</span></span><br><span class="line">img = np.zeros((<span class="number">300</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line">cv.namedWindow(<span class="string">'image'</span>)</span><br><span class="line"><span class="comment"># 创建颜色变化的轨迹栏</span></span><br><span class="line">cv.createTrackbar(<span class="string">'R'</span>,<span class="string">'image'</span>,<span class="number">0</span>,<span class="number">255</span>,nothing)</span><br><span class="line">cv.createTrackbar(<span class="string">'G'</span>,<span class="string">'image'</span>,<span class="number">0</span>,<span class="number">255</span>,nothing)</span><br><span class="line">cv.createTrackbar(<span class="string">'B'</span>,<span class="string">'image'</span>,<span class="number">0</span>,<span class="number">255</span>,nothing)</span><br><span class="line"><span class="comment"># 为 ON/OFF 功能创建开关</span></span><br><span class="line">switch = <span class="string">'0 : OFF \n1 : ON'</span></span><br><span class="line">cv.createTrackbar(switch, <span class="string">'image'</span>,<span class="number">0</span>,<span class="number">1</span>,nothing)</span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">    cv.imshow(<span class="string">'image'</span>,img)</span><br><span class="line">    k = cv.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span></span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 得到四条轨迹的当前位置</span></span><br><span class="line">    r = cv.getTrackbarPos(<span class="string">'R'</span>,<span class="string">'image'</span>)</span><br><span class="line">    g = cv.getTrackbarPos(<span class="string">'G'</span>,<span class="string">'image'</span>)</span><br><span class="line">    b = cv.getTrackbarPos(<span class="string">'B'</span>,<span class="string">'image'</span>)</span><br><span class="line">    s = cv.getTrackbarPos(switch,<span class="string">'image'</span>)</span><br><span class="line">    <span class="keyword">if</span> s == <span class="number">0</span>:</span><br><span class="line">        img[:] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        img[:] = [b,g,r]</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;1.&lt;a href=&quot;#header1&quot;&gt;图像入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2.&lt;a href=&quot;#header2&quot;&gt;视频入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;3.&lt;a href=&quot;#header3&quot;&gt;绘图&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;4.&lt;a href=&quot;#header4&quot;&gt;鼠标作为画笔&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;5.&lt;a href=&quot;#header5&quot;&gt;轨迹栏作为调色板&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;图像入门&quot;&gt;&lt;a href=&quot;#图像入门&quot; class=&quot;headerlink&quot; title=&quot;图像入门&quot;&gt;&lt;/a&gt;&lt;span id=&quot;header1&quot;&gt;图像入门&lt;/span&gt;&lt;/h1&gt;&lt;h2 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;在这里，你将学习如何读取图像，如何显示图像以及如何将其保存回去&lt;/li&gt;
&lt;li&gt;你将学习以下功能：cv.imread()，cv.imshow()，cv.imwrite()&lt;/li&gt;
&lt;li&gt;(可选)你将学习如何使用Matplotlib显示图像&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="opencv" scheme="http://yoursite.com/categories/opencv/"/>
    
    
      <category term="opencv" scheme="http://yoursite.com/tags/opencv/"/>
    
      <category term="图像" scheme="http://yoursite.com/tags/%E5%9B%BE%E5%83%8F/"/>
    
  </entry>
  
  <entry>
    <title>岭回归</title>
    <link href="http://yoursite.com/2020/07/11/%E5%B2%AD%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/07/11/%E5%B2%AD%E5%9B%9E%E5%BD%92/</id>
    <published>2020-07-11T08:20:38.000Z</published>
    <updated>2020-07-11T08:28:09.049Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/longley.csv" target="_blank" rel="noopener">longley.csv</a></p><a id="more"></a><p><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%991.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%992.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%993.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%994.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%995.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%996.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%997.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%998.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%999.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%9910.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%9911.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%9912.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%9913.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%AD%A3%E5%88%9914.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> genfromtxt</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = genfromtxt(<span class="string">'./data/longley.csv'</span>, delimiter=<span class="string">','</span>)</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure><pre><code>[[     nan      nan      nan      nan      nan      nan      nan      nan] [     nan   83.     234.289  235.6    159.     107.608 1947.      60.323] [     nan   88.5    259.426  232.5    145.6    108.632 1948.      61.122] [     nan   88.2    258.054  368.2    161.6    109.773 1949.      60.171] [     nan   89.5    284.599  335.1    165.     110.929 1950.      61.187] [     nan   96.2    328.975  209.9    309.9    112.075 1951.      63.221] [     nan   98.1    346.999  193.2    359.4    113.27  1952.      63.639] [     nan   99.     365.385  187.     354.7    115.094 1953.      64.989] [     nan  100.     363.112  357.8    335.     116.219 1954.      63.761] [     nan  101.2    397.469  290.4    304.8    117.388 1955.      66.019] [     nan  104.6    419.18   282.2    285.7    118.734 1956.      67.857] [     nan  108.4    442.769  293.6    279.8    120.445 1957.      68.169] [     nan  110.8    444.546  468.1    263.7    121.95  1958.      66.513] [     nan  112.6    482.704  381.3    255.2    123.366 1959.      68.655] [     nan  114.2    502.601  393.1    251.4    125.368 1960.      69.564] [     nan  115.7    518.173  480.6    257.2    127.852 1961.      69.331] [     nan  116.9    554.894  400.7    282.7    130.081 1962.      70.551]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_data = data[<span class="number">1</span>:,<span class="number">2</span>:]</span><br><span class="line">y_data = data[<span class="number">1</span>:,<span class="number">1</span>,np.newaxis]</span><br><span class="line">print(x_data)</span><br><span class="line">print(y_data)</span><br></pre></td></tr></table></figure><pre><code>[[ 234.289  235.6    159.     107.608 1947.      60.323] [ 259.426  232.5    145.6    108.632 1948.      61.122] [ 258.054  368.2    161.6    109.773 1949.      60.171] [ 284.599  335.1    165.     110.929 1950.      61.187] [ 328.975  209.9    309.9    112.075 1951.      63.221] [ 346.999  193.2    359.4    113.27  1952.      63.639] [ 365.385  187.     354.7    115.094 1953.      64.989] [ 363.112  357.8    335.     116.219 1954.      63.761] [ 397.469  290.4    304.8    117.388 1955.      66.019] [ 419.18   282.2    285.7    118.734 1956.      67.857] [ 442.769  293.6    279.8    120.445 1957.      68.169] [ 444.546  468.1    263.7    121.95  1958.      66.513] [ 482.704  381.3    255.2    123.366 1959.      68.655] [ 502.601  393.1    251.4    125.368 1960.      69.564] [ 518.173  480.6    257.2    127.852 1961.      69.331] [ 554.894  400.7    282.7    130.081 1962.      70.551]][[ 83. ] [ 88.5] [ 88.2] [ 89.5] [ 96.2] [ 98.1] [ 99. ] [100. ] [101.2] [104.6] [108.4] [110.8] [112.6] [114.2] [115.7] [116.9]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(np.mat(x_data).shape)</span><br><span class="line">print(np.mat(y_data).shape)</span><br><span class="line">X_data = np.concatenate((np.ones((<span class="number">16</span>,<span class="number">1</span>)),x_data),axis=<span class="number">1</span>)</span><br><span class="line">print(X_data.shape)</span><br></pre></td></tr></table></figure><pre><code>(16, 6)(16, 1)(16, 7)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(X_data[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>[[1.00000e+00 2.34289e+02 2.35600e+02 1.59000e+02 1.07608e+02 1.94700e+03  6.03230e+01] [1.00000e+00 2.59426e+02 2.32500e+02 1.45600e+02 1.08632e+02 1.94800e+03  6.11220e+01] [1.00000e+00 2.58054e+02 3.68200e+02 1.61600e+02 1.09773e+02 1.94900e+03  6.01710e+01]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights</span><span class="params">(xArr,yArr,lam=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">    xMat = np.mat(xArr)</span><br><span class="line">    yMat = np.mat(yArr)</span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    rxTx = xTx +np.eye(xMat.shape[<span class="number">1</span>])*lam</span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(rxTx) == <span class="number">0.0</span>:</span><br><span class="line">        print(<span class="string">'This martix cannot do inverse'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    ws = rxTx.I*xMat.T*yMat</span><br><span class="line">    <span class="keyword">return</span> ws</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ws = weights(X_data,y_data)</span><br><span class="line">print(ws)</span><br></pre></td></tr></table></figure><pre><code>[[ 7.38107363e-04] [ 2.07703836e-01] [ 2.10076376e-02] [ 5.05385441e-03] [-1.59173066e+00] [ 1.10442920e-01] [-2.42280461e-01]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.mat(X_data)* np.mat(ws)</span><br></pre></td></tr></table></figure><pre><code>matrix([[ 83.55075226],        [ 86.92588689],        [ 88.09720227],        [ 90.95677622],        [ 96.06951002],        [ 97.81955375],        [ 98.36444357],        [ 99.99814266],        [103.26832266],        [105.03165135],        [107.45224671],        [109.52190685],        [112.91863666],        [113.98357055],        [115.29845063],        [117.64279933]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/longley.csv&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;longley.csv&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="http://yoursite.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>标准方程法</title>
    <link href="http://yoursite.com/2020/07/11/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%95/"/>
    <id>http://yoursite.com/2020/07/11/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%95/</id>
    <published>2020-07-11T08:03:11.000Z</published>
    <updated>2020-07-11T08:06:09.113Z</updated>
    
    <content type="html"><![CDATA[<p>标准方程法求线性回归代码展示:<br>数据集下载<a href="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/data.csv" target="_blank" rel="noopener">data</a></p><a id="more"></a><p><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%951.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%952.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%953.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%954.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%955.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%956.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%957.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%958.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> genfromtxt</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data =np.genfromtxt(<span class="string">'./data/data.csv'</span>, delimiter=<span class="string">','</span>)</span><br><span class="line">x_data = data[:,<span class="number">0</span>,np.newaxis]</span><br><span class="line">y_data = data[:,<span class="number">1</span>,np.newaxis]</span><br><span class="line">plt.scatter(x_data,y_data)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/11/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%95/output_2_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(np.mat(x_data).shape)</span><br><span class="line">print(np.mat(y_data).shape)</span><br><span class="line">X_data = np.concatenate((np.ones((<span class="number">100</span>,<span class="number">1</span>)),x_data),axis=<span class="number">1</span>)</span><br><span class="line">print(X_data.shape)</span><br></pre></td></tr></table></figure><pre><code>(100, 1)(100, 1)(100, 2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(X_data[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>[[ 1.         32.50234527] [ 1.         53.42680403] [ 1.         61.53035803]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights</span><span class="params">(xArr,yArr)</span>:</span></span><br><span class="line">    xMat = np.mat(xArr)</span><br><span class="line">    yMat = np.mat(yArr)</span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(xTx) ==<span class="number">0.0</span>:</span><br><span class="line">        print(<span class="string">'This martix cannot do inverse'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    ws = xTx.I*xMat.T*yMat</span><br><span class="line">    <span class="keyword">return</span> ws</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ws = weights(X_data,y_data)</span><br><span class="line">print(ws)</span><br></pre></td></tr></table></figure><pre><code>[[7.99102098] [1.32243102]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_test = np.array([[<span class="number">20</span>],[<span class="number">80</span>]])</span><br><span class="line">y_test = ws[<span class="number">0</span>]+x_test*ws[<span class="number">1</span>]</span><br><span class="line">plt.plot(x_data,y_data,<span class="string">'b.'</span>)</span><br><span class="line">plt.plot(x_test,y_test,<span class="string">'r'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/11/%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%95/output_7_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;标准方程法求线性回归代码展示:&lt;br&gt;数据集下载&lt;a href=&quot;http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/data.csv&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;data&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="http://yoursite.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>集成学习voting</title>
    <link href="http://yoursite.com/2020/07/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0voting/"/>
    <id>http://yoursite.com/2020/07/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0voting/</id>
    <published>2020-07-11T07:43:06.000Z</published>
    <updated>2020-07-11T07:44:20.704Z</updated>
    
    <content type="html"><![CDATA[<p>voting代码简单演示</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">x_data,y_data = iris.data[:,<span class="number">1</span>:<span class="number">3</span>],iris.target</span><br><span class="line">clf1 = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">clf2 = DecisionTreeClassifier()</span><br><span class="line">clf3 = LogisticRegression()</span><br><span class="line"></span><br><span class="line">sclf = VotingClassifier([(<span class="string">'knn'</span>,clf1),(<span class="string">'dtree'</span>,clf2),(<span class="string">'lr'</span>,clf3)])</span><br><span class="line"><span class="keyword">for</span> clf,label <span class="keyword">in</span> zip([clf1,clf2,clf3,sclf],</span><br><span class="line">                    [<span class="string">'KNN'</span>,<span class="string">'Decistion Tree'</span>,<span class="string">'LogisticRegression'</span>,<span class="string">'VotingClassifier'</span>]):</span><br><span class="line">    scores = model_selection.cross_val_score(clf,x_data,y_data,cv=<span class="number">3</span>,scoring=<span class="string">'accuracy'</span>)</span><br><span class="line">    print(<span class="string">'Accuracy: %0.2f[%s]'</span> %(scores.mean(),label))</span><br></pre></td></tr></table></figure><pre><code>Accuracy: 0.91[KNN]Accuracy: 0.90[Decistion Tree]Accuracy: 0.91[LogisticRegression]Accuracy: 0.92[VotingClassifier]C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:460: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning.  &quot;this warning.&quot;, FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:460: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning.  &quot;this warning.&quot;, FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:460: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning.  &quot;this warning.&quot;, FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:460: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning.  &quot;this warning.&quot;, FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:460: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning.  &quot;this warning.&quot;, FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &apos;lbfgs&apos; in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\linear_model\logistic.py:460: FutureWarning: Default multi_class will be changed to &apos;auto&apos; in 0.22. Specify the multi_class option to silence this warning.  &quot;this warning.&quot;, FutureWarning)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;voting代码简单演示&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="集成学习" scheme="http://yoursite.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>集成学习stacking</title>
    <link href="http://yoursite.com/2020/07/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0stacking/"/>
    <id>http://yoursite.com/2020/07/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0stacking/</id>
    <published>2020-07-11T07:34:47.000Z</published>
    <updated>2020-07-11T07:52:07.138Z</updated>
    
    <content type="html"><![CDATA[<p>stacking代码简单演示</p><a id="more"></a><p><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/stack1.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/stack2.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/stack3.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> mlxtend.classifier <span class="keyword">import</span> StackingClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">x_data,y_data=iris.data[:,<span class="number">1</span>:<span class="number">3</span>],iris.target</span><br><span class="line">clf1 = KNeighborsClassifier(n_neighbors=<span class="number">1</span>)</span><br><span class="line">clf2 = DecisionTreeClassifier()</span><br><span class="line">clf3 = LogisticRegression()</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">sclf = StackingClassifier(classifiers=[clf1,clf2,clf3],meta_classifier=lr)</span><br><span class="line"><span class="keyword">for</span> clf,label <span class="keyword">in</span> zip([clf1,clf2,clf3,sclf],</span><br><span class="line">                    [<span class="string">'KNN'</span>,<span class="string">'Decision Tree'</span>,<span class="string">'LogisticRegression'</span>,<span class="string">'StackingClassifier'</span>]):</span><br><span class="line">    scores = model_selection.cross_val_score(clf,x_data,y_data,cv=<span class="number">3</span>,scoring=<span class="string">'accuracy'</span>)</span><br><span class="line">    print(<span class="string">'Accuracy:%0.2f [%s]'</span> %(scores.mean(),label))</span><br></pre></td></tr></table></figure><pre><code>Accuracy:0.91 [KNN]Accuracy:0.93 [Decision Tree]Accuracy:0.95 [LogisticRegression]Accuracy:0.93 [StackingClassifier]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;stacking代码简单演示&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="集成学习" scheme="http://yoursite.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>PCA</title>
    <link href="http://yoursite.com/2020/07/11/PCA/"/>
    <id>http://yoursite.com/2020/07/11/PCA/</id>
    <published>2020-07-11T07:21:40.000Z</published>
    <updated>2020-07-11T07:22:57.828Z</updated>
    
    <content type="html"><![CDATA[<p>PCA简单代码展示:</p><a id="more"></a><p><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA1.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA2.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA3.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA4.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA5.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA6.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA7.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA8.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA9.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PCA10.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report,confusion_matrix</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">digits = load_digits()</span><br><span class="line">x_data = digits.data</span><br><span class="line">y_data = digits.target</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x_data,y_data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_data.shape</span><br></pre></td></tr></table></figure><pre><code>(1797, 64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">100</span>,<span class="number">50</span>), max_iter=<span class="number">500</span>)</span><br><span class="line">mlp.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>MLPClassifier(activation=&apos;relu&apos;, alpha=0.0001, batch_size=&apos;auto&apos;, beta_1=0.9,              beta_2=0.999, early_stopping=False, epsilon=1e-08,              hidden_layer_sizes=(100, 50), learning_rate=&apos;constant&apos;,              learning_rate_init=0.001, max_fun=15000, max_iter=500,              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,              power_t=0.5, random_state=None, shuffle=True, solver=&apos;adam&apos;,              tol=0.0001, validation_fraction=0.1, verbose=False,              warm_start=False)</code></pre><p>协方差代码形式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">函数原型：def cov(m, y&#x3D;None, rowvar&#x3D;True, bias&#x3D;False, ddof&#x3D;None, fweights&#x3D;None,aweights&#x3D;None)</span><br><span class="line">m:一维或则二维的数组，默认情况下每一行代表一个变量（属性），每一列代表一个观测</span><br><span class="line">y:与m具有一样的形式的一组数据</span><br><span class="line">rowvar:默认为True,此时每一行代表一个变量（属性），每一列代表一个观测；为False时，则反之</span><br><span class="line">bias:默认为False,此时标准化时除以n-1；反之为n。其中n为观测数</span><br><span class="line">ddof:类型是int，当其值非None时，bias参数作用将失效。当ddof&#x3D;1时，将会返回无偏估计（除以n-1），即使指定了fweights和aweights参数；当ddof&#x3D;0时，则返回简单平均值。</span><br><span class="line">frequency weights:一维数组，代表每个观测要重复的次数（相当于给观测赋予权重）</span><br><span class="line">analytic weights:一维数组，代表观测矢量权重。对于被认为“重要”的观察,这些相对权重通常很大,而对于被认为不太重要的观察,这些相对权重较小。如果ddof &#x3D; 0,则可以使用权重数组将概率分配给观测向量。</span><br></pre></td></tr></table></figure><p>代码示例<br>基本使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 计算协方差的时候，一行代表一个特征</span><br><span class="line"># 下面计算cov(T, S, M)</span><br><span class="line">T &#x3D; np.array([9, 15, 25, 14, 10, 18, 0, 16, 5, 19, 16, 20])</span><br><span class="line">S &#x3D; np.array([39, 56, 93, 61, 50, 75, 32, 85, 42, 70, 66, 80])</span><br><span class="line">M &#x3D; np.asarray([38, 56, 90, 63, 56, 77, 30, 80, 41, 79, 64, 88])</span><br><span class="line">X &#x3D; np.vstack((T, S, M))</span><br><span class="line"># X每行代表一个属性</span><br><span class="line">#  每列代表一个示例，或者说观测</span><br><span class="line">print(np.cov(X))</span><br><span class="line"></span><br><span class="line"># [[ 47.71969697 122.9469697  129.59090909]</span><br><span class="line">#  [122.9469697  370.08333333 374.59090909]</span><br><span class="line">#  [129.59090909 374.59090909 399.        ]]</span><br></pre></td></tr></table></figure><p>重点：协方差矩阵计算的是不同维度之间的协方差，而不是不同样本之间。拿到一个样本矩阵，首先要明确的就是行代表什么，列代表什么。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zeroMean</span><span class="params">(dataMat)</span>:</span></span><br><span class="line">    meanVal = np.mean(dataMat, axis=<span class="number">0</span>)</span><br><span class="line">    newData = dataMat - meanVal</span><br><span class="line">    <span class="keyword">return</span> newData, meanVal</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca</span><span class="params">(dataMat,top)</span>:</span></span><br><span class="line">    newData, meanVal = zeroMean(dataMat)</span><br><span class="line">    covMat = np.cov(newData,rowvar=<span class="number">0</span>) <span class="comment"># 求样本的协方差矩阵。</span></span><br><span class="line">    eigVals,eigVects = np.linalg.eig(np.mat(covMat)) <span class="comment"># 对协方差1m 𝑋𝑋𝑇矩阵做特征值分解。</span></span><br><span class="line">    eigValIndice = np.argsort(eigVals)</span><br><span class="line">    n_eigValIndice = eigValIndice[<span class="number">-1</span>:-(top+<span class="number">1</span>):<span class="number">-1</span>] <span class="comment"># 选出最大的k个特征值对应的k个特征向量。</span></span><br><span class="line">    n_eigVect = eigVects[:,n_eigValIndice]</span><br><span class="line">    lowDDataMat = newData*n_eigVect <span class="comment"># 将原始数据投影到选取的特征向量上。</span></span><br><span class="line">    reconMat = (lowDDataMat*n_eigVect.T)+meanVal</span><br><span class="line">    <span class="keyword">return</span> lowDDataMat,reconMat</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lowDDataMat,reconMat = pca(x_data,<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.array(lowDDataMat)[:,<span class="number">0</span>]</span><br><span class="line">y = np.array(lowDDataMat)[:,<span class="number">1</span>]</span><br><span class="line">plt.scatter(x,y,c=<span class="string">'r'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/11/PCA/output_8_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = mlp.predict(x_data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.array(lowDDataMat)[:,<span class="number">0</span>]</span><br><span class="line">y = np.array(lowDDataMat)[:,<span class="number">1</span>]</span><br><span class="line">plt.scatter(x,y,c=y_data)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/11/PCA/output_10_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lowDDataMat,reconMat = pca(x_data,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">x = np.array(lowDDataMat)[:,<span class="number">0</span>]</span><br><span class="line">y = np.array(lowDDataMat)[:,<span class="number">1</span>]</span><br><span class="line">z = np.array(lowDDataMat)[:,<span class="number">2</span>]</span><br><span class="line">ax = plt.figure().add_subplot(<span class="number">111</span>,projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.scatter(x,y,z,c=y_data,s=<span class="number">10</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/07/11/PCA/output_12_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PCA简单代码展示:&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="主成分分析" scheme="http://yoursite.com/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯单词拼写器</title>
    <link href="http://yoursite.com/2020/07/11/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8D%95%E8%AF%8D%E6%8B%BC%E5%86%99%E5%99%A8/"/>
    <id>http://yoursite.com/2020/07/11/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8D%95%E8%AF%8D%E6%8B%BC%E5%86%99%E5%99%A8/</id>
    <published>2020-07-11T03:51:14.000Z</published>
    <updated>2020-07-11T03:51:55.017Z</updated>
    
    <content type="html"><![CDATA[<p>贝叶斯单词拼写器代码:<br>数据集下载:<a href="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/big.txt" target="_blank" rel="noopener">big.txt</a></p><a id="more"></a><p><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF1.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF2.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF3.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF4.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF5.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF6.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF7.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF8.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF9.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF10.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF11.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF12.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF13.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF14.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF15.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF16.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF17.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF18.png" alt><br><img src="http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF19.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text = open(<span class="string">'./data/big.txt'</span>).read()</span><br><span class="line">text = re.findall(<span class="string">'[a-z]+'</span>, text.lower())</span><br><span class="line">dic_words = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> text:</span><br><span class="line">    dic_words[t]=dic_words.get(t,<span class="number">0</span>)+<span class="number">1</span></span><br><span class="line">dic_words</span><br></pre></td></tr></table></figure><pre><code>{&apos;the&apos;: 80030, &apos;project&apos;: 288, &apos;gutenberg&apos;: 263, &apos;ebook&apos;: 87, &apos;of&apos;: 40025, &apos;adventures&apos;: 17, &apos;sherlock&apos;: 101, &apos;holmes&apos;: 467, &apos;by&apos;: 6738, &apos;sir&apos;: 177, &apos;arthur&apos;: 34, &apos;conan&apos;: 4, &apos;doyle&apos;: 5, &apos;in&apos;: 22047, &apos;our&apos;: 1066, &apos;series&apos;: 128, &apos;copyright&apos;: 69, &apos;laws&apos;: 233, &apos;are&apos;: 3630, &apos;changing&apos;: 44, &apos;all&apos;: 4144, &apos;over&apos;: 1282, &apos;world&apos;: 362, &apos;be&apos;: 6155, &apos;sure&apos;: 123, &apos;to&apos;: 28766, &apos;check&apos;: 38, &apos;for&apos;: 6939, &apos;your&apos;: 1279, &apos;country&apos;: 423, &apos;before&apos;: 1363, &apos;downloading&apos;: 5, &apos;or&apos;: 5352, &apos;redistributing&apos;: 7, &apos;this&apos;: 4063, &apos;any&apos;: 1204, &apos;other&apos;: 1502, &apos;header&apos;: 7, &apos;should&apos;: 1297, &apos;first&apos;: 1177, &apos;thing&apos;: 303, &apos;seen&apos;: 444, &apos;when&apos;: 2923, &apos;viewing&apos;: 7, &apos;file&apos;: 21, &apos;please&apos;: 172, &apos;do&apos;: 1503, &apos;not&apos;: 6625, &apos;remove&apos;: 53, &apos;it&apos;: 10681, &apos;change&apos;: 150, &apos;edit&apos;: 4, &apos;without&apos;: 1015, &apos;written&apos;: 117, &apos;permission&apos;: 52, &apos;read&apos;: 218, &apos;legal&apos;: 52, &apos;small&apos;: 527, &apos;print&apos;: 47, &apos;and&apos;: 38312, &apos;information&apos;: 73, &apos;about&apos;: 1497, &apos;at&apos;: 6791, &apos;bottom&apos;: 42, &apos;included&apos;: 43, &apos;is&apos;: 9774, &apos;important&apos;: 285, &apos;specific&apos;: 37, &apos;rights&apos;: 168, &apos;restrictions&apos;: 23, &apos;how&apos;: 1315, &apos;may&apos;: 2551, &apos;used&apos;: 276, &apos;you&apos;: 5622, &apos;can&apos;: 1095, &apos;also&apos;: 778, &apos;find&apos;: 294, &apos;out&apos;: 1987, &apos;make&apos;: 504, &apos;a&apos;: 21155, &apos;donation&apos;: 10, &apos;get&apos;: 468, &apos;involved&apos;: 107, &apos;welcome&apos;: 18, &apos;free&apos;: 421, &apos;plain&apos;: 108, &apos;vanilla&apos;: 6, &apos;electronic&apos;: 58, &apos;texts&apos;: 7, &apos;ebooks&apos;: 54, &apos;readable&apos;: 13, &apos;both&apos;: 529, &apos;humans&apos;: 2, &apos;computers&apos;: 7, &apos;since&apos;: 260, &apos;these&apos;: 1231, &apos;were&apos;: 4289, &apos;prepared&apos;: 138, &apos;thousands&apos;: 93, &apos;volunteers&apos;: 22, &apos;title&apos;: 39, &apos;author&apos;: 29, &apos;release&apos;: 28, &apos;date&apos;: 48, &apos;march&apos;: 135, &apos;most&apos;: 908, &apos;recently&apos;: 30, &apos;updated&apos;: 4, &apos;november&apos;: 41, &apos;edition&apos;: 21, &apos;language&apos;: 61, &apos;english&apos;: 211, &apos;character&apos;: 174, &apos;set&apos;: 324, &apos;encoding&apos;: 5, &apos;ascii&apos;: 11, &apos;start&apos;: 67, &apos;additional&apos;: 30, &apos;editing&apos;: 6, &apos;jose&apos;: 1, &apos;menendez&apos;: 1, &apos;contents&apos;: 50, &apos;i&apos;: 7682, &apos;scandal&apos;: 19, &apos;bohemia&apos;: 15, &apos;ii&apos;: 77, &apos;red&apos;: 288, &apos;headed&apos;: 37, &apos;league&apos;: 53, &apos;iii&apos;: 91, &apos;case&apos;: 438, &apos;identity&apos;: 11, &apos;iv&apos;: 55, &apos;boscombe&apos;: 16, &apos;valley&apos;: 78, &apos;mystery&apos;: 39, &apos;v&apos;: 51, &apos;five&apos;: 279, &apos;orange&apos;: 23, &apos;pips&apos;: 12, &apos;vi&apos;: 37, &apos;man&apos;: 1652, &apos;with&apos;: 9740, &apos;twisted&apos;: 21, &apos;lip&apos;: 56, &apos;vii&apos;: 34, &apos;adventure&apos;: 34, &apos;blue&apos;: 143, &apos;carbuncle&apos;: 17, &apos;viii&apos;: 39, &apos;speckled&apos;: 5, &apos;band&apos;: 54, &apos;ix&apos;: 28, &apos;engineer&apos;: 12, &apos;s&apos;: 5631, &apos;thumb&apos;: 51, &apos;x&apos;: 136, &apos;noble&apos;: 48, &apos;bachelor&apos;: 18, &apos;xi&apos;: 28, &apos;beryl&apos;: 4, &apos;coronet&apos;: 29, &apos;xii&apos;: 28, &apos;copper&apos;: 26, &apos;beeches&apos;: 12, &apos;she&apos;: 3946, &apos;always&apos;: 608, &apos;woman&apos;: 325, &apos;have&apos;: 3493, &apos;seldom&apos;: 76, &apos;heard&apos;: 636, &apos;him&apos;: 5230, &apos;mention&apos;: 46, &apos;her&apos;: 5284, &apos;under&apos;: 963, &apos;name&apos;: 262, &apos;his&apos;: 10034, &apos;eyes&apos;: 939, &apos;eclipses&apos;: 2, &apos;predominates&apos;: 3, &apos;whole&apos;: 744, &apos;sex&apos;: 11, &apos;was&apos;: 11410, &apos;that&apos;: 12512, &apos;he&apos;: 12401, &apos;felt&apos;: 697, &apos;emotion&apos;: 36, &apos;akin&apos;: 14, &apos;love&apos;: 484, &apos;irene&apos;: 18, &apos;adler&apos;: 16, &apos;emotions&apos;: 10, &apos;one&apos;: 3371, &apos;particularly&apos;: 174, &apos;abhorrent&apos;: 1, &apos;cold&apos;: 257, &apos;precise&apos;: 13, &apos;but&apos;: 5653, &apos;admirably&apos;: 7, &apos;balanced&apos;: 6, &apos;mind&apos;: 341, &apos;take&apos;: 616, &apos;perfect&apos;: 39, &apos;reasoning&apos;: 41, &apos;observing&apos;: 21, &apos;machine&apos;: 39, &apos;has&apos;: 1603, &apos;as&apos;: 8064, &apos;lover&apos;: 26, &apos;would&apos;: 1953, &apos;placed&apos;: 182, &apos;himself&apos;: 1158, &apos;false&apos;: 64, &apos;position&apos;: 432, &apos;never&apos;: 593, &apos;spoke&apos;: 218, &apos;softer&apos;: 10, &apos;passions&apos;: 29, &apos;save&apos;: 110, &apos;gibe&apos;: 2, &apos;sneer&apos;: 6, &apos;they&apos;: 3938, &apos;admirable&apos;: 14, &apos;things&apos;: 321, &apos;observer&apos;: 13, &apos;excellent&apos;: 62, &apos;drawing&apos;: 240, &apos;veil&apos;: 16, &apos;from&apos;: 5709, &apos;men&apos;: 1145, &apos;motives&apos;: 14, &apos;actions&apos;: 77, &apos;trained&apos;: 23, &apos;reasoner&apos;: 6, &apos;admit&apos;: 65, &apos;such&apos;: 1436, &apos;intrusions&apos;: 1, &apos;into&apos;: 2124, &apos;own&apos;: 785, &apos;delicate&apos;: 54, &apos;finely&apos;: 11, &apos;adjusted&apos;: 16, &apos;temperament&apos;: 5, &apos;introduce&apos;: 23, &apos;distracting&apos;: 1, &apos;factor&apos;: 41, &apos;which&apos;: 4842, &apos;might&apos;: 536, &apos;throw&apos;: 48, &apos;doubt&apos;: 152, &apos;upon&apos;: 1111, &apos;mental&apos;: 37, &apos;results&apos;: 229, &apos;grit&apos;: 1, &apos;sensitive&apos;: 35, &apos;instrument&apos;: 35, &apos;crack&apos;: 20, &apos;high&apos;: 290, &apos;power&apos;: 548, &apos;lenses&apos;: 1, &apos;more&apos;: 1997, &apos;disturbing&apos;: 9, &apos;than&apos;: 1206, &apos;strong&apos;: 168, &apos;nature&apos;: 170, &apos;yet&apos;: 488, &apos;there&apos;: 2972, &apos;late&apos;: 165, &apos;dubious&apos;: 1, &apos;questionable&apos;: 3, &apos;memory&apos;: 55, &apos;had&apos;: 7383, &apos;little&apos;: 1001, &apos;lately&apos;: 22, &apos;my&apos;: 2249, &apos;marriage&apos;: 96, &apos;drifted&apos;: 5, &apos;us&apos;: 684, &apos;away&apos;: 838, &apos;each&apos;: 411, &apos;complete&apos;: 145, &apos;happiness&apos;: 143, &apos;home&apos;: 295, &apos;centred&apos;: 2, &apos;interests&apos;: 118, &apos;rise&apos;: 240, &apos;up&apos;: 2284, &apos;around&apos;: 271, &apos;who&apos;: 3050, &apos;finds&apos;: 23, &apos;master&apos;: 141, &apos;establishment&apos;: 40, &apos;sufficient&apos;: 75, &apos;absorb&apos;: 4, &apos;attention&apos;: 191, &apos;while&apos;: 768, &apos;loathed&apos;: 1, &apos;every&apos;: 650, &apos;form&apos;: 507, &apos;society&apos;: 169, &apos;bohemian&apos;: 8, &apos;soul&apos;: 168, &apos;remained&apos;: 231, &apos;lodgings&apos;: 11, &apos;baker&apos;: 49, &apos;street&apos;: 180, &apos;buried&apos;: 21, &apos;among&apos;: 451, &apos;old&apos;: 1180, &apos;books&apos;: 59, &apos;alternating&apos;: 2, &apos;week&apos;: 95, &apos;between&apos;: 654, &apos;cocaine&apos;: 4, &apos;ambition&apos;: 13, &apos;drowsiness&apos;: 4, &apos;drug&apos;: 21, &apos;fierce&apos;: 12, &apos;energy&apos;: 45, &apos;keen&apos;: 32, &apos;still&apos;: 922, &apos;ever&apos;: 274, &apos;deeply&apos;: 77, &apos;attracted&apos;: 36, &apos;study&apos;: 144, &apos;crime&apos;: 61, &apos;occupied&apos;: 116, &apos;immense&apos;: 77, &apos;faculties&apos;: 8, &apos;extraordinary&apos;: 74, &apos;powers&apos;: 149, &apos;observation&apos;: 39, &apos;following&apos;: 208, &apos;those&apos;: 1201, &apos;clues&apos;: 3, &apos;clearing&apos;: 29, &apos;mysteries&apos;: 9, &apos;been&apos;: 2599, &apos;abandoned&apos;: 72, &apos;hopeless&apos;: 17, &apos;official&apos;: 91, &apos;police&apos;: 94, &apos;time&apos;: 1529, &apos;some&apos;: 1536, &apos;vague&apos;: 39, &apos;account&apos;: 177, &apos;doings&apos;: 11, &apos;summons&apos;: 11, &apos;odessa&apos;: 3, &apos;trepoff&apos;: 1, &apos;murder&apos;: 30, &apos;singular&apos;: 36, &apos;tragedy&apos;: 9, &apos;atkinson&apos;: 1, &apos;brothers&apos;: 50, &apos;trincomalee&apos;: 1, &apos;finally&apos;: 156, &apos;mission&apos;: 34, &apos;accomplished&apos;: 39, &apos;so&apos;: 3017, &apos;delicately&apos;: 3, &apos;successfully&apos;: 25, &apos;reigning&apos;: 3, &apos;family&apos;: 210, &apos;holland&apos;: 12, &apos;beyond&apos;: 225, &apos;signs&apos;: 98, &apos;activity&apos;: 131, &apos;however&apos;: 430, &apos;merely&apos;: 189, &apos;shared&apos;: 25, &apos;readers&apos;: 11, &apos;daily&apos;: 44, &apos;press&apos;: 81, &apos;knew&apos;: 496, &apos;former&apos;: 177, &apos;friend&apos;: 283, &apos;companion&apos;: 81, &apos;night&apos;: 385, &apos;on&apos;: 6643, &apos;twentieth&apos;: 19, &apos;returning&apos;: 68, &apos;journey&apos;: 69, &apos;patient&apos;: 383, &apos;now&apos;: 1697, &apos;returned&apos;: 194, &apos;civil&apos;: 177, &apos;practice&apos;: 95, &apos;way&apos;: 859, &apos;led&apos;: 196, &apos;me&apos;: 1920, &apos;through&apos;: 815, &apos;passed&apos;: 367, &apos;well&apos;: 1198, &apos;remembered&apos;: 120, &apos;door&apos;: 498, &apos;must&apos;: 955, &apos;associated&apos;: 196, &apos;wooing&apos;: 2, &apos;dark&apos;: 181, &apos;incidents&apos;: 14, &apos;scarlet&apos;: 22, &apos;seized&apos;: 114, &apos;desire&apos;: 96, &apos;see&apos;: 1101, &apos;again&apos;: 866, &apos;know&apos;: 1048, &apos;employing&apos;: 7, &apos;rooms&apos;: 86, &apos;brilliantly&apos;: 5, &apos;lit&apos;: 74, &apos;even&apos;: 946, &apos;looked&apos;: 760, &apos;saw&apos;: 599, &apos;tall&apos;: 74, &apos;spare&apos;: 27, &apos;figure&apos;: 103, &apos;pass&apos;: 154, &apos;twice&apos;: 84, &apos;silhouette&apos;: 1, &apos;against&apos;: 660, &apos;blind&apos;: 23, &apos;pacing&apos;: 26, &apos;room&apos;: 960, &apos;swiftly&apos;: 38, &apos;eagerly&apos;: 39, &apos;head&apos;: 725, &apos;sunk&apos;: 27, &apos;chest&apos;: 81, &apos;hands&apos;: 455, &apos;clasped&apos;: 11, &apos;behind&apos;: 401, &apos;mood&apos;: 51, &apos;habit&apos;: 55, &apos;attitude&apos;: 72, &apos;manner&apos;: 135, &apos;told&apos;: 490, &apos;their&apos;: 2955, &apos;story&apos;: 133, &apos;work&apos;: 382, &apos;risen&apos;: 30, &apos;created&apos;: 62, &apos;dreams&apos;: 16, &apos;hot&apos;: 119, &apos;scent&apos;: 17, &apos;new&apos;: 1211, &apos;problem&apos;: 76, &apos;rang&apos;: 29, &apos;bell&apos;: 65, &apos;shown&apos;: 113, &apos;chamber&apos;: 35, &apos;formerly&apos;: 77, &apos;part&apos;: 704, &apos;effusive&apos;: 2, &apos;glad&apos;: 150, &apos;think&apos;: 557, &apos;hardly&apos;: 173, &apos;word&apos;: 298, &apos;spoken&apos;: 92, &apos;kindly&apos;: 86, &apos;eye&apos;: 110, &apos;waved&apos;: 29, &apos;an&apos;: 3423, &apos;armchair&apos;: 49, &apos;threw&apos;: 96, &apos;across&apos;: 222, &apos;cigars&apos;: 7, &apos;indicated&apos;: 88, &apos;spirit&apos;: 167, &apos;gasogene&apos;: 1, &apos;corner&apos;: 128, &apos;then&apos;: 1558, &apos;stood&apos;: 383, &apos;fire&apos;: 274, &apos;introspective&apos;: 3, &apos;fashion&apos;: 49, &apos;wedlock&apos;: 1, &apos;suits&apos;: 8, &apos;remarked&apos;: 169, &apos;watson&apos;: 83, &apos;put&apos;: 435, &apos;seven&apos;: 132, &apos;half&apos;: 318, &apos;pounds&apos;: 26, &apos;answered&apos;: 226, &apos;indeed&apos;: 139, &apos;thought&apos;: 902, &apos;just&apos;: 767, &apos;trifle&apos;: 11, &apos;fancy&apos;: 50, &apos;observe&apos;: 37, &apos;did&apos;: 1875, &apos;tell&apos;: 492, &apos;intended&apos;: 58, &apos;go&apos;: 905, &apos;harness&apos;: 27, &apos;deduce&apos;: 14, &apos;getting&apos;: 92, &apos;yourself&apos;: 162, &apos;very&apos;: 1340, &apos;wet&apos;: 60, &apos;clumsy&apos;: 8, &apos;careless&apos;: 14, &apos;servant&apos;: 46, &apos;girl&apos;: 166, &apos;dear&apos;: 449, &apos;said&apos;: 3464, &apos;too&apos;: 548, &apos;much&apos;: 671, &apos;certainly&apos;: 119, &apos;burned&apos;: 77, &apos;lived&apos;: 113, &apos;few&apos;: 458, &apos;centuries&apos;: 12, &apos;ago&apos;: 108, &apos;true&apos;: 205, &apos;walk&apos;: 75, &apos;thursday&apos;: 7, &apos;came&apos;: 979, &apos;dreadful&apos;: 68, &apos;mess&apos;: 10, &apos;changed&apos;: 134, &apos;clothes&apos;: 62, &apos;t&apos;: 1318, &apos;imagine&apos;: 96, &apos;mary&apos;: 705, &apos;jane&apos;: 2, &apos;incorrigible&apos;: 2, &apos;wife&apos;: 367, &apos;given&apos;: 364, &apos;notice&apos;: 98, &apos;fail&apos;: 40, &apos;chuckled&apos;: 7, &apos;rubbed&apos;: 32, &apos;long&apos;: 991, &apos;nervous&apos;: 54, &apos;together&apos;: 260, &apos;simplicity&apos;: 30, &apos;itself&apos;: 273, &apos;inside&apos;: 43, &apos;left&apos;: 834, &apos;shoe&apos;: 11, &apos;where&apos;: 977, &apos;firelight&apos;: 2, &apos;strikes&apos;: 19, &apos;leather&apos;: 35, &apos;scored&apos;: 4, &apos;six&apos;: 176, &apos;almost&apos;: 325, &apos;parallel&apos;: 17, &apos;cuts&apos;: 5, &apos;obviously&apos;: 38, &apos;caused&apos;: 102, &apos;someone&apos;: 160, &apos;carelessly&apos;: 14, &apos;scraped&apos;: 21, &apos;round&apos;: 556, &apos;edges&apos;: 70, &apos;sole&apos;: 70, &apos;order&apos;: 404, &apos;crusted&apos;: 2, &apos;mud&apos;: 36, &apos;hence&apos;: 32, &apos;double&apos;: 49, &apos;deduction&apos;: 12, &apos;vile&apos;: 16, &apos;weather&apos;: 42, &apos;malignant&apos;: 88, &apos;boot&apos;: 22, &apos;slitting&apos;: 2, &apos;specimen&apos;: 14, &apos;london&apos;: 76, &apos;slavey&apos;: 1, &apos;if&apos;: 2372, &apos;gentleman&apos;: 99, &apos;walks&apos;: 10, &apos;smelling&apos;: 5, &apos;iodoform&apos;: 43, &apos;black&apos;: 235, &apos;mark&apos;: 38, &apos;nitrate&apos;: 7, &apos;silver&apos;: 128, &apos;right&apos;: 710, &apos;forefinger&apos;: 7, &apos;bulge&apos;: 2, &apos;side&apos;: 511, &apos;top&apos;: 42, &apos;hat&apos;: 105, &apos;show&apos;: 213, &apos;secreted&apos;: 2, &apos;stethoscope&apos;: 2, &apos;dull&apos;: 74, &apos;pronounce&apos;: 9, &apos;active&apos;: 96, &apos;member&apos;: 50, &apos;medical&apos;: 22, &apos;profession&apos;: 22, &apos;could&apos;: 1700, &apos;help&apos;: 230, &apos;laughing&apos;: 115, &apos;ease&apos;: 44, &apos;explained&apos;: 60, &apos;process&apos;: 219, &apos;hear&apos;: 183, &apos;give&apos;: 523, &apos;reasons&apos;: 64, &apos;appears&apos;: 108, &apos;ridiculously&apos;: 1, &apos;simple&apos;: 139, &apos;easily&apos;: 114, &apos;myself&apos;: 227, &apos;though&apos;: 650, &apos;successive&apos;: 17, &apos;instance&apos;: 50, &apos;am&apos;: 746, &apos;baffled&apos;: 8, &apos;until&apos;: 325, &apos;explain&apos;: 123, &apos;believe&apos;: 183, &apos;good&apos;: 744, &apos;yours&apos;: 46, &apos;quite&apos;: 502, &apos;lighting&apos;: 16, &apos;cigarette&apos;: 6, &apos;throwing&apos;: 46, &apos;down&apos;: 1128, &apos;distinction&apos;: 19, &apos;clear&apos;: 233, &apos;example&apos;: 286, &apos;frequently&apos;: 218, &apos;steps&apos;: 188, &apos;lead&apos;: 137, &apos;hall&apos;: 83, &apos;often&apos;: 443, &apos;hundreds&apos;: 48, &apos;times&apos;: 236, &apos;many&apos;: 609, &apos;don&apos;: 581, &apos;observed&apos;: 131, &apos;point&apos;: 223, &apos;seventeen&apos;: 10, &apos;because&apos;: 630, &apos;interested&apos;: 65, &apos;problems&apos;: 78, &apos;enough&apos;: 175, &apos;chronicle&apos;: 7, &apos;two&apos;: 1138, &apos;trifling&apos;: 12, &apos;experiences&apos;: 11, &apos;sheet&apos;: 29, &apos;thick&apos;: 77, &apos;pink&apos;: 27, &apos;tinted&apos;: 9, &apos;notepaper&apos;: 2, &apos;lying&apos;: 118, &apos;open&apos;: 325, &apos;table&apos;: 296, &apos;last&apos;: 565, &apos;post&apos;: 117, &apos;aloud&apos;: 28, &apos;note&apos;: 115, &apos;undated&apos;: 1, &apos;either&apos;: 293, &apos;signature&apos;: 9, &apos;address&apos;: 76, &apos;will&apos;: 1577, &apos;call&apos;: 197, &apos;quarter&apos;: 46, &apos;eight&apos;: 128, &apos;o&apos;: 257, &apos;clock&apos;: 120, &apos;desires&apos;: 22, &apos;consult&apos;: 19, &apos;matter&apos;: 365, &apos;deepest&apos;: 15, &apos;moment&apos;: 487, &apos;recent&apos;: 54, &apos;services&apos;: 38, &apos;royal&apos;: 111, &apos;houses&apos;: 117, &apos;europe&apos;: 153, &apos;safely&apos;: 11, &apos;trusted&apos;: 16, &apos;matters&apos;: 136, &apos;importance&apos;: 117, &apos;exaggerated&apos;: 28, &apos;we&apos;: 1906, &apos;quarters&apos;: 72, &apos;received&apos;: 280, &apos;hour&apos;: 157, &apos;amiss&apos;: 6, &apos;visitor&apos;: 74, &apos;wear&apos;: 30, &apos;mask&apos;: 12, &apos;what&apos;: 3011, &apos;means&apos;: 253, &apos;no&apos;: 2348, &apos;data&apos;: 17, &apos;capital&apos;: 144, &apos;mistake&apos;: 39, &apos;theorise&apos;: 1, &apos;insensibly&apos;: 2, &apos;begins&apos;: 47, &apos;twist&apos;: 14, &apos;facts&apos;: 72, &apos;suit&apos;: 25, &apos;theories&apos;: 21, &apos;instead&apos;: 137, &apos;carefully&apos;: 72, &apos;examined&apos;: 49, &apos;writing&apos;: 69, &apos;paper&apos;: 177, &apos;wrote&apos;: 149, &apos;presumably&apos;: 8, &apos;endeavouring&apos;: 8, &apos;imitate&apos;: 7, &apos;processes&apos;: 35, &apos;bought&apos;: 55, &apos;crown&apos;: 61, &apos;packet&apos;: 11, &apos;peculiarly&apos;: 14, &apos;stiff&apos;: 20, &apos;peculiar&apos;: 84, &apos;hold&apos;: 114, &apos;light&apos;: 278, &apos;large&apos;: 483, &apos;e&apos;: 136, &apos;g&apos;: 55, &apos;p&apos;: 66, &apos;woven&apos;: 5, &apos;texture&apos;: 6, &apos;asked&apos;: 777, &apos;maker&apos;: 4, &apos;monogram&apos;: 4, &apos;rather&apos;: 219, &apos;stands&apos;: 19, &apos;gesellschaft&apos;: 1, &apos;german&apos;: 196, &apos;company&apos;: 192, &apos;customary&apos;: 19, &apos;contraction&apos;: 61, &apos;like&apos;: 1080, &apos;co&apos;: 30, &apos;course&apos;: 389, &apos;papier&apos;: 1, &apos;eg&apos;: 1, &apos;let&apos;: 506, &apos;glance&apos;: 91, &apos;continental&apos;: 46, &apos;gazetteer&apos;: 1, &apos;took&apos;: 573, &apos;heavy&apos;: 139, &apos;brown&apos;: 71, &apos;volume&apos;: 30, &apos;shelves&apos;: 3, &apos;eglow&apos;: 1, &apos;eglonitz&apos;: 1, &apos;here&apos;: 691, &apos;egria&apos;: 1, &apos;speaking&apos;: 185, &apos;far&apos;: 408, &apos;carlsbad&apos;: 1, &apos;remarkable&apos;: 77, &apos;being&apos;: 918, &apos;scene&apos;: 49, &apos;death&apos;: 330, &apos;wallenstein&apos;: 1, &apos;its&apos;: 1635, &apos;numerous&apos;: 50, &apos;glass&apos;: 116, &apos;factories&apos;: 29, &apos;mills&apos;: 39, &apos;ha&apos;: 75, &apos;boy&apos;: 169, &apos;sparkled&apos;: 5, &apos;sent&apos;: 319, &apos;great&apos;: 792, &apos;triumphant&apos;: 16, &apos;cloud&apos;: 30, &apos;made&apos;: 1007, &apos;precisely&apos;: 24, &apos;construction&apos;: 25, &apos;sentence&apos;: 26, &apos;frenchman&apos;: 102, &apos;russian&apos;: 461, &apos;uncourteous&apos;: 1, &apos;verbs&apos;: 1, &apos;only&apos;: 1873, &apos;remains&apos;: 73, &apos;therefore&apos;: 186, &apos;discover&apos;: 28, &apos;wanted&apos;: 213, &apos;writes&apos;: 20, &apos;prefers&apos;: 2, &apos;wearing&apos;: 87, &apos;showing&apos;: 104, &apos;face&apos;: 1125, &apos;comes&apos;: 91, &apos;mistaken&apos;: 59, &apos;resolve&apos;: 14, &apos;doubts&apos;: 39, &apos;sharp&apos;: 83, &apos;sound&apos;: 219, &apos;horses&apos;: 262, &apos;hoofs&apos;: 24, &apos;grating&apos;: 10, &apos;wheels&apos;: 47, &apos;curb&apos;: 4, &apos;followed&apos;: 329, &apos;pull&apos;: 23, &apos;whistled&apos;: 13, &apos;pair&apos;: 40, &apos;yes&apos;: 688, &apos;continued&apos;: 291, &apos;glancing&apos;: 98, &apos;window&apos;: 186, &apos;nice&apos;: 53, &apos;brougham&apos;: 4, &apos;beauties&apos;: 2, &apos;hundred&apos;: 229, &apos;fifty&apos;: 94, &apos;guineas&apos;: 3, &apos;apiece&apos;: 7, &apos;money&apos;: 326, &apos;nothing&apos;: 646, &apos;else&apos;: 201, &apos;better&apos;: 266, &apos;bit&apos;: 63, &apos;doctor&apos;: 183, &apos;stay&apos;: 74, &apos;lost&apos;: 224, &apos;boswell&apos;: 1, &apos;promises&apos;: 15, &apos;interesting&apos;: 71, &apos;pity&apos;: 75, &apos;miss&apos;: 112, &apos;client&apos;: 33, &apos;want&apos;: 323, &apos;sit&apos;: 89, &apos;best&apos;: 268, &apos;slow&apos;: 65, &apos;step&apos;: 139, &apos;stairs&apos;: 31, &apos;passage&apos;: 110, &apos;paused&apos;: 79, &apos;immediately&apos;: 182, &apos;outside&apos;: 110, &apos;loud&apos;: 64, &apos;authoritative&apos;: 2, &apos;tap&apos;: 10, &apos;come&apos;: 934, &apos;entered&apos;: 282, &apos;less&apos;: 367, &apos;feet&apos;: 179, &apos;inches&apos;: 16, &apos;height&apos;: 36, &apos;limbs&apos;: 67, &apos;hercules&apos;: 4, &apos;dress&apos;: 138, &apos;rich&apos;: 92, &apos;richness&apos;: 2, &apos;england&apos;: 311, &apos;bad&apos;: 155, &apos;taste&apos;: 23, &apos;bands&apos;: 27, &apos;astrakhan&apos;: 1, &apos;slashed&apos;: 3, &apos;sleeves&apos;: 30, &apos;fronts&apos;: 1, &apos;breasted&apos;: 1, &apos;coat&apos;: 172, &apos;deep&apos;: 215, &apos;cloak&apos;: 62, &apos;thrown&apos;: 92, &apos;shoulders&apos;: 125, &apos;lined&apos;: 32, &apos;flame&apos;: 15, &apos;coloured&apos;: 21, &apos;silk&apos;: 50, &apos;secured&apos;: 48, &apos;neck&apos;: 203, &apos;brooch&apos;: 1, &apos;consisted&apos;: 38, &apos;single&apos;: 173, &apos;flaming&apos;: 8, &apos;boots&apos;: 91, &apos;extended&apos;: 75, &apos;halfway&apos;: 19, &apos;calves&apos;: 3, &apos;trimmed&apos;: 8, &apos;tops&apos;: 3, &apos;fur&apos;: 38, &apos;completed&apos;: 25, &apos;impression&apos;: 67, &apos;barbaric&apos;: 2, &apos;opulence&apos;: 3, &apos;suggested&apos;: 69, &apos;appearance&apos;: 135, &apos;carried&apos;: 282, &apos;broad&apos;: 92, &apos;brimmed&apos;: 4, &apos;hand&apos;: 834, &apos;wore&apos;: 58, &apos;upper&apos;: 130, &apos;extending&apos;: 35, &apos;past&apos;: 223, &apos;cheekbones&apos;: 4, &apos;vizard&apos;: 1, &apos;apparently&apos;: 68, &apos;raised&apos;: 212, &apos;lower&apos;: 196, &apos;appeared&apos;: 197, &apos;hanging&apos;: 42, &apos;straight&apos;: 124, &apos;chin&apos;: 30, &apos;suggestive&apos;: 11, &apos;resolution&apos;: 57, &apos;pushed&apos;: 81, &apos;length&apos;: 63, &apos;obstinacy&apos;: 7, &apos;harsh&apos;: 22, &apos;voice&apos;: 462, &apos;strongly&apos;: 41, &apos;marked&apos;: 138, &apos;accent&apos;: 18, &apos;uncertain&apos;: 30, &apos;pray&apos;: 79, &apos;seat&apos;: 170, &apos;colleague&apos;: 7, &apos;dr&apos;: 48, &apos;occasionally&apos;: 89, &apos;cases&apos;: 453, &apos;whom&apos;: 489, &apos;honour&apos;: 16, &apos;count&apos;: 748, &apos;von&apos;: 11, &apos;kramm&apos;: 2, &apos;nobleman&apos;: 11, &apos;understand&apos;: 412, &apos;discretion&apos;: 13, &apos;trust&apos;: 68, &apos;extreme&apos;: 72, &apos;prefer&apos;: 21, &apos;communicate&apos;: 15, &apos;alone&apos;: 337, &apos;rose&apos;: 243, &apos;caught&apos;: 90, &apos;wrist&apos;: 68, &apos;back&apos;: 746, &apos;chair&apos;: 135, &apos;none&apos;: 110, &apos;say&apos;: 755, &apos;anything&apos;: 379, &apos;shrugged&apos;: 35, &apos;begin&apos;: 97, &apos;binding&apos;: 18, &apos;absolute&apos;: 56, &apos;secrecy&apos;: 18, &apos;years&apos;: 571, &apos;end&apos;: 465, &apos;present&apos;: 329, &apos;weight&apos;: 70, &apos;influence&apos;: 138, &apos;european&apos;: 99, &apos;history&apos;: 439, &apos;promise&apos;: 67, &apos;excuse&apos;: 53, &apos;strange&apos;: 220, &apos;august&apos;: 70, &apos;person&apos;: 185, &apos;employs&apos;: 2, &apos;wishes&apos;: 42, &apos;agent&apos;: 25, &apos;unknown&apos;: 87, &apos;confess&apos;: 36, &apos;once&apos;: 569, &apos;called&apos;: 450, &apos;exactly&apos;: 47, &apos;aware&apos;: 52, &apos;dryly&apos;: 5, &apos;circumstances&apos;: 107, &apos;delicacy&apos;: 11, &apos;precaution&apos;: 9, &apos;taken&apos;: 438, &apos;quench&apos;: 3, &apos;grow&apos;: 74, &apos;seriously&apos;: 63, &apos;compromise&apos;: 71, &apos;families&apos;: 45, &apos;speak&apos;: 255, &apos;plainly&apos;: 39, &apos;implicates&apos;: 5, &apos;house&apos;: 661, &apos;ormstein&apos;: 2, &apos;hereditary&apos;: 14, &apos;kings&apos;: 27, &apos;murmured&apos;: 18, &apos;settling&apos;: 16, &apos;closing&apos;: 35, &apos;glanced&apos;: 176, ...}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">alphabet = <span class="string">'abcdefghigklmnopqrstuvwxyz'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits1</span><span class="params">(word)</span>:</span></span><br><span class="line">    n = len(word)</span><br><span class="line">    <span class="keyword">return</span> set([word[<span class="number">0</span>:i]+word[i+<span class="number">1</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]+</span><br><span class="line">              [word[<span class="number">0</span>:i]+word[i+<span class="number">1</span>]+word[i]+word[i+<span class="number">2</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> range(n<span class="number">-1</span>)]+</span><br><span class="line">              [word[<span class="number">0</span>:i]+c+word[i+<span class="number">1</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> range(n) <span class="keyword">for</span> c <span class="keyword">in</span> alphabet] +</span><br><span class="line">              [word[<span class="number">0</span>:i]+c+word[i:] <span class="keyword">for</span> i <span class="keyword">in</span> range(n+<span class="number">1</span>) <span class="keyword">for</span> c <span class="keyword">in</span> alphabet])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits2</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> set(e2 <span class="keyword">for</span> e1 <span class="keyword">in</span> edits1(word) <span class="keyword">for</span> e2 <span class="keyword">in</span> edits1(e1))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">e1 = edits1(<span class="string">'hello'</span>)</span><br><span class="line">e2 = edits2(<span class="string">'hello'</span>)</span><br><span class="line">len(e1)+len(e2)</span><br></pre></td></tr></table></figure><pre><code>33328</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">known</span><span class="params">(words)</span>:</span></span><br><span class="line">    w = set()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> dic_words:</span><br><span class="line">            w.add(word)</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correct</span><span class="params">(word)</span>:</span></span><br><span class="line">    candidates = known([word]) <span class="keyword">or</span> known(edits1(word)) <span class="keyword">or</span> known(edits2(word)) <span class="keyword">or</span> word</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> word == candidates:</span><br><span class="line">        <span class="keyword">return</span> word</span><br><span class="line">    max_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> candidates:</span><br><span class="line">        <span class="keyword">if</span> dic_words[c]&gt;=max_num:</span><br><span class="line">            max_num=dic_words[c]</span><br><span class="line">            candidate = c</span><br><span class="line">    <span class="keyword">return</span> candidate</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correct(<span class="string">'ehell'</span>)</span><br></pre></td></tr></table></figure><pre><code>&apos;shell&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correct(<span class="string">'hel'</span>)</span><br></pre></td></tr></table></figure><pre><code>&apos;he&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correct(<span class="string">'heade'</span>)</span><br></pre></td></tr></table></figure><pre><code>&apos;head&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correct(<span class="string">'haved'</span>)</span><br></pre></td></tr></table></figure><pre><code>&apos;have&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correct(<span class="string">'adevnues'</span>)</span><br></pre></td></tr></table></figure><pre><code>&apos;avenues&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;贝叶斯单词拼写器代码:&lt;br&gt;数据集下载:&lt;a href=&quot;http://zs-hexo-blog.oss-cn-beijing.aliyuncs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/data/big.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;big.txt&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="贝叶斯算法" scheme="http://yoursite.com/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
