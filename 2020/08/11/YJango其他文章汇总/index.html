<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="张帅的Blog" type="application/atom+xml" />






<meta name="description" content="YJango学习观系列">
<meta property="og:type" content="article">
<meta property="og:title" content="YJango其他文章汇总">
<meta property="og:url" content="http://yoursite.com/2020/08/11/YJango%E5%85%B6%E4%BB%96%E6%96%87%E7%AB%A0%E6%B1%87%E6%80%BB/index.html">
<meta property="og:site_name" content="张帅的Blog">
<meta property="og:description" content="YJango学习观系列">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pic1.zhimg.com/v2-0cd32763d1067e4fa6ae63e494302e07_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=P(A)+%253D+5%252F16%5C%5C+P(B)+%253D+4%252F16%5C%5C+P(C)+%253D+3%252F16%5C%5C+P(D)+%253D+2%252F16%5C%5C+P(G)+%253D+1%252F16%5C%5C+P(K)+%253D+1%252F16%5C%5C">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=X(A)+%253D+2%5C%5CX(B)+%253D+3%5C%5CX(C)+%253D+4%5C%5CX(D)+%253D+5%5C%5CX(G)+%253D+6%5C%5CX(K)+%253D+7">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=log_2+6+%5Capprox+2.58+%5C++bits%5C%5C+log_e+6+%5Capprox+1.79+%5C++nats%5C%5C+log_%7B10%7D+6+%5Capprox+0.78++%5C++bans%5C%5C">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-be88c02bf2d6aa49530d07cced9a4632_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-7c00f984b625f66240f47d092ba14fe1_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-fe7c8ed324c9a2e5efdec392ee9a80c0_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-9f586226bbae39c9dabb28d8d4436928_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-0bb7c531c8d518aa4af78f90752c3ee6_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-265f8d8b33abf1659a10ec3d23e97ff1_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-82dd0737ac79a63d949e7c8ad1239ba3_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-746ff9fde965cb61f90d83e712ba4c67_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-c61d2008f6fbdb7f298d1d3ad16c8bae_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-4598c108df88f9f8119757eab0e318c8_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-f328f131d915bd589d9c195bee4a3dc2_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-8d4508f43698f933a1c54f0347c1999d_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-c4bf85890918ede7952697c4d5e88618_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-c7f11100548239eb1228b3386bb32b48_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-30bf9b80852d026da71460ee2d779486_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-7610bd6fb437760a76b443fcad4a977b_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-f1002fbea2dd7fe0855195a711bdd025_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-b4df6267baa84a74f9a919d1b34448a9_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-d544ab8761c043f3728bdf57b6b728ea_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-491de634ad4b70b00dc0a3ebaa58d672_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-92e1a99688d288711b704cb2f7fa1b67_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-92e1a99688d288711b704cb2f7fa1b67_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-fe46aca26f8e4625ea462c93fe6871b9_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-1ebee9a3fb36a6d1502d517b24bfb5c3_b.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-69d03cf2b3677ad7dc3b0d9af58841b4_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-92ff4b847ac5fa41d91d1e76a910c483_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-b1bd0f75b46ed27daf27910f2a6b6e3f_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-8d7d1ef957ebbf8ba9bb9cf8ff2d87ff_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/v2-b7d47097d8f10e6baeb329e88e59b563_b.webp">
<meta property="og:image" content="https://pic1.zhimg.com/v2-664c152ffc58a28a7f900f9a723cbb83_b.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-3ec7216f7ab84dac089836b166c0ae28_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-82f05552fd2ddde28a0ef20814d7acbb_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-00fe10bf8877137bc5957cf0cd7f9219_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-69c014a15afde18a4086950c30e97d1b_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-0c0e7f5ffa98c2c1eb87763dd5d1d9a3_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-a675e692f7f7755d91bcdba5e988e910_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-6d17d1fb77d3ae1838f5253193456317_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-111e37e8479aa57bedbfb2dbcd8e5b63_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-2820b0562c8fcd7a49d57c4deb1e4f3c_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-83fd9f01e2ea38c7f6b8aeaa308cf040_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-dff3f6e72881ebd222414eabb9504671_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-55811ac3d91f56f19543714b1b5abe49_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-a81a10592b96a1d2b067e1d4ae3951e7_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-7ac033df767fcd722c88cda4829cb13b_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-c984ea3ba696a0a786bb0bb52f0d772e_b.webp">
<meta property="og:image" content="https://pic3.zhimg.com/v2-8cc0db5acd643dd7ca3668ad6e35aabb_b.webp">
<meta property="og:image" content="https://pic3.zhimg.com/v2-db52470df88f53271d8e06722da39122_b.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-8b7c5c5225b6a7337e23786ecb5b2fe3_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-9e770433dc6a146e7625dd155ba00ec5_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-c84b8f3c65a62e4ceee81899c5126365_b.webp">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-a9c81692067bca508bc88ba3f3ecb7b8_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-78c48d9ca0b66d6b46202b019b5ecb66_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-1c85ff7e786721b62d2f9b15991a6871_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-b75451ec04c675d9ba7e3e1ba2971821_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://pic3.zhimg.com/v2-db52470df88f53271d8e06722da39122_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-f1f179149020fd496170de1bb25fcbee_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-eb4824dc842bb2f73be2b8d297c51944_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-5b968059df4831d80b6c049579c5ea18_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-e45fc2149e49856df73c73fc9b635db3_720w.png">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-bce0d99e8bc969fa3c2ffa99f93935c5_720w.png">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-703dffbefaddcf8dcdb39ccf589312e9_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-3cbda7436b42c7b05c8a11868794e2b2_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-b6cc00b99f001d39d97be0932bd52575_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-eb21a394a6bc08394a26b60707471c98_720w.png">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-2ffadd794aef7201d3a1a2e598a490ce_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-918f052df1c52710ee2d26ffe5af441a_720w.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-6f015b68033e1158702857617109679d_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-39576faf84513b6f607ee5bbbec2f175_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-338d014ff709c0f35ece69610a9b31fb_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-8eeb0cba9259ea5d9083bb41dd0651bd_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-feb75672c765888a371f7decf8ac2f11_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-55069445ed54ce163b76c611ba26b639_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-4a0ea7ba42166b62bc4f42e8b150815d_720w.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-a4d35c245931f264ed9a0716fdf20685_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-3da84b5b80ba7a0d779284566f80be93_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-2c82abd20c4e7c40f7f13f035b924b0b_720w.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-c902a9e33b0322051a5f9165e9439247_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-7e5bc60a9e9bd0b597e4b650fecc439e_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-d2859e5c486ed704492ab80079e99535_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-0d24890b2e0d73f4ce4ad17ebfb2d0c4_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-b9aed3dd68b9818561faa7d8ed24ea5a_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-18c11c6f485e9f1bbc9a50eb3d248439_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-2b411af47b1cad7b727bb676c847ce59_720w.png">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-ce9919e4930c1f29241afec0538b2605_720w.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-e877b9099b1139c1a34b0bf66bf92aa4_720w.png">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+y_0+%2526%253D+x_0*w_1+%252B+x_1*w_2%252B+x_4*w_3%252B+x_5*w_4%252Bb_0%5C%5Cy_0+%2526%253D+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_1%2526w_2%2526+w_3%2526w_4+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_0%5C%5C+x_1%5C%5C+x_4%5C%5C+x_5%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%252Bb_0+%5Cend%7Bsplit%7D">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-e1691956fd1beb5d7a637924a1a73d91_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/v2-7fce29335f9b43bce1b373daa40cccba_b.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-0d24890b2e0d73f4ce4ad17ebfb2d0c4_720w.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-23db15ec3f783bbb5cf811711e46dbba_720w.png">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Br1%7D%2526w_%7Br2%7D%5C%5C+w_%7Br3%7D%2526w_%7Br4%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%252C+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bg1%7D%2526w_%7Bg2%7D%5C%5C+w_%7Bg3%7D%2526w_%7Bg4%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%252C+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bb1%7D%2526w_%7Bb2%7D%5C%5C+w_%7Bb3%7D%2526w_%7Bb4%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+y_0+%2526%253D+x_%7Br0%7D*w_%7Br1%7D+%252B+x_%7Br1%7D*w_%7Br2%7D%252B+x_%7Br4%7D*w_%7Br3%7D%252B+x_%7Br5%7D*w_%7Br4%7D%252B+x_%7Bg0%7D*w_%7Bg1%7D+%252B+x_%7Bg1%7D*w_%7Bg2%7D%252B+x_%7Bg4%7D*w_%7Bg3%7D%252B+x_%7Bg5%7D*w_%7Bg4%7D%252B+x_%7Bb0%7D*w_%7Bb1%7D+%252B+x_%7Bb1%7D*w_%7Bb2%7D%252B+x_%7Bb4%7D*w_%7Bb3%7D%252B+x_%7Bb5%7D*w_%7Bb4%7D%252Bb_0%5C%5Cy_0+%2526%253D+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Br1%7D%2526w_%7Br2%7D%2526+w_%7Br3%7D%2526w_%7Br4%7D+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_%7Br0%7D%5C%5C+x_%7Br1%7D%5C%5C+x_%7Br4%7D%5C%5C+x_%7Br5%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D+%252B%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bg1%7D%2526w_%7Bg2%7D%2526+w_%7Bg3%7D%2526w_%7Bg4%7D+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_%7Bg0%7D%5C%5C+x_%7Bg1%7D%5C%5C+x_%7Bg4%7D%5C%5C+x_%7Bg5%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%252B%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bb1%7D%2526w_%7Bb2%7D%2526+w_%7Bb3%7D%2526w_%7Bb4%7D+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_%7Bb0%7D%5C%5C+x_%7Bb1%7D%5C%5C+x_%7Bb4%7D%5C%5C+x_%7Bb5%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%252Bb_0%5Cend%7Bsplit%7D">
<meta property="og:image" content="https://pic4.zhimg.com/v2-0bc83b72ef50099b70a10cc3ab528f62_b.jpg">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-c1010eb5dcf032ea95eab495a45f9b31_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-f53f6ac43abd2555cfbbba6ea7fdc0e4_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-644d108587a6ce7fa471ede5d2e11e98_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-c78b8d059715bb5f42c93716a98d5a69_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-6df64fccc9a8e2f696626f85233acb3c_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-65461a21a909eca2e190c54db59a2c8f_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/v2-c7f1ea1d42820b4de30bd548c3986ecd_b.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-d11e1d2f2c41b6df713573f8155bc324_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-54a469b2873542e75abf2bc5d8fcaa1a_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-a9983c3cee935b68c73965bc1abe268c_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-11a4d56793af815eb2b4585d64aec178_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-1a4b2a3795d8f073e921d766e70ce6ec_720w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-cd717414dcf32dac4df73c00f1e7c6c3_720w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-8e9d7ec0662e903e475bd93a64067554_720w.png">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-cf87890eb8f2358f23a1ac78eb764257_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-60e7c1e89c5aed5b828cbb24fc1e5a80_720w.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-1aac56212d5d143a006d569318e3ee8b_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-18c11c6f485e9f1bbc9a50eb3d248439_720w.png">
<meta property="og:image" content="https://picb.zhimg.com/80/v2-0ce892f8b247f2b48a76cc57cbcba41d_720w.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-9692631d087622f1b34c80055f13fac5_720w.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-59429b22ac90930c502736b33db0d8e0_720w.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-40fb6ab7bf89ce43af1c52e673da65eb_720w.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-87fc4b7449d751c59977c3a368ae6f7e_720w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-d3fd09f011583932b832ea64f78233af_720w.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-0bebba2947e5e968a93e6def0ae5d00c_720w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-389496d1436895dfe43199a0f54c35ca_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-55dca535836121c65546bc11e2d457c1_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-09e1bda72c4b903e25db203ab4aa6dc6_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-e153aa561b6d729f5023e077eb7f204c_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-a6c5f337408f1e3ec31d67074a830bd6_720w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-764d83497fecd09920e19cfd91fb1dd8_720w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-cd6a1087598ee5a2ae24d1a86a6b2190_720w.jpg">
<meta property="article:published_time" content="2020-08-11T01:59:15.000Z">
<meta property="article:modified_time" content="2020-08-12T16:12:26.450Z">
<meta property="article:author" content="Zhangshuai">
<meta property="article:tag" content="hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic1.zhimg.com/v2-0cd32763d1067e4fa6ae63e494302e07_1440w.jpg?source=172ae18b">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/08/11/YJango其他文章汇总/"/>





  <title>YJango其他文章汇总 | 张帅的Blog</title>
  








<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">张帅的Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">用hexo搭建的简易博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            Schedule
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            Commonweal 404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/11/YJango%E5%85%B6%E4%BB%96%E6%96%87%E7%AB%A0%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhangshuai">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar2.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张帅的Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">YJango其他文章汇总</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-11T09:59:15+08:00">
                2020-08-11
              </time>
            

            

            
          </span>

          


          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><a href="https://githubzhangshuai.github.io/2020/08/10/%E5%AD%A6%E4%B9%A0%E8%A7%82/#more" target="_blank" rel="noopener">YJango学习观系列</a><br><a id="more"></a></p>
<ul>
<li><a href="#header1">函数、概率、信息的基础串讲</a></li>
<li><a href="#header2">如何生动有趣的入门线性代数</a></li>
<li><a href="#header3">概率simple入门</a></li>
<li><a href="#header4">很多人都不知道自动化与机器学习的区别</a></li>
<li><a href="#header5">机器学习理论引入的知识分类</a></li>
<li><a href="#header6">英语总结</a></li>
<li><a href="#header7">深层学习为何要“Deep”</a></li>
<li><a href="#header8">YJango的TensorFlow1.x整体把握</a></li>
<li><a href="#header9">YJango的循环神经网络——介绍</a></li>
<li><a href="#header10">YJango的循环神经网络——实现LSTM</a></li>
<li><a href="#header11">YJango的循环神经网络——scan实现LSTM</a></li>
<li><a href="#header12">YJango的循环神经网络——双向LSTM&amp;GRU</a></li>
<li><a href="#header13">YJango的卷积神经网络——介绍</a></li>
<li><a href="#header14">YJango的Word Embedding—介绍</a></li>
<li><a href="#header15">YJango的Batch Normalization—介绍</a></li>
</ul>
<h1 id="函数、概率、信息的基础串讲"><a href="#函数、概率、信息的基础串讲" class="headerlink" title="函数、概率、信息的基础串讲"></a><span id="header1">函数、概率、信息的基础串讲</span></h1><p><img src="https://pic1.zhimg.com/v2-0cd32763d1067e4fa6ae63e494302e07_1440w.jpg?source=172ae18b" alt></p>
<p>一、函数（映射）<br>这是一个发生在信使、农民、猎人、学者、商人之间的故事。<br>为了在恶劣环境下增加生存几率，信使编造了一个故事：<br>大家都是象神的子民，需一起生活，用自己的劳动所得去换取别人的劳动所得。</p>
<p>一次，猎人用一块猪肉与农民交换了一个土豆。<br>但第二次交换时，肉块比较大，猎人觉得自己换的不如之前的多。<br>为确保每次交换的公平，他们向学者求助。</p>
<p>学者需要确保的不是具体一次交换的公平，而是以后每次交换的公平。<br>但每次交换时，肉块重量都可以变化，并不确定。</p>
<p>所以学者把肉块每次交换的重量叫做变量 (variable) x ，<br>具体一次交换的重量叫做常量 (constant) $x_2$ ，下角标的 2 表示第 2 次。<br>同理土豆每次交换的重量叫做变量 (variable) y 。</p>
<p>接下来学者需要确定的是重量（变量）可以有哪些值。</p>
<p>于是他把所有可能猪肉重量想象成一个整体，叫做集合 (set) X= ｛所有可能猪肉重量｝。<br>所有土豆重量的整体叫做集合 Y= {所有可能土豆重量}。<br>集合内所包含的每个重量都叫做元素 (element)。</p>
<p>由于变量 x 与长宽高一样，所描述的重量是一种状态 (state)，<br>因此包含状态这种物理意义的集合 X 也叫空间 (space) X 。</p>
<p>那么学者需要确保的就是：<br>猪肉空间 X 里任意重量 x 都可以换得土豆空间 Y 里一个公平重量 y ，<br>也就是确定从 x 到 y 的变换关系 。</p>
<p>他把输入 x 这种变换前的状态叫做自变量 (independent variable)，<br>把输出 y 这种变换后的状态叫做因变量 (dependent variables)。<br>把从 x 到 y 这种单向变换的关系叫做函数或映射 (transformation or function or map) f:x-&gt;y （二者不一定非是因果关系，只是想根据自变量获得因变量的值而已）。</p>
<p>由于肉的获取较为困难，所以大家同意每次交换的土豆重量 y 是猪肉重量 x 的 2 倍，也就是 y=f(x)=2x 。</p>
<blockquote>
<p>集合 set（空间 space）：个体组成的整体。<br>元素 element（常量 constant）：整体内部的个体 。<br>变量 variable（宏观态 macro state）：集合的任意（某个）元素。<br>自变量：变化前的任意状态。<br>因变量：变化后的任意状态。<br>常量 constant（微观态 micro state）：集合的具体（一个）元素。<br>函数 transformation（变换）：某集合任意元素变成另个集合对应元素的方式（关系）。</p>
</blockquote>
<p>但此时学者遇到了一个困难，怎么测量重量呢？</p>
<p>学者想到的办法是用其它物体的重量作为参照重量进行对比。<br>这个物体需要易保存，且尽量不随时间变化而改变，因此肉和土豆都不行。</p>
<p>最后学者选择了一块金属，恰好与我们今日所选择的千克等重，并把它的重量称为常量k 。 他又选了一块小金属，重量是千克的一半，并把它的重量称为常量 b。</p>
<p>学者做了一个天枰。每次测量时就去看最少用多少 ( n ) 个参照重量 k 可以翘起 m 重量的被测物。<br>n=m/k ， n 便是重量，单位是千克。若选择小金属， n=m/b ，则单位是斤。</p>
<blockquote>
<p>测量：用选定事物的属性来 衡量 要测量事物的属性。</p>
</blockquote>
<p>可算出肉的重量后，很难找到相同重量的土豆，且土豆又不易分割。<br>所以学者又发明了一个中间交换物：钱（货币）。</p>
<p>钱，这个中间交换物可以是任何东西，甚至可以是并非实体的口头约定，<br>关键是如何才能让大家都认可。</p>
<p>聪明的学者从海边找了一堆他们的住处无法见到的贝壳，<br>又让信使告诉大家：象神托梦说“大家死后可用贝壳跟象神换取任何物品。”<br>于是大家欣然接受用自己劳动的所得交换贝壳。</p>
<blockquote>
<p>货币：构建在公众信用基础上的中间交换量 信用：可由礼德、宗教、法律等提供</p>
</blockquote>
<p>二、概率<br>农民和学者住的近，但和其他人住的都比较远，不过商人的倒卖填补了交换的距离障碍。</p>
<p>根据大家的喜好，鸡、鸭、猪、羊、牛、鹿的肉价分别如下：</p>
<p>鸡肉：2 贝壳/千克<br>鸭肉：3 贝壳/千克<br>猪肉：4 贝壳/千克<br>羊肉：5 贝壳/千克<br>牛肉：6 贝壳/千克<br>鹿肉：7 贝壳/千克</p>
<p>可有一次商人要卖肉给农民时，却忘了自己手里的这块肉是哪种肉类。<br>对肉类有不确定性的商人就问住在隔壁的学者。<br>可学者也不确定这是什么肉类，<br>但学者知道猎人每个月都会猎到 5 只鸡、4 只鸭、3 头猪、2 头羊、1 头牛、1 头鹿。</p>
<p>学者把所有可能的猎物想象成另一个集合，称其为样本空间 S ，<br>把 3 头猪想象成一个小集合 C= {猪阿强,猪不屈,猪富贵}，<br>而小集合是由 S 里的部分元素组成的 $C \subsetet S$ ，<br>因此学者在数学上称它为 S 的 子集 (subset)，<br>在物理上称它为事件 (event)，<br>一共有 6 个不相交的事件。</p>
<p>A= {鸟愤怒，鸟闪电，鸟炸弹，鸟大嘴，鸟抑郁}<br>B= {可达鸭、哥达鸭、大葱鸭、小黄鸭}<br>C= {猪阿强,猪不屈,猪富贵}<br>D= {喜羊羊,懒羊羊}<br>G= {撼地牛}<br>K= {鹿大仙}</p>
<p>学者把这块肉具体是哪个猎物的肉叫做结果 s (outcome)。<br>若结果是事件 A 里的元素 $s \in A$ ，那这块肉就是鸟肉 A （事件 A 发生）。</p>
<p>学者把事件作为输入，把自己对事件会发生的确信度作为输出，<br>抽象出了一个叫做概率的函数 P() 。</p>
<p>当样本空间内的样本发生几率相同时，确信度与事件的函数关系是：<br>确信度等于事件元素个数占有样本空间元素个数的比例 P(A)=|A|/|S| ，<br>因此确信度所处的区域是 [0,1] ，而 1 表示必然事件，0 表示不可能事件。</p>
<p>于是学者对于 6 个事件的确信度分别是：<br><img src="https://www.zhihu.com/equation?tex=P%28A%29+%3D+5%2F16%5C%5C+P%28B%29+%3D+4%2F16%5C%5C+P%28C%29+%3D+3%2F16%5C%5C+P%28D%29+%3D+2%2F16%5C%5C+P%28G%29+%3D+1%2F16%5C%5C+P%28K%29+%3D+1%2F16%5C%5C" alt></p>
<blockquote>
<p>结果：可能发生的状态。<br>样本空间：所有可能发生的结果所组成的集合。<br>事件：样本空间的子集。<br>发生：当实际结果$s_{outcome} \in A$ 时，表示 A 事件发生。<br>概率：将事件空间变换到概率空间的函数。<br>朴素概率计算： $P_{nvative}(A)=|A|/|S|$ （A 表示集合中元素的个数）。</p>
</blockquote>
<p>但每次都输入一个事件非常不方便，而且事件本身无法进行运算。<br>当某个事件发生后，需要用该类肉的价格来替换事件进行运算。</p>
<p>所以学者干脆想出了另一个函数，叫做随机变量 X （随机变量不是变量，是函数），<br>输入是事件，而输出就是对应肉类的价格。</p>
<p>这样 6 个事件经过随机变量 X() 后就被变换成了可运算的数字。<br><img src="https://www.zhihu.com/equation?tex=X%28A%29+%3D+2%5C%5CX%28B%29+%3D+3%5C%5CX%28C%29+%3D+4%5C%5CX%28D%29+%3D+5%5C%5CX%28G%29+%3D+6%5C%5CX%28K%29+%3D+7" alt></p>
<blockquote>
<p>随机变量(r.v.)：将事件空间变换到实数空间的函数（映射更准确）。</p>
</blockquote>
<p>随机变量 X 有 6 可能状态种，<br>但不管是哪种肉类（鸡肉、鸭肉、猪肉、羊肉、牛肉、鹿肉），它们都是肉，<br>就如同男人和女人都叫人一样。</p>
<p>学者把 随机变量 X 所代表的肉 叫做宏观态 (macrostate)，<br>把随机变量 X 的每个具体的可能状态叫做微观态 (microstate)。</p>
<blockquote>
<p>宏观态：不考虑内部差异的状态统称（就是变量） 微观态：考虑内部差异的具体状态（就是常量）</p>
</blockquote>
<p>学者想知道肉类这个宏观态的各个微观态的概率分布（distribution）情况，便将事件随机变量值 X 作为输入，将事件的确信度值 P 作为输出，构造出了概率质量函数 (PMF)。</p>
<blockquote>
<p>概率质量函数 (PMF)：将离散随机变量的实数空间变换到概率空间的函数。</p>
</blockquote>
<p>虽然学者对此肉的种类依然有不确定性，<br>但他根据概率和对应的随机变量值算出了平均价格，<br>称之为随机变量 [公式] 的期望 (expected value)。</p>
<p>$E(X)=\sum_i^6p_ix_i=5/162+4/163+3/164+2/165+1/166+1/167 \approx 3.56$</p>
<blockquote>
<p>期望：随机变量 [公式] 所有可能状态的加权平均值。</p>
</blockquote>
<p>学者提议商人用这个价格卖给农民，但农民只想用正确的价格购买。<br>由于这是商人自己忘记肉类而造成的，<br>因此商人不得不求助信使到猎人那里问一下自己上次买的是什么肉，<br>再用点火把的方式来来通知商人。</p>
<p>他们约定用 3 个火把的状态来通知肉的种类：</p>
<p>不点、不点、不点<br>不点、不点、点燃：对应鸡<br>不点、点燃、不点：对应鸭<br>不点、点燃、点燃：对应猪<br>点燃、不点、不点：对应羊<br>点燃、不点、点燃：对应牛<br>点燃、点燃、不点：对应鹿<br>点燃、点燃、点燃</p>
<p>信息</p>
<p>可问题来了，商人该付给信使多少个贝壳呢？<br>信使通知商人肉的种类消除的是不确定性，该如何量化不确定性呢？</p>
<p>学者最初想沿用测量重量的方法：<br>看看最少用多少 ( n ) 个参照宏观态（另一个随机变量）的不确定性，<br>可以消除随机变量 $X$ 的不确定性。</p>
<p>学者选择火把的状态做为参照宏观态（也就是抛硬币会产生了两种状态），<br>用侧重量的公式来测量不确定性，分母是参照宏观态的微观态数量，<br>点燃或不点燃两种状态的数量，即 2，<br>分子是随机变量 X 的微观态数量，即 6 种肉类。</p>
<p>n=m/k=6/2 ，得出 3</p>
<p>然而 3 个火把一共可以产生 8 种不同状态，而不是 6 种。</p>
<p>学者很快意识到这种方法 n=m/k=6/2=3 ，<br>测量不确定性是错误的沿用了测量重量时的假设。</p>
<p>测量重量时用除法是由于重量 m 是以线性方式进行累积的，<br>n 是累积次数， k 是单位的重量（单次累积量），<br>累积 n 次后获得了 m=n*k 千克的肉。<br>反过来，要求累积了多少次，就用反函数 n=m/k 。</p>
<p>可状态却不是以线性方式进行累积的，<br>每加一个火把时，它的两种状态会与之前所有状态共同产生新状态 n<em>n</em>n ，共 k 次。</p>
<p>即状态是以指数方式累积的，<br>n 是累积次数， k 是参照宏观态的微观态数量，<br>累积完 n 次后获得了 $m=k^n$ 个不同的状态。<br>若反过来求 m 个状态是由参照宏观态多少次累积而成的，<br>就用指数的反函数，即对数 $n=log_km$ 进行测量。</p>
<p>于是学者构建了一个新的函数：信息熵 (information entropy)，<br>输入是随机变量 X ，输出是不确定性。<br>而用于消除不确定性的事物叫做信息。</p>
<p>熵相当于一个没有光的黑屋子，信息相当于把黑屋子照亮的光。<br>同一个随机变量 X 的信息与熵数量相等，意义相反。消除不确定性意味着获取信息。</p>
<p>学者又把由 2 种微观态的参照宏观态所测出信息熵的单位叫做 bit 。<br>把由 e 种微观态的参照宏观态所测出信息熵的单位叫做 nat 。<br>把由 10 种微观态的参照宏观态所测出信息/熵的单位叫做 ban。</p>
<p><img src="https://www.zhihu.com/equation?tex=log_2+6+%5Capprox+2.58+%5C++bits%5C%5C+log_e+6+%5Capprox+1.79+%5C++nats%5C%5C+log_%7B10%7D+6+%5Capprox+0.78++%5C++bans%5C%5C" alt></p>
<p>然而这个公式只在待测宏观态的所有微观态都是等概率时才有效，<br>因为选定的参照宏观态本身的 2 种微观态就是等概率 50% 与 50%。<br>H(X) bit 的信息可以从 $2^{H(X)}$ 个等概率的微状态里确定对应宏观态具体是哪个微观态。</p>
<p>可学者已经通过统计观察，获得了一些这块肉是哪种肉的信息，<br>他知道这块肉更有可能是鸡肉，6 种微观态不再是等概率。<br>即使信使什么消息都不传递，他也有更高的可能性猜中鸡肉。<br>若这时再让信使告诉学者肉类是鸡肉，那么他消除的不确定性就不足 &lt; log_26 bits</p>
<p>若想算出分布不是均等的宏观态 X 的信息，他需要调整公式，<br>分别测量宏观态所对应每个微观态的信息后，再平均起来。</p>
<p>事实上，上面的公式本身就可视为 6 个微观态的信息平 $p_i$ 均后的结果：<br>$H(X)=\sum_i^6log_2m_i=1/6log_26+1/6log_26+1/6log_26+1/6log_26+1/6log_26+1/6log_26 \approx 2.58bits$</p>
<p>这时只需将 $p_i$ 替换成对应微状态的比例即可，</p>
<p>$H(X)=\sum_i^6log_2m_i=5/16<em>m1+4/16</em>m2+3/16<em>m3+2/16</em>m4+1/16<em>m5+1/16</em>m6$</p>
<p>然而学者不知道 $m_i$ ，他不知道确认每个微观态相当于从多少个等概率的状态里确定一个状态，但他知道，概率的倒数 $1/P_i$ 就等于 $m_i$ 个等概率状态的个数。<br>当 $P_i$ 是 1%，那么确定 1% 可能发生的事件，相当于从 100 个等概率的状态里确定一个状态，相当于要用 $6.64 \approx log_2100$ 个火把的组合才能让某人从 100 个等概率状态里确定一个状态。所以，学者对肉类的实际不确定性是：</p>
<p>$H(X)=\sum_i^6log_21/p_i=5/16log_216/5+4/16log_216/4+3/16log_216/3+2/16log_216/2+1/16log_216/1+1/16log_216/1 \approx 2.35bits $</p>
<p>经过整理后，学者就得到了最后的通用熵公式： $H(X)=\sum p_ilog_2{p_i}^{-1}=-\sum p_ilog_2{p_i}$</p>
<p>这个公式不再假设随机变量 X 是均匀分布，而是 X 的每个取值的信息都可以变化。<br>当 X 是连续随机变量时，就正是要用超智能体02视频里所讲的积分，即累积速率可变的“乘法”来求得。</p>
<p>通用熵公式：每个微观态的信息量（又叫自信息）的加权平均值。</p>
<p>那么学者最后让商人付给信使 2.35 个贝壳了吗？<br>没有，他让商人付了 2.58 个贝壳。</p>
<p>因为对学者而言，学者知道肉类的部分信息，6 种状态不再是等概率；<br>可对商人而言，商人没有任何关于该肉类的信息，6 种状态都是等概率的，<br>而这是商人与信使之间的交换。<br>也就是说，信息是相对于观察者（接受者）而言的。</p>
<p>对猎人而言，肉类的熵为 0，他没有不确定性。<br>对学者而言，肉类的熵为 2.35 bits ，他的不确定性被统计到的信息减少了。<br>对商人而言，肉类的熵为 2.58 bits ，他的不确定性最大。</p>
<p>“太阳从东边升起”这句话， 对已经知道这件事情的人而言，没有提供任何信息。<br>对知道或东或西升起的人而言，因为从 2 个等可能状态中确定了一个状态，提供了 1 bit 的信息。<br>而对于觉得东南西北 4 个方向都有可能的人而言，提供了 2 bits 的信息。</p>
<blockquote>
<p>熵的相对性：相对于观察者</p>
</blockquote>
<p>教育</p>
<p>学者知道每个人的存活质量是由大家的效率而共同决定的。<br>如果猎人打猎的技术好，大家就有更多的肉可以交换，<br>于是学者把大家聚在一起，教授函数、概率、熵的概念。</p>
<p>农民对于熵和概率的区别很迷惑，于是学者解释道：</p>
<p>概率的输入是事件（一个具体的微观态），<br>输出是该事件会发生的确信度，是微观态这个常量的属性。<br>而熵的输入是随机变量 X（一个宏观态），更准确的说是该宏观态的分布，<br>输出是该随机变量 X 会是哪个微观态的不确定性，是宏观态的属性。</p>
<blockquote>
<p>概率：微观态的确定性。<br>熵：宏观态的不确定性。</p>
</blockquote>
<p>猎人问道，可不可以说熵是描述无序或混乱的。学者并不建议这样理解信息熵。</p>
<p>因为日常生活中的无序（disorder）和混乱（chaos）两词多用于描述一个具体微观态的排列方式，所以没有物理背景的初学者听到这种描述时，会错误的认为熵是描述一个具体的微观态如何排列的。</p>
<p>于是就出现了大量的人说：这种排列方式的熵大，这种排列方式的熵小。<br><img src="https://pic1.zhimg.com/80/v2-be88c02bf2d6aa49530d07cced9a4632_720w.jpg" alt></p>
<p>可对你我而言，两种排列方式的熵是 0，<br>因为我们已经看到了它，获得了确定它当前状态的所有信息。</p>
<p>不仅如此，由于熵是描述宏观态的不确定性，<br>所以在讨论熵时一定要明确指定要描述的是哪个宏观态的熵。<br>因为即使是同样的场景，也会因选择不同的宏观态而产生不同的熵。</p>
<p>为体会这种相对性我们回到现代，看一下这个叫做俄罗斯赌盘的自杀游戏。</p>
<p>如果把随机变量（宏观态） X 定义为第几枪会打出子弹，<br>那么样本空间为 S {第1枪，第2枪，第3枪，第4枪，第5枪，第6枪}。</p>
<p>没观察前，6 枪都可能，并不确定会在哪一枪：不确定性是 $log_26$ 。</p>
<p>第一次开枪，消除掉了第一枪的不确定性，还有 5 种可能，不确定性是 $log_25$ ，<br>而这一次观察提供了 $log_26-log_25 bits$ 的关于随机变量 X 的信息。</p>
<p>如果第二次开枪打出了子弹，则消除了所有不确定性，获得 $log_25$ 的信息，<br>若没打出子弹，则消除掉了第二枪的不确定性，还有 4 种可能，不确定性是 $log_24$ ，<br>而这一次观察提供了 $log_25-log_24 bits$ 的关于随机变量 X 的信息。</p>
<p>以此类推开 5 枪后若都没打出子弹，我们的不确定性也消除了，<br>全部的信息加起来也正好是 log_26 bits 。</p>
<p>然而如果把随机变量（宏观态） X 定义为开枪后的人是死（微观态）是活（微观态），<br>那样本空间就为 S= {死，活}。</p>
<p>开枪前，熵是 $H(X)=-\sum p_ilog_2p_i=-1/6log_2(1/6)-5/6log_2(5/6) \approx 0.65bits$</p>
<p>概率质量函数是 ｛ 5/6,1/6 ｝</p>
<p>开完一枪后，熵为 0， 我们观察到这个人要么死了，要么还活着。</p>
<p>熵的相对性：相对宏观态（随机变量）</p>
<h1 id="如何生动有趣的入门线性代数"><a href="#如何生动有趣的入门线性代数" class="headerlink" title="如何生动有趣的入门线性代数"></a><span id="header2">如何生动有趣的入门线性代数</span></h1><p>什么是线性代数？<br>不断变化的世界使我们产生时间观念。正确描述事物状态及其不同时间下的变化至关重要。我们知道在三维空间下如何描述物体的位置。然而除了长宽高，世界上还有很多决定事物状态的因素。如决定股票价钱的因素、决定天气的因素。这些因素又该如何合理的描述？线性代数给了我们答案。</p>
<p>线性代数是有关任意维度空间下事物状态和状态变化的规则。</p>
<p><img src="https://pic1.zhimg.com/80/v2-7c00f984b625f66240f47d092ba14fe1_720w.jpg" alt></p>
<p>向量点乘</p>
<p>先让我们来看一段<a href="https://www.bilibili.com/video/av6467776/" target="_blank" rel="noopener">视频</a>，但我希望你只看一遍！PPAP洗脑全球<br>如果你继续读到了这句话，那么恭喜你，你抵抗住了病毒的洗脑。同时你听到了3个向量点乘。</p>
<p>1、I have a pen, I have an apple—-&gt;apple pen<br>[applepen] = [1 1r]·[pen r apple r] （eq.1）<br>2、I have a pen, I have a pineapple—-&gt;pineapple pen<br>[pine apple pen] = [1 1]·$\left[ \begin{array}{cc} pen \\ pineapple \end{array} \right]$ （eq.2）<br>3、apple pen, pineapple pen—-&gt;pen pineapple apple pen<br>[penpineapple applepen] = [1 1]·$\left[ \begin{array}{cc} applepen \\ pineapplepen \end{array} \right]$ （eq.3）<br>以（eq.1）举例。等式右边的第二个向量表示你有什么，右边的第一个向量表示你各拿几个，而等式的左边表示你获得了什么。从中你可以看出来：</p>
<p>向量点乘(dot product)是一种组合(combination)<br>矩阵乘向量<br>我们也可以把（eq.1）（eq.2）合二为一表示为（eq.4）：</p>
<p>I have a pen, I have an apple—-&gt;apple pen，<br>I have a pen, I have a pineapple—-&gt;pineapple pen<br>$\left [ \begin{array}{c} applepen \\ pineapplepen \end{array} \right] = \left [ \begin{array}{ccc} 1&amp;0&amp;1 \\ 0&amp;1&amp;1 \end{array} \right ]· \left [<br>    \begin{array}{c} apple \\ pineapple \\ pen \end{array} \right] $（eq.4）</p>
<p>这时，表示你各拿几个的向量变成了两行（两组），也就成了矩阵（向量是只有一行或一列的矩阵）。<br>表示你各拿几个的一个向量也叫一组权重(weights)。<br>在 [1 0 1]中，第一个1对应着apple，第二个0对应着pineapple，第三个1对应着pen，我们不可以随意调换位置。所以，</p>
<blockquote>
<p>向量是有顺序的一组数字，每个数字都是该向量的一个因素(element) 因素横着排列的向量叫做行向量(row vector)，因素竖着排列的向量叫做列向量(column vector)</p>
</blockquote>
<p>到这里我们需要更具体的描述一下第一个结论。向量点乘是一种组合，但</p>
<blockquote>
<p>向量点乘向量可以是列向量中各个因素的一个组合</p>
</blockquote>
<p>上式（eq.4）可分两步计算：</p>
<p>计算第一行权重$\left [ \begin{array}{ccc} 1&amp;0&amp;1  \end{array} \right ]· \left [<br>    \begin{array}{c} apple \\ pineapple \\ pen \end{array} \right]$得到的组合apple pen后，放到了第一行$\left [ \begin{array}{c} applepen \\  \end{array} \right]$<br>计算第二行权重$\left [ \begin{array}{ccc}  0&amp;1&amp;1 \end{array} \right ]· \left [<br>    \begin{array}{c} apple \\ pineapple \\ pen \end{array} \right] $得到的组合pineapple pen后，放到了第二行$\left [ \begin{array}{c}  \\ pineapplepen \end{array} \right]$<br>行成的$\left [ \begin{array}{c} applepen \\ pineapplepen \end{array} \right]$依然有顺序，仍然是一个向量。比较向量点乘向量，我们可以看出</p>
<blockquote>
<p>矩阵乘向量可以是列向量中各个因素的多个有顺序的组合</p>
</blockquote>
<p>向量乘矩阵<br>然而形成组合的成分并不一定非要是向量中的各个元素，也可以是不同向量之间的组合。我们可以把（eq.1）（eq.2）（eq.3）改写成（eq.5）（eq.6）：<br>$\left[ \begin{array}{c} apple&amp;pineapplepen \end{array} \right]=[1·1]·\left [ \begin{array}{rr} pen&amp;pen\\ apple&amp;pineapple \end{array} \right ]$（eq.5）<br>$\left[ \begin{array}{c} penpineappleapplepen \end{array} \right]=\left[ \begin{array}{c} pineapplepen&amp;applepen \end{array} \right]·\left [ \begin{array}{r} 1\\1 \end{array} \right ]$（eq.6）</p>
<p>在（eq.5）等式右侧的矩阵是由两个行向量组成的。矩阵中，第一个行向量表示怪蜀黍两次组合中分别先拿什么，第二个行向量表示两次组合中分别后拿什么。等式右侧的权重（行向量）的第一个因素对应着矩阵中第一个行向量的个数，第二个因素表示右侧第二个行向量的个数。这样保持矩阵中每个行向量内部因素的比例，完成矩阵内向量与向量之间的组合。</p>
<blockquote>
<p>向量乘矩阵可以是矩阵中各个行向量的多个有顺序的组合</p>
</blockquote>
<p>而向量中的每个因素都可以当成是因素个数为一个的向量，也再次解释了为什么，向量可以看成是矩阵。</p>
<p>在（eq.6）中，你会发现，要形成组合的向量被拿到了乘法点(dot)的左边，而权重被拿到了右边。因为当行向量的因素作为组合成分时，乘法点右侧的矩阵（向量）装有着权重信息。效果是拿一个penpineapple和一个applepen形成组合。<br>从中你可以看出矩阵乘法并不满足乘法交换律，因为交换了两个矩阵的位置，就交换了权重与要形成组合的向量的位置。</p>
<blockquote>
<p>矩阵乘法不满足乘法交换律：commutative law: AB =! BA</p>
</blockquote>
<p>矩阵乘矩阵<br>如果怪蜀黍跳了两遍舞蹈。第二遍跳舞时，他在两次组合时，后一次拿的东西都是都拿两个，那么我们就可以把等式右侧的行向量变成两个行向量，也就形成了一个矩阵。<br>$\left[ \begin{array}{cc} applepen&amp;pineapplepen\\2<em>apple+pen&amp;2</em>pineapple+pen \end{array}\right]=\left[ \begin{array}{cc} 1&amp;1\\1&amp;2 \end{array} \right]·\left[ \begin{array}{cc}pen&amp;pen\\apple&amp;pineapple \end{array} \right]$</p>
<p>那怪蜀黍在唱第二遍时，就要唱：<br>I have a pen. I have two apples. 2-Apples-pen!<br>I have a pen. I have two pineapples. 2-Pineapples-pen!<br>那该蜀黍就有卖水果的嫌疑，每次都拿两个水果。<br>至此你看到了我用的是2*pineapple +pen方式去形成组合。也就是只有乘法来控制数量，加法来组合不同向量。这样的组合方式才是线性代数讨论的组合，即线性组合。所以我们所有概括的结论中，所有组合前面都要加上线性二字。同时乘法所乘的数属于什么数要事先规定好（经常被规定为是实数$ \subset R$，也有虚数域）。不过这还没有结束，严谨性是数学的特点。我上文所说的“加法”“乘法”也只不过是一个名字而已。它们到底指的是什么运算，遵循什么样的规则。然后当你看线性代数教材的时候，你就会发现这8条规则。</p>
<p>$x+y=y+x$.<br>$x+(y+z)=(x+y)+z$.<br>There is a unique “zero vector” such that $x+0=x$ for all x.<br>For each x there is a unique vector $-x$ such that $x+(-x)=0$.<br>$1x=x$.<br>$(c_1c_2)x=c_1(c_2)x$.<br>$c(x+y)=cx+cy$.<br>$(c_1+c_2)x=c_1x+c_2x$.</p>
<p>然而你不需要去记它们。你只需要知道，他们是用于描述和约束在线性代数中的加法，乘法的运算。特别要注意的是，这些运算都有一个原点（0），为了允许正负的出现。</p>
<blockquote>
<p>线性组合：一组向量乘上各自对应的一个标量后再相加所形成的组合。（满足上述对乘法、加法的规则）</p>
</blockquote>
<p>当我们再用(m by n)，即m行n列的方式去描述一个矩阵的形状(shape)时，你就得到了矩阵的第一种描述：</p>
<p>矩阵的静态信息<br>坐标值与坐标系：</p>
<p>矩阵所包含的信息从来都是成对出现，拿向量$\left[ \begin{array}{c} apple\\pen \end{array} \right]$举例来说，这个向量并没有被赋予任何数值。但你已经确定了你要在apple的数量和pen的数量的两个因素（两个维度）下描述你的数据。换句话说，你已规定好你的坐标系。所以当你写出任何具有实际数值的向量，例如$\left[ \begin{array}{c} 2\\1 \end{array} \right]$<br>时，他们的坐标系（二维向量空间）和坐标值就同时被确定了。它实际上是$\left[ \begin{array}{c} apple\\pen \end{array} \right]$和$\left[ \begin{array}{c} 2\\1 \end{array} \right]$的缩写。二者无法分割。即使是$\left[ \begin{array}{c} apple\\pen \end{array} \right]$，虽然我没有再pen，apple前面写具体数字。但依然包含所有因素间的比例相同的隐含信息。而调换2和1的顺序同时也表示坐标轴之间的调换。</p>
<p>坐标值的两种看法：</p>
<p>单单考虑坐标值时，有两种角度去理解矩阵所包含的静态信息。</p>
<p>矩阵的静态坐标值信息：</p>
<blockquote>
<p>（1）若干个维度相同的要形成组合的向量信息<br>（2）若干组维度相同的权重信息</p>
</blockquote>
<p>他们本质都是向量，然而（2）中所指的向量（或叫权重）是用于控制每个向量的数量（scale），而（1）中的所指的向量是要通过乘法与加法的线性组合形成新向量的向量。</p>
<p>拿矩阵$\left[ \begin{array}{c} 1&amp;1\\2&amp;1 \end{array} \right]$来说，你可以理解成该矩阵包含了两个行向量，也可以理解为包含了两组权重；同时，用列向量的方式也同样可以理解成向量和权重。</p>
<p>矩阵的动态信息</p>
<p>在一个矩阵内，你把矩阵内的向量理解为向量或权重都可以。但是当两个矩阵进行矩阵乘法时，一旦选择以权重信息理解其中一个矩阵，另一个矩阵的信息就会被瞬间确定为要形成组合的向量（量子力学的味道）。</p>
<p>$\left[ \begin{array}{cc} applepen&amp;pineapplepen\\apple+2<em>pen&amp;pineapple+2</em>pen \end{array} \right]=\left[ \begin{array}{cc} 1&amp;2\\2&amp;1 \end{array} \right] · \left[ \begin{array}{cc} pen&amp;pen\\apple&amp;pineapple \end{array} \right]$<br>例来说，它的实际数学表达应该是：<br>$\left[ \begin{array}{cc} 1+1&amp;1+1\\1+2<em>1&amp;1+2</em>1 \end{array} \right]=\left[ \begin{array}{cc} 1&amp;2\\2&amp;1 \end{array} \right]·\left[ \begin{array}{cc} 1&amp;1\\2&amp;1 \end{array} \right]$ 即便是都换成了数字，其物理意义任然存在，始终并未丢失。但也可以被理解为其他的物理意义。我会在$\left[ \begin{array}{cc} 1&amp;1\\2&amp;1 \end{array} \right]$ 与 $\left[ \begin{array}{cc} pen&amp;pen\\apple&amp;pineapple \end{array} \right]$ 二者之间进行切换，他们表示同一个矩阵。</p>
<p>当我把矩阵$\left[ \begin{array}{cc} 1&amp;2\\2&amp;1 \end{array} \right]$看成是两组行向量的权重时，后一个矩阵的两个行向量$\left[ \begin{array}{cc} pen&amp;pen \end{array} \right]$和$\left[ \begin{array}{ccc} apple&amp;pineapple&amp;diag \end{array} \right]$就瞬间被赋予了要形成组合的向量的观察方式。<br>当我把矩阵$\left[ \begin{array}{cc} 1&amp;1\\1&amp;1 \end{array} \right]$看成是两组列向量的权重时，前一个矩阵的两个列向量$\left[ \begin{array}{ccc} 1&amp;r&amp;2 \end{array} \right]$和$\left[ \begin{array}{c} 1\\1 \end{array} \right]$就瞬间被赋予了要形成组合的向量的观察方式。</p>
<p>矩阵的动态信息，两个矩阵相乘A⋅B 时，</p>
<blockquote>
<p>当把前者矩阵(A)中行向量理解成若干组权重，后者矩阵(B)中的行向量就是要形成组合的成分。</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/80/v2-fe7c8ed324c9a2e5efdec392ee9a80c0_720w.jpg" alt><br>同样的两个矩阵相乘</p>
<blockquote>
<p>当把后者矩阵(B)中列向量理解成若干组权重，前者矩阵(A)中的列向量就是要形成组合的成分。</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-9f586226bbae39c9dabb28d8d4436928_720w.jpg" alt></p>
<p>注意对应行向量与列向量。</p>
<p>请回想线性组合的描述（一组向量乘上各自对应的一个标量后再相加所形成的组合），这是因为向量的维度和权重的维度要一一对应。所以，</p>
<p>矩阵A(m by n)和矩阵B(p by q)能够做乘法的条件是 n = p</p>
<p>向量空间<br>很多线性代数教材所引入的第一个概念就是线性空间（linear space）。可见它的地位。虽然它有些抽象，但是却是自然而然推演出来的一个概念。<br>空间的本质是集合。而且是一个能够容纳所有你要描述内容的集合。<br>在具体讨论之前先要对上句话中“你要描述的内容”进行进一步说明。<br>从如何理解线性代数这四个字开始。首先我们已经知道了什么是线性（那8个条件约束的加法和乘法）。那什么是代数？意思是指你可以把任何概念都代入其中。<br>可以怪蜀黍手中的水果和笔换成盆和<a href="https://link.zhihu.com/?target=http%3A//www.bilibili.com/video/av6470859/">大菠萝PPAP河南话版</a>。也可以换成任何宇宙上有的物体。然而不仅仅是物体，甚至可以是一个抽象的概念。我个人最喜欢的描述是：向量空间是描述状态(state)的线性空间。再加上之前的约束，于是我们就有了</p>
<blockquote>
<p>向量空间是能够容纳所有线性组合的状态空间</p>
</blockquote>
<p>那什么样的空间（所有状态的集合）能够容纳所有的线性组合？<br>如果说，我现在想要描述的你的两个状态（下图中的行向位置，和纵向位置），向量的维度就是二维。那么一个大圆盘够不够容纳所有的线性组合？答案是不够。<br><img src="https://picb.zhimg.com/80/v2-0bb7c531c8d518aa4af78f90752c3ee6_720w.jpg" alt></p>
<p>因为线性组合是一组向量乘上各自对应的一个标量后再相加所形成的组合，而这个标量是实数域的时候，由于实数域无线延伸，那么乘以标量后的状态也会无限延伸。所以向量空间一定是各个维度都像实数轴一样可以无线延伸。最终你得到的将不会是一维下的线段，二维下的圆盘。而一定是一维下的无限延伸的直线，二维下的无限延伸的平面。<br>向量空间的基本特点是各个维度都可以无限延伸。<br>我之所以用状态二字，是因为刚才的两个维度，我可以用于描述你的速度和体温。这时，这两个维度所展开的依然是一个平面，但却又不是描述位置的平面。</p>
<p>子空间</p>
<p>子空间（subspace）可以被想成是向量空间内的空间，同样要满足能够容纳线性组合的条件<br>那么最小的子空间是什么？只有一个状态的空间（集合）。而这个状态不是其他状态，就是0。只有这样才可以在乘以完一个标量后依然不会跑出空间外部。（因为跑出去了，我们就不得不扩大空间来容纳它）。其次空集可不可以是向量空间？不可以，空集是没有任何元素的集合，既然什么状态都没有，又怎么能够容纳线性组合。</p>
<blockquote>
<p>最小的向量空间是只包含零向量的空间</p>
</blockquote>
<p>假如上图的圆盘是一个无线延伸的平面，那么这个平面的子空间就是那个平面上所有直线吗？不是，8个运算规则中明确规定了，一定要有原点，这样才可以包含正负。所以这个平面的子空间是所有过原点的直线，并且包括中心的那个原点自己所组成的最小子空间，同时也包括这个平面自身（最大的子空间）</p>
<p>线性无关</p>
<p>s你会发现，在怪蜀黍的例子中，当要把可以把（eq.1）（eq.2）合二为一表示为（eq.4）时，是这个样子：</p>
<p>$\left [ \begin{array}{c} applepen \\ pineapplepen \end{array} \right] = \left [ \begin{array}{ccc} 1&amp;0&amp;1 \\ 0&amp;1&amp;1 \end{array} \right ]· \left [<br>    \begin{array}{c} apple \\ pineapple \\ pen \end{array} \right] $（eq.4）</p>
<p>eq.4）最右侧的向量并不是$\left[ \begin{array}{c} apple\\pen\\pineapple\\pen \end{array} \right]$4个维度。而是三个。因为pen 和pen是一个东西。我们想用的是若干个毫不相关的因素去描述状态。这里的毫不相关是在线性空间下的毫不相关，所以叫做线性无关。那么当我们要描述的状态是由向量来描述时怎么办？我们知道判断两个向量是否线性无关是，可以看他是否在空间下平行。但怎么判断几个向量之间（不一定是两个）是否线性无关？我们需要可靠的依据。这也是数学为什么要证明，它要让使用者知道某个性质在什么条件下适用，什么条件下又不适用。</p>
<blockquote>
<p>线性无关（linearly independent）: 当$c_i$表示权重，$v_i$表示向量时，<br>$c_1v_1+c_2v_2+…+c_kv_k=0$只发生在当 $c_1=c_2=…c_k=0$全都等于零时。<br>换句话说，这些向量不可以通过线性组合形成彼此。形成彼此的情况只能是他们都是零向量。</p>
</blockquote>
<p>张成</p>
<p>明白了线性无关后，张成（spanning）就十分容易了，接下来要注意的是词的属性和关联词。<br>张成（spanning）是一个动词，而动词的主语是一组向量（a set of vectors）。描述的是一组向量通过线性组合所能形成子空间。是个动词，描述的内容并不是形成的这个空间，而是形成的这个行为。</p>
<p>$\left[ \begin{array}{c} apple\\pen\\pineapple\\pen \end{array} \right]$，就可以看成是4个向量，这4个向量，可以张成一个三维空间。（因为有两维线性相关，所以并不能张成4维）</p>
<p>基（基底）</p>
<p>基底也是建立在张成的基础上理解的。</p>
<blockquote>
<p>一个向量空间的一个基底（A basis for a vector space V）是一串有顺序的向量（a sequence of vectors），满足：<br>A、向量之间彼此线性无关 （不可多余）<br>B、这些向量可以张成向量空间V （不可过少）<br>换句话说，刚刚好可以张成向量空间V的一串向量是该向量空间V的一个基底</p>
</blockquote>
<p>基底是一个类似people的复数名词，是从属于某个空间的，而不是矩阵，也不是向量。</p>
<p>维度</p>
<p>一个向量空间可以有无数个基底。但每个基底所包含的向量的个数（the number of vectors in every basis）是一个空间的维度。注意，维度是空间的概念，而不是描述一个具体的向量。人们常说的n维向量实际是指n维向量空间内的向量，由于在讨论时并未给向量指定任何实际的数值，所以可以是任何值，可以张成整个空间。所以其真正描述的依旧是一个空间。并且，选择的维度是一个站在观察者角度，希望在某个向量空间下可以尽可能的描述一个物体的状态而选择的，并不一定是被描述者真实处在的空间。数学就是这么“拐外抹角”的去描述一个概念，不过确实非常有必要。但若是你觉得理解起来有困难。就简单记住：</p>
<blockquote>
<p>互不相关的因素的个数是一个向量空间的维度。</p>
</blockquote>
<p>秩</p>
<p>秩（rank）是矩阵的概念。指的是一个矩阵的所有列向量所能张成的空间的维度。</p>
<blockquote>
<p>矩阵的所有列向量所张成的空间叫做列空间（column space）<br>矩阵的所有行向量所张成的空间叫做行空间（row space）<br>一个矩阵的列空间的维度是这个矩阵的秩，同时也等于该矩阵行空间的维度<br>秩是用于描述矩阵的包含的信息的<br>转置一个矩阵可以理解为调换一个矩阵的行空间与列空间。<br>单位矩阵可以被理解为行空间与列空间相同。</p>
</blockquote>
<p>线性变换</p>
<p>线性变换（linear transformation）可以说是最最重要的概念了。你可以忘记我上面描述的所有内容，但不可以不深刻理解线性变换。下面是关于什么叫变换。由于概念很重要，我先不用逗比例子来解释。而用比较抽象的描述。<br><img src="https://pic3.zhimg.com/80/v2-265f8d8b33abf1659a10ec3d23e97ff1_720w.jpg" alt><br>一个从n维实数域（$R^n$）到m维实数域（$R^m$）的变换（transformation or mapping or function）T是将n维实数域（$R^n$）空间下任意一个向量x转换成为在m维实数域（$R^m$）空间下对应向量T(x)<br>其中n维实数域（$R^m$）空间叫做变换T的domain，m维实数域（$R^m$）的空间叫做该变换的codomain。<br>向量T(x)叫做向量x的image（变换T行为下的）<br>所有image组成的集合叫做变换T的range</p>
<p>而线性变换是是指线性规则所造成的变换，T()是由一个矩阵A来实现的。此时你就会看到无处不在的式子：</p>
<p>y=Ax ：列向量x左乘一个矩阵A后得到列向量y</p>
<p>$\left [ \begin{array}{c} applepen \\ pineapplepen \end{array} \right] = \left [ \begin{array}{ccc} 1&amp;0&amp;1 \\ 0&amp;1&amp;1 \end{array} \right ]· \left [<br>    \begin{array}{c} apple \\ pineapple \\ pen \end{array} \right] $（eq.4）举例来说，<br>x是三维空间的向量（即A的domain是三维），而经过线性变换后，变成了二维空间的向量A（即A的codomain是二维）。</p>
<blockquote>
<p>矩阵A可以被理解成一个函数(function)，将三维空间下的每个向量投到二维空间下。<br>y=Ax也可以理解为x经由一个动因A，使其状态发生了改变。<br>Ax同时也是深层神经网络每层变换中的核心：y=a(Ax+b)</p>
</blockquote>
<p>在机器学习中你会你会需要构架一个虚拟的世界，并选择合适的、用于描述某个事物状态的各种因素。</p>
<blockquote>
<p>线性代数是有关如何构架“世界”的学问。矩阵又是存储着所架构的世界的信息的媒介。</p>
</blockquote>
<p>举一个小小的例子，比如你想通过温度，气候，湿度，当天时间，海拔，经度，纬度等信息来描述天气状况，从而进行预测是否会下雨。你如何合理的选择这些信息？你如何知道这些信息，海拔和气候如是否相关，是否重复？如果重复，那么你又是否可以减少某个信息？判断的准则又是什么？</p>
<p>数学讲的是我刚才所描述的内容的纯粹的结构关系。请你忘记我给你举得怪蜀黍例子，抓住“逻辑框架”。当你可以把这种关系应用在任何符合该结构关系的现实现象中时，你就算是精通了如何应用数学。</p>
<p>线性代数的内容十分庞大，行列式，特征向量，奇异值分解等你也会经常用到。然而我的描述就到此为止，我无法涵盖所有内容。写这篇文章只是希望能够用你脑中已有的概念帮助你构建一个对线性代数模糊的认识。当你今后用到线性代数时，再不断的加深和更正此刻的理解。</p>
<h1 id="概率simple入门"><a href="#概率simple入门" class="headerlink" title="概率simple入门"></a><span id="header3">概率simple入门</span></h1><p>什么是概率？<br>通过线性代数，我们知道了该如何描述事物状态及其变化。遗憾的是，对一个微小的生物而言，世界并非确定性（deterministic）的，由于信息量的限制，很多事物是无法确定其变化后会到达哪种状态。然而为了更好的生存，预测未来状态以决定下一刻的行为至关重要。而概率给我们的决策提供了依据。</p>
<blockquote>
<p>概率是用来衡量我们对事物在变化到不同状态的确信度。</p>
</blockquote>
<p><img src="https://pic3.zhimg.com/v2-82dd0737ac79a63d949e7c8ad1239ba3_1440w.jpg?source=172ae18b" alt></p>
<p>该篇内容是Joseph K. Blitzstein的<a href="https://link.zhihu.com/?target=http%3A//projects.iq.harvard.edu/stat110/about">《Introduction to Probability》</a>中的第一章，该概率书非常适合入门。文章是加入自己理解后的总结。以服务于机器学习的理解视角切入。</p>
<p>通过线性代数，我们知道了该如何描述事物状态及其变化。遗憾的是，对一个微小的生物而言，世界并非确定性（nondeterministic）的，由于感知限制，很多事物是无法确定其状态的。然而为了更好的生存，预测未来状态以决定下一刻的行为至关重要。而概率给我们的决策提供了依据。</p>
<p>一、什么是概率？</p>
<blockquote>
<p>概率是我们对事件处于哪个状态的确信度。</p>
</blockquote>
<p>情景：如何考虑转盘在未来停止后指针指向各个数字的可能性？为方便研究，需要总结出在任何情况都普遍适用的属性，并给予它们固定的名字。<br>1,2,3是可能被指到的三个结果（outcome）。在这里，这三个结果组成的集合也同时是样本空间（sample space），即无论事态如何发展，结果都不会出现在该集合之外（和向量空间一样）。样本空间的子集，如{1,2}叫做一个事件（event），表示指针指到1或2的情况。满足任何一个情况都算作该事件发生了（occurred）。所有事件发生的可能性都用值域为[0,1]间的实数表示，1表示必然发生，0表示不可能发生。{1}, {2,3}两个不相交的事件的概率和为1。[0,1]间的实数是概率得出的值，但并非概率的全部。概率是一个函数。</p>
<p><img src="https://picb.zhimg.com/80/v2-746ff9fde965cb61f90d83e712ba4c67_720w.jpg" alt></p>
<blockquote>
<p>概率：概率是将样本空间内的子集投向概率空间的函数。<br>概率P()将事件$A \subset S$作为输入，并输出[0,1]之间的实数表示其发生的可能性。该函数需要满足两个条件：<br>1.$ P(0)=0,P(S)=1 $，空集的概率为0，全集的概率为1。<br>2.$P(\bigcup_{j=1}^{\infty} A_j)= \sum_{j=1}^{\infty} P(A_j)$不相交事件之间的并集事件的概率等于各个事件概率之和。<br>结果：可能到达的状态<br>样本空间：所有可能发生的结果所组成的集合。<br>事件：样本空间的子集。</p>
</blockquote>
<p>当实际发生的结果$S_{outcome} \subset A$时，表示A事件发生。</p>
<p>二、朴素概率的计算以及和普遍概率的区别是什么？</p>
<p>人们在计算概率时常常犯的错误就是不假思索的假定所有结果所发生的可能性都相同。并用事件的结果个数比上样本空间的结果个数。<br>朴素概率：$P_{native}A=|A|/|S|$，|A|和|S|表示集合中元素的个数。<br>但是这种假设并不严谨。</p>
<p>实例：在上图原盘问题中，如果使用朴素概率来计算指针停止时指向2的概率，就会得到$P_{native}A=|A|/|S|=1/3$的概率。但很明显，指向3的结果就占有原盘一半的空间，指向3的概率更大。使得各个结果发生的可能性并不相同。不可以使用朴素概率算法。从图中可以看出答案是1/4。</p>
<p>样本空间好比是总价为1的一筐苹果，一个事件就是一堆苹果，概率是将这堆苹果转换成实际价钱的函数。但苹果有大有小，只有当所有苹果都一模一样时，这堆苹果的价钱才是 苹果数/总个数。空集，即一个苹果都没有的话，价格为0。整框苹果的话，价格自然为1。把整框苹果分成几堆（事件之间不相交），价格的总和为1。<br><img src="https://pic1.zhimg.com/80/v2-c61d2008f6fbdb7f298d1d3ad16c8bae_720w.jpg" alt></p>
<p>条件概率<br>当我们获得更多信息后，新信息会对原始样本空间产生更新。</p>
<p>三、条件概率又是什么？</p>
<p>条件概率是新信息对样本空间进行调整后的概率情况。<br>实例：从一副洗好的扑克里，不放回的依次抽两张卡片。事件A表示第一张卡片是心，事件B表示第二张卡片是红色。求事件B发生的条件下，事件A发生的概率P(A|B)。以及事件A发生的条件下，事件B发生的概率P(B|A)。</p>
<p>卡片都是均匀形状，可用朴素概率计算。最初的样本空间是 54∗53=2862 种。事件B发生后，样本空间被调整，所有第二张不是红色的结果都会从样本空间内去掉，变成 26∗53=1378种（可认为第二张先抓，顺序不影响组合结果）。其中第一张是心，且第二张是红色的结果有13∗25=325种。所以P(A|B)的概率为 325/1378≈0.236。</p>
<p>事件A发生后，所有第一张不是心的结果都会从样本空间内去掉，变成13∗53=689种。其中第一张是心，且第二张是红色的结果有 13∗25=325种。所以P(B|A)的概率为325/689≈0.472。</p>
<p>P(A|B)和P(B|A)二者的条件对原始样本空间的调整不同，所以并不相等。同时“|”右边的事件并不意味着先发生，也并不意味着是左边事件的起因。</p>
<p>实例：先后投两次硬币。原始样本空间是{正正，反反，正反，反正}。已知事件A是第一次投得正面，事件B是第二次投得正面。P(B|A)更新后的样本空间为{正正，正反}。但第二次投得正面的概率仍然是1/2。事件A和事件B彼此没有影响，叫做两个事件独立。</p>
<blockquote>
<p>条件概率：$P(A|B)=P(A \bigcap B)/P(B)$<br>P(A|B)表示B事件条件下，A发生的条件概率。<br>P(A)叫做先验概率（prior probability），即事态未更新时，A事件的概率。<br>P(A|B)也叫做后验概率（posterior probability），即事态更新后，A事件的概率。<br>$P(A \bigcap B)$是B发生后A的事件集合，而除以P(B)是在该基础上，将样本空间的总概率重新调整为1。<br>当事件A与B为独立事件时，其中一个事件的发生并不会对另一个事件的样本空间产生影响。即P(A|B)=P(A)，P(B|A)=P(B)。</p>
</blockquote>
<p>贝叶斯公式<br>人们经常将P(A|B)和P(B|A)搞混，把二者搞混的现象叫做检察官谬误（prosecutor’s fallacy）。</p>
<p>四、P(A|B)和P(B|A)两者之间的关系是什么？<br>实例：某机器对在所有人口中得病率为1%的癌症识别率为95%（有病的人被测出患病的概率和没病的人被测出健康的概率）。一个被测得有病的人真实患癌症的概率是多少？<br>得出答案是95%的人就是搞混了P(A|B)和P(B|A)。正确答案约等于16%。拿10000个人来思考。<br>真正的样本空间是由测得有病的癌症患者和测得有病的正常人组成，所以答案是95/(95+495)≈16%。</p>
<p>我们知道条件概率是新信息对样本空间进行调整后的概率情况，所以检察官谬误实际上是样本空间的更新产生了差错。不过我们可以从条件概率中寻找关系：通过变形条件概率的定义，就可以得出著名的贝叶斯公式和全概率公式。</p>
<blockquote>
<p>贝叶斯公式（Bayes’ theorem）：$P(A|B)=P(B|A)P(A)/P(B)$<br>全概率公式（Law of total probability）：$P(B)=\sum_i^n P(B|A_i)P(A_i)$<br>其中$A_i$是样本空间S的分割(partition)，即彼此不相交，并且组成的并集是样本空间。<br>如下图：<br><img src="https://pic3.zhimg.com/80/v2-4598c108df88f9f8119757eab0e318c8_720w.jpg" alt><br>用这两个公式，我们重新计算上面的癌症问题：</p>
</blockquote>
<p>例： 其中 P(A)是人口中患癌症的概率，为1%，P(B)是测得有病的概率。P(A|B)就是测得有病时，患癌症的概率。 P(B|A)是有患癌症时，测得有病的概率，为95%。P(B|AC)就是没病时却测得有癌症的概率，为5%。<br>想知道的是，当被测得有病时，真正患癌症的概率P(A|B)是多少。<br>由贝叶斯公式可以得到：$P(A|B) = P(B|A)P(A)/P(B)=0.95<em>0.01/P(B)$<br>由全概率公式可以得到：$P(B)=P(B|A)P(A)+P(B|A^C)P(A^C)$<br>全部代入就得到：$ 0.95</em>0.01/(0/95<em>0.01+0.05</em>0.99)\approx 16$%</p>
<p>这两个公式在机器学习中非常重要。贝叶斯公式告诉了我们P(A|B)和P(B|A)两者之间的关系。很多时候，我们难以得出其中一个的时候，可以改求另一个。</p>
<p>实例：语音识别中，听到某串声音的条件O下，该声音是某段语音[公式]的条件概率最大的arg maxP(s|o)为识别结果。然而P(s|o)并不好求。所以改求p(s|o)=P(o|s)P(s)/P(o)。P(o)对比较同一个P(s|o)时并没有影响，因为大家都有，则不需要考虑。剩下的P(o|s)叫做声学模型，描述该段语音会发出什么样的声音。而P(s)叫做语言模型，包含着语法规则信息。</p>
<p>而全概率公式又是连接条件概率与非条件概率的桥梁。</p>
<blockquote>
<p>全概率公式可以将非条件概率，分成若干块条件概率来计算。</p>
</blockquote>
<p>实例：三门问题。三扇门中有一扇门后是汽车，其余是羊。参赛者会先被要求选择一扇门。这时主持人会打开后面是羊的一扇门，并给参赛者换到另一扇门的机会。问题是参赛者该不该换？ 应该换门。换门后获得汽车的概率为2/3，不换门的概率为1/3。<br>用全概率公式来思考该问题就可以将问题拆分成若干个相对简单的条件概率。<br>实例：三门问题。三扇门中有一扇门后是汽车，其余是羊。参赛者会先被要求选择一扇门。这时主持人会打开后面是羊的一扇门，并给参赛者换到另一扇门的机会。问题是参赛者该不该换？ 应该换门。换门后获得汽车的概率为2/3，不换门的概率为1/3。</p>
<p>用全概率公式来思考该问题就可以将问题拆分成若干个相对简单的条件概率。<br>P(getcar)获得汽车的概率可以用拆分成选择各个门可得汽车的概率。$P(D_1)$为车在第一扇门的概率。<br>$P(getcar)=P(getcar|D_1)P(D_1)+P(getcar|D_2)P(D_2)+P(getcar|D_3)P(D_3)$<br>$P(getcar)=P(getcar|D_1)<em>1/3+P(getcar|D_2)</em>1/3+P(getcar|D_3)<em>1/3$<br>如果不换门，得车的概率就是$P(D_1)$，即1/3.<br>若换门。当车在第一扇门后时，$P(getcar|D_1)</em>1/3$由于换门的选择而变成了0。<br>但当车在第二或第三扇门后时，由于主持人去掉了一扇后面为羊的门，换门的选择会100%得到车。<br>所以，$P(getcar)=0<em>1/3+1</em>1/3+1*1/3=2/3$</p>
<p>随机变量<br>五、是否有更好的方式表达事件？</p>
<p>随机变量是一种非常方便的事件表达方式。虽然它的名字叫做随机变量，但它实际上是一个函数。 我们在“什么是概率”的例子中已经应用了随机变量的概念。我们用数字去表达事件。比较一下不用随机变量的方式。</p>
<p>实例：我们用文字去表达事件和概率。样本空间 $\Omega$ = { 橘黄色，绿色，蓝色 }。<br>情况1：若仅仅是问转盘停止后指针指到某个颜色的概率还可以接受。如P(指到橘黄色)。<br>情况2：如果是奖励游戏，转到橘黄、绿、蓝色分别奖励1、2、3元。转3次后，想知道奖励了多少钱的概率。3元的我们要写一次描述，4元的也要写一次描述。十分笨拙。如果想问的是美元呢？我们又没办法用事件去乘以汇率。</p>
<p>然而如果用随机变量，就变得非常方便。设$X_r$表示转r次后一共奖励了多少人民币。 c是人民币对美元汇率的话，c·$X_r$就表示表示转r次后一共奖励了多少美元。$X_{r+1}-X(r)$就表示了下一局赢得了多少人民币。</p>
<blockquote>
<p>随机变量：给定一个样本空间 $\Omega$一个随机变量(r.v.)是将样本空间投射到实数域的函数。</p>
</blockquote>
<p>一个样本空间可以有很多个随机变量。在最初的例子，我们就已经将样本空间$\Omega$={橘黄色，绿色，蓝色}对应到了实数域中的1,2,3。<br><img src="https://pic1.zhimg.com/80/v2-f328f131d915bd589d9c195bee4a3dc2_720w.jpg" alt></p>
<p>随机变量作为函数而言是确定的。输入事件橘黄色，一定会得到1这个输出，函数本身并没有什么“随机”。“随机”是由于函数的输入的发生概率。</p>
<p>X=3表达的是指针指到蓝色的事件。P(X=3)表达指针指到蓝色的事件的概率。</p>
<p>随机变量是认为事先选择的，非常灵活，好的随机变量会使问题简化许多。</p>
<p>根据随机变量投射后的值域是离散还是连续，随机变量可以分为离散随机变量和连续随机变量。</p>
<p>分布<br>随机变量中的“随机”来自事件发生的概率。分布（distribution）是描述随机变量所对应的所有事件的发生概率的情况。</p>
<p>实例：上例随机变量$X_1$（转1次奖励人民币数）的分布情况用概率质量函数（probability mass function，简写为PMF）表示就是：<br><img src="https://pic2.zhimg.com/80/v2-8d4508f43698f933a1c54f0347c1999d_720w.jpg" alt></p>
<p>概率五要件<br>样本空间：所有可能结果组成的集合。<br>随机变量：将事件投向实数的函数。用数字代表事件。<br>事件：样本空间的子集。<br>概率：将事件投向[公式]实数域的函数。用实数表示确信度。<br>分布：随机变量的取值情况。</p>
<p><img src="https://pic2.zhimg.com/80/v2-c4bf85890918ede7952697c4d5e88618_720w.jpg" alt></p>
<p>注意在应用中区分物理意义与数学定义。如随机变量虽然是以事件为输入，实数为输出。但是在用于表达概率P(X=3)是用3这个数字去表示事件，并得出该事件的概率，并不是将实数作为输入。又如概率的数学定义是事件投射到[0,1]的实数上，但在物理意义中，是样本空间的内在情况决定了事件。上图中：</p>
<p>蓝线：表示人们为了描述物理现象而定义的数学函数。箭头由输入空间指向输出空间。<br>概率函数：输入为事件，输出为[0,1]实数<br>随机变量函数：输入为事件，输出为实数（但使用时，用实数代表事件）<br>概率质量函数：输入为实数，输出为[0,1]实数</p>
<p>红线：表示真实的物理现象。箭头由因指向果。<br>由确信度所反映的内在分布情况决定了事件的发生。<br>事件的发生决定了随机变量的输出值。</p>
<h1 id="很多人都不知道自动化与机器学习的区别"><a href="#很多人都不知道自动化与机器学习的区别" class="headerlink" title="很多人都不知道自动化与机器学习的区别"></a><span id="header4">很多人都不知道自动化与机器学习的区别</span></h1><p>目录</p>
<ul>
<li>集合、变量、函数</li>
<li>自动化与机器学习的区别</li>
</ul>
<p>正文<br>这篇文章其实是给文科生补三个数学概念的。</p>
<p>一、集合（一类）、变量（任意）、函数（知识）</p>
<p>可能不少人有一种误解，认为输入和输出是一个具体的情况。又怎么能说知识在压缩信息呢？ 然而输入和输出的可能情况并非只有一个，往往是无数个。</p>
<p>例1：没有两片树叶是一模一样的，但我们却可以认识所有的树叶。<br><img src="https://pic4.zhimg.com/80/v2-c7f11100548239eb1228b3386bb32b48_720w.jpg" alt></p>
<p>例2：小猫的长相都不相同，也形态各异，但我们却可以认识所有的猫。<br><img src="https://picb.zhimg.com/80/v2-30bf9b80852d026da71460ee2d779486_720w.jpg" alt></p>
<p>例3：每次炒菜时的所用的食材量，火候，调味料也都千差万别，但我们却可以对应的进行调整，做出叫同个菜名的食物。</p>
<p>你可以感觉出这里想要描述的是一类事物，每一次的输入可以是这一类事物中的任意一种情况。我们的知识可以应对所有输入而得到对应的输出。</p>
<p>那么该如何描述这些概念呢？因为如果在讨论一个问题时没有办法准确描述所指的事物到底是什么，那就根本没有办法开展和交流。 这些看似微不足道的概念其实直到 19 世纪才第一次正式创立。而这个奠定了整个现代数学，乃至所有科学根基的工具就是集合。</p>
<p>若把所有的树叶（元素）归到一个集合中，用这个集合来表示一类事物，输入是这一类事物中的任意一个。也正是由于这种任意性，输入也被称为变量。输出同理也是变量。</p>
<p>我们在讨论输入和输出时，并不是说隔壁老王家那只叫翠花的二哈，而是说所有的哈士奇。<br><img src="https://picb.zhimg.com/80/v2-7610bd6fb437760a76b443fcad4a977b_720w.jpg" alt></p>
<p>但其我们早就掌握了这种概念，只是当初并未正式的总结。<a href="https://www.bilibili.com/video/av32026984" target="_blank" rel="noopener">《超智能体》02</a> 的开篇里提到的「智人为什么会从众多生物中脱颖而出的原因就是在于智人的语言出现了变量与函数的概念」。</p>
<p>例1：英语中的 the apple 指的是特定的一个苹果，是一个常量。而 an apple 指的却是任意一个苹果，也就是变量。</p>
<p>例2：中文里我们也会用“这个”和“那个”来特指某个事物，而没有这些特指时，我们往往是在讨论变量。</p>
<p>例3：“人啊，还是要看命”句话里的人就是变量。 这句话甚至包含了一种“知识”，其预测就是所有人都要认命。虽然这个“知识”不合理。但你可以感觉到它的作用。中医、玄学、科学也都在提取知识，只是科学是当中最可靠的一种提取知识的方法。</p>
<p>这种概念的产生让我们能够从经验中提取知识，并一代一代的传递下去。</p>
<p>二、自动化与当代 AI 的区别</p>
<p>如果把每个图像和这个图像是否是树叶记录下来，哪怕是最快的计算机也无法查找和存储这些多的信息。这恰恰是当初计算机所办不到的事情，没有办法仅通过演示几个例子就能让计算机搞清楚其他没有演示的情况，也就是学习能力。</p>
<p>曾经计算机所执行的指令都是人类所学到的知识。如今的人工智能所产生的突破并非有了意识，而是能够让计算机自己来从有限的例子中学到知识，然后将学到的知识用于今后的预测中。</p>
<p>这也是自动化与目前AI最大的区别，即知识是否是由机器自己发现的，这也正是很多张口闭口都是AI的人压根就没搞明白的事情。现在你再来看这个视频时，恐怕会有新的理解：</p>
<p>有了集合、变量、函数的概念后，下一篇我们再来谈知识的第二种分类：以任务类型为视角。</p>
<h1 id="机器学习理论引入的知识分类"><a href="#机器学习理论引入的知识分类" class="headerlink" title="机器学习理论引入的知识分类"></a><span id="header5">机器学习理论引入的知识分类</span></h1><p>前言<br>这种分类完全是从机器学习理论中引入到日常学习中的。明白了这种分类后，就可以轻松理解<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIxNDI5MDk0MQ%3D%3D%26mid%3D2247483892%26idx%3D1%26sn%3Dbd451e1b54871bf10e45b79fcea930ef%26chksm%3D97a89966a0df107078f7602f9e4b5fe5f39b92dfecd1fa6a4fd6cff4fc7768f173b9125c9ab3%26scene%3D21%23wechat_redirect">《学习观》05</a>中提到的两个概念了。</p>
<p>目录</p>
<ul>
<li>分类</li>
<li>回归</li>
<li>数学的特别</li>
</ul>
<p>正文<br>若以任务类型为视角，则知识可划分为“分类（classification）”与 “回归 （regression）”。</p>
<p>一、君子和而不同，小人同而不和</p>
<p>分类知识是最常用的。它们是判断一个事物属于哪个类型，也出现在各式各样的决策中。</p>
<p>例1：判断一个数字是偶数还是奇数（二类）</p>
<ul>
<li>输入：任意数字</li>
<li>输出：是否为偶数</li>
</ul>
<p>例2：判断一个行为是不是爱情（二类）</p>
<ul>
<li>输入：任意事件</li>
<li>输出：是否为爱情</li>
</ul>
<p>例3：从外表判断一个人的年龄段（三类）</p>
<ul>
<li>输入：某人外表</li>
<li>输出：少年或青年或老年</li>
</ul>
<p>例4：判断一个生物属于植物、动物、昆虫、微生物等（超过三类）</p>
<ul>
<li>输入：某生物的特征</li>
<li>输出：哪种生物类别</li>
</ul>
<p>例5：判断一个发音属于哪个单词（数千类）</p>
<ul>
<li>输入：某段发音</li>
<li>输出：哪个单词</li>
</ul>
<p>例6：决定是否与某人结婚</p>
<ul>
<li>输入：相处时观察到的言行与家庭等综合因素</li>
<li>输出：结婚与否</li>
</ul>
<p>例7：决定是否买车</p>
<ul>
<li>输入：个人与环境等综合因素</li>
<li>输出：是否买车</li>
</ul>
<p>在没有计算机扩展我们自身能力之前，思考类知识中大部分都是分类知识。在中国古代的著作里，如《论语》、《孟子》等留下来的知识也都是分类知识。「君子和而不同，小人同而不和」可用于判断君子和小人。</p>
<p>分类知识可以说是最重要，可往往也是数学中最容易被轻视的知识。因为应用任何知识之前，都是先用分类知识来判断问题属于哪一类，然后才能够应用公式和性质来解决。由于很多学生缺少这类知识的训练，造成他们只会做逻辑题，却难以解决应用题，更无法用数学知识解决生活问题。让学生误以为数学只是一种智力游戏。</p>
<p>很多题解不出来是因为学生根本无法判断某个问题属于哪一类，连用公式和性质的机会都没有。遇到这种情况时，很多家长和老师都简单的归因为“不熟”，提升方式也基本靠悟。但是什么叫“不熟”？这种“不熟”又该如何提升。</p>
<p>很多人往往是工作了以后才提升了该能力，因为他们遇到了很多实际例子，基本等于重学了一遍。不觉得很奇怪吗？本该在学校学习的东西反而不得不在工作中才真正学会。可这并非没有办法的事情，因为只要在学生阶段针对性的用实际例子来训练这类知识，就不必在工作中来重新学习了。</p>
<p>比如学习三角函数时，第一个要学习的知识不是三角函数的公式，而是要学会判断哪些东西可被视为三角形的各个角和边。世界上没有“三角形”这种东西，是人们观察了很多个实例，总结共性后所抽象出来的知识。在学习时也需要通过很多个实例才能将这种知识迁移到学生的脑中。只有当学会了判断它后，才能够将三角函数的知识应用于机器人的控制，飞机的导航，傅里叶变换，周期性动画的制作等。</p>
<p>而在画思维导图时，这类知识对应的关键词一般是主谓结构。你会自我提问“它是什么”来明确输入输出，问“为什么是”来决定判断的边界（依据）。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f1002fbea2dd7fe0855195a711bdd025_720w.jpg" alt></p>
<p>一个事物（输入）都有哪些类（输出）</p>
<p>例1：比如知识的分类（上）里的大脑模式视角这个关键词（输入）是主语，系动词被思维导图的连线代替了，谓语（输出）拥有两类：</p>
<ul>
<li>输入：大脑模式视角</li>
<li>输出：思考类或运动类</li>
<li>边界：是否依靠意识</li>
</ul>
<p>一个知识（输入）都有子知识（输出）</p>
<p>例2：思考类与运动类的速度特点这个关键词这个关键词（输入）是主语，谓语（输出）拥有4个子知识（由你自己总结）：</p>
<ul>
<li>输入：特点</li>
<li>输出：速度、精度、因素量、并行</li>
</ul>
<p>二、从定性到定量</p>
<p>另一种只是不再是判断类别，而涉及如何从一种状态变成另一种状态。大都数的运动类都是回归知识。一个问题既可以被当作回归来处理（定量），也可以当作分类来处理（定性）。 在判断完问题属于哪一类后，可精准预测的定量的知识就更有价值。</p>
<p>例1：走路</p>
<ul>
<li>输入：环境</li>
<li>输出：大脑送给肌肉的信号</li>
</ul>
<p>例2：炒菜的放盐量</p>
<ul>
<li>输入：食材数量</li>
<li>输出：该放多少盐</li>
</ul>
<p>例3：从外表判断一个人的实际年龄（分类时是判断年龄段）</p>
<ul>
<li>输入：某人外表</li>
<li>输出：年龄</li>
</ul>
<p>例4：射击游戏的鼠标移动</p>
<ul>
<li>输入：游戏画面情况</li>
<li>输出：手臂肌肉移动</li>
</ul>
<p>三、数学的特别</p>
<p>想特别说明的就是数学的知识，所有的数学的公式都是别人总结好的“知识的描述”，是纯粹的关系，而且是将同一类知识进行二次提取。比如 y=ax+b 这种关系可以表示所有符合线性关系的知识。</p>
<p>例1：西瓜斤数与总价的关系</p>
<ul>
<li>输入：斤数</li>
<li>输出：总价</li>
</ul>
<p>例2：光的传播时间与位移</p>
<ul>
<li>输入：时间</li>
<li>输出：位移</li>
</ul>
<p>例3：超过3公里时北京市出租汽的行驶距离与价格</p>
<ul>
<li>输入：距离</li>
<li>输出：价格</li>
</ul>
<p>当作为二阶知识时，线性关系这个分类知识的：</p>
<ul>
<li>输入：某个知识</li>
<li>输出：是否为线性</li>
</ul>
<p>这里我将问题留个读者：为什么大部分人都难以学好数学？数学明明被用于所有科学的现实问题，可为什么大部分人都觉得自己学不会。一遍一遍的记住了数学公式，甚至理清了这些公式是怎么来的，但在现实问题面前全面崩溃。</p>
<p>在画思维导图时，回归知识对应的关键词一般是动宾结构。你会自我提问“它的目的”来明确输入变成什么样的输出，问“如何达到”来明确具体的步骤。</p>
<p><img src="https://pic1.zhimg.com/80/v2-b4df6267baa84a74f9a919d1b34448a9_720w.jpg" alt></p>
<p>例1：比如<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIxNDI5MDk0MQ%3D%3D%26mid%3D2247483892%26idx%3D1%26sn%3Dbd451e1b54871bf10e45b79fcea930ef%26chksm%3D97a89966a0df107078f7602f9e4b5fe5f39b92dfecd1fa6a4fd6cff4fc7768f173b9125c9ab3%26scene%3D21%23wechat_redirect">《学习观》05</a>里的拆分知识这个关键词的“拆分”是动词（函数），“知识”是宾语（输出）：</p>
<p>输入：要被拆分的复合知识<br>输出：众多子知识<br>函数：“拆分”这个动作行为<br>​</p>
<p>明白了这两种知识分类之后，请再看一遍 <a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIxNDI5MDk0MQ%3D%3D%26mid%3D2247483892%26idx%3D1%26sn%3Dbd451e1b54871bf10e45b79fcea930ef%26chksm%3D97a89966a0df107078f7602f9e4b5fe5f39b92dfecd1fa6a4fd6cff4fc7768f173b9125c9ab3%26scene%3D21%23wechat_redirect">《学习观》05</a> 和<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIxNDI5MDk0MQ%3D%3D%26mid%3D2247483899%26idx%3D1%26sn%3D07994dbdaec912616b07832972db94bf%26chksm%3D97a89969a0df107f0ab791abdf6b8bb6aeef77bfcc55b1ef397d6655eb00161c03089c8010d5%26scene%3D21%23wechat_redirect">《学习观》5.5</a>，希望你可以有新的理解。</p>
<h1 id="英语总结"><a href="#英语总结" class="headerlink" title="英语总结"></a><span id="header6">英语总结</span></h1><h2 id="英语学习关键点"><a href="#英语学习关键点" class="headerlink" title="英语学习关键点"></a>英语学习关键点</h2><p>发音：想摆脱口音，第一注重元音的发音。</p>
<p>元音：忘记中文的音，以每个音都是新音素去对待英语的音素。歌手唱歌时听不出口音是因为元音发的对。双元音ai、ei记得发到位，不要看做一个音，而是两个音圆滑的发出。<br>辅音：只要嘴型对，辅音的发音基本没问题。比如w是圆型口型，v是上齿触下唇。可快速发very well来体会不同。</p>
<h2 id="记音素要在单词中记忆"><a href="#记音素要在单词中记忆" class="headerlink" title="记音素要在单词中记忆"></a>记音素要在单词中记忆</h2><p>单词：记忆一定要有背景。<br>意思：新单词的意思理解要建立在已学英语单词的基础上，不要只看中文意思，要看英语解释。柯林斯英汉就很好。比较try和attempt：V-T/V-I If you try to do something, you want to do it, and you take action which you hope will help you to do it. ；V-T If you attempt to do something, especially something difficult, you try to do it. 试图 (尤指做困难的事)<br>记忆：音素放在单词中记忆，单词放在句子中记忆（最好可清晰展示用法的句子），句子放在段落中记忆。（学英语可以认为你就是在学英语句子）</p>
<p><img src="https://pic2.zhimg.com/80/v2-d544ab8761c043f3728bdf57b6b728ea_720w.jpg" alt><br><img src="https://pic2.zhimg.com/80/v2-491de634ad4b70b00dc0a3ebaa58d672_720w.jpg" alt><br><img src="https://pic1.zhimg.com/80/v2-92e1a99688d288711b704cb2f7fa1b67_720w.jpg" alt><br><img src="https://pic1.zhimg.com/80/v2-92e1a99688d288711b704cb2f7fa1b67_720w.jpg" alt><br><img src="https://pic2.zhimg.com/80/v2-fe46aca26f8e4625ea462c93fe6871b9_720w.jpg" alt></p>
<h1 id="深层学习为何要“Deep”"><a href="#深层学习为何要“Deep”" class="headerlink" title="深层学习为何要“Deep”"></a><span id="header7">深层学习为何要“Deep”</span></h1><p>一、基本变换：层<br>神经网络是由一层一层构建的，那么每层究竟在做什么？</p>
<p>数学式子：$\vec{y}=a(W\vec{x}+b)$，其中$\vec{x}$是输入向量，$\vec{y}$是输出向量，$\vec{b}$是偏移向量，W是权重矩阵，a()是激活函数。每一层仅仅是把输入$\vec{x}$经过如此简单的操作得到$\vec{y}$。<br>数学理解：通过如下5种对输入空间（输入向量的集合）的操作，完成 输入空间 —&gt; 输出空间 的变换 (矩阵的行空间到列空间)。<br>注：用“空间”二字的原因是被分类的并不是单个事物，而是一类事物。空间是指这类事物所有个体的集合。</p>
<ol>
<li>升维/降维</li>
<li>放大/缩小</li>
<li>旋转</li>
<li>平移</li>
<li>“弯曲”<br>这5种操作中，1,2,3的操作由$W\vec{x}$完成，4的操作是由$+\vec{b$完成，5的操作则是由a()来实现。</li>
</ol>
<p><img src="https://pic2.zhimg.com/v2-1ebee9a3fb36a6d1502d517b24bfb5c3_b.jpg" alt></p>
<p>物理理解：对 $W·\vec{x}$ 的理解就是通过组合形成新物质。$a()$又符合了我们所处的世界都是非线性的特点。<br>情景：$\vec{x}$是二维向量，维度是碳原子和氧原子的数量[C;O]，数值且定为[1;1]，若确定$\vec{y}$是三维向量，就会形成如下网络的形状 (神经网络的每个节点表示一个维度)。通过改变权重的值，可以获得若干个不同物质。右侧的节点数决定了想要获得多少种不同的新物质。（矩阵的行数）<br><img src="https://pic4.zhimg.com/80/v2-69d03cf2b3677ad7dc3b0d9af58841b4_720w.jpg" alt></p>
<ol>
<li>如果权重W的数值如（1），那么网络的输出 $\vec{y}$ 就会是三个新物质，[二氧化碳，臭氧，一氧化碳]。<br>$\left[ \begin{array}{c} CO_2\\O_3\\CO \end{array} \right]=$\left[ \begin{array}{cc} 1&amp;2\\0&amp;3\\1&amp;1 \end{array} \right]·\left[ \begin{array}{c} C\\O \end{array} \right]（1）</li>
<li>也可以减少右侧的一个节点，并改变权重W至（2），那么输出$\vec{y}$ 就会是两个新物质，[O_{0.3};CO_{1.5}]。<br>$\left[ \begin{array}{c} O_{0.3}\\CO_{1.5} \end{array} \right]=\left[ \begin{array}{cc} 0&amp;0.3\\1&amp;1.5 \end{array} \right]·\left[ \begin{array}{c} C\\O \end{array} \right]$（2）</li>
<li>如果希望通过层网络能够从[C, O]空间转变到[CO_2;O_3;CO]空间的话，那么网络的学习过程就是将W的数值变成尽可能接近(1)的过程 。如果再加一层，就是通过组合[CO_2;O_3;CO]这三种基础物质，形成若干更高层的物质。</li>
<li>重要的是这种组合思想，组合成的东西在神经网络中并不需要有物理意义。<blockquote>
<p>每层神经网络的物理理解：通过现有的不同物质的组合形成新物质。</p>
</blockquote>
</li>
</ol>
<p>二、理解视角：<br>现在我们知道了每一层的行为，但这种行为又是如何完成识别任务的呢？</p>
<p>数学视角：“线性可分”<br>*一维情景：以分类为例，当要分类正数、负数、零，三类的时候，一维空间的直线可以找到两个超平面（比当前空间低一维的子空间。当前空间是直线的话，超平面就是点）分割这三类。但面对像分类奇数和偶数无法找到可以区分它们的点的时候，我们借助 x % 2（取余）的转变，把x变换到另一个空间下来比较，从而分割。<br><img src="https://pic3.zhimg.com/80/v2-92ff4b847ac5fa41d91d1e76a910c483_720w.jpg" alt></p>
<ul>
<li>二维情景：平面的四个象限也是线性可分。但下图的红蓝两条线就无法找到一超平面去分割。<br><img src="https://picb.zhimg.com/80/v2-b1bd0f75b46ed27daf27910f2a6b6e3f_720w.jpg" alt><br>神经网络的解决方法依旧是转换到另外一个空间下，用的是所说的5种空间变换操作。比如下图就是经过放大、平移、旋转、扭曲原二维空间后，在三维空间下就可以成功找到一个超平面分割红蓝两线 (同SVM的思路一样)。<br><img src="https://pic4.zhimg.com/80/v2-8d7d1ef957ebbf8ba9bb9cf8ff2d87ff_720w.jpg" alt></li>
</ul>
<p>上面是一层神经网络可以做到的，如果把$\vec{y}$ 当做新的输入再次用这5种操作进行第二遍空间变换的话，网络也就变为了二层。最终输出是$\vec{y}=a_2(W_2·(a_1(W_1·\vec{x}+b_1))+b_2)$。</p>
<p>设想网络拥有很多层时，对原始输入空间的“扭曲力”会大幅增加，如下图，最终我们可以轻松找到一个超平面分割空间。<br><img src="https://picb.zhimg.com/v2-b7d47097d8f10e6baeb329e88e59b563_b.webp" alt></p>
<p>当然也有如下图失败的时候，关键在于“如何扭曲空间”。所谓监督学习就是给予神经网络网络大量的训练例子，让网络从训练例子中学会如何变换空间。每一层的权重W就控制着如何变换空间，我们最终需要的也就是训练好的神经网络的所有层的权重矩阵。</p>
<p>这里有非常棒的可视化空间变换<a href="https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" target="_blank" rel="noopener">demo</a>，一定要打开尝试并感受这种扭曲过程。更多内容请看<a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/" target="_blank" rel="noopener">Neural Networks, Manifolds, and Topology</a>。<br><img src="https://pic1.zhimg.com/v2-664c152ffc58a28a7f900f9a723cbb83_b.jpg" alt></p>
<blockquote>
<p>线性可分视角：神经网络的学习就是学习如何利用矩阵的线性变换加激活函数的非线性变换，将原始输入空间投向线性可分/稀疏的空间去分类/回归。<br>增加节点数：增加维度，即增加线性转换能力。<br>增加层数：增加激活函数的次数，即增加非线性转换次数。</p>
</blockquote>
<p>物理视角：“物质组成”</p>
<ul>
<li><p>类比：回想上文由碳氧原子通过不同组合形成若干分子的例子。从分子层面继续迭代这种组合思想，可以形成DNA，细胞，组织，器官，最终可以形成一个完整的人。继续迭代还会有家庭，公司，国家等。这种现象在身边随处可见。并且原子的内部结构与太阳系又惊人的相似。不同层级之间都是以类似的几种规则再不断形成新物质。你也可能听过分形学这三个字。可通过观看从<a href="https://video.tudou.com/v/XMjAzNzM4MzcyOA==.html?__fr=oldtd" target="_blank" rel="noopener">1米到150亿光年</a>来感受自然界这种层级现象的普遍性。<br><img src="https://picb.zhimg.com/80/v2-3ec7216f7ab84dac089836b166c0ae28_720w.jpg" alt></p>
</li>
<li><p>人脸识别情景：我们可以模拟这种思想并应用在画面识别上。由像素组成菱角再组成五官最后到不同的人脸。每一层代表不同的不同的物质层面 (如分子层)。而每层的W存储着如何组合上一层的物质从而形成新物质。<br>如果我们完全掌握一架飞机是如何从分子开始一层一层形成的，拿到一堆分子后，我们就可以判断他们是否可以以此形成方式，形成一架飞机。<br>附：<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.72546&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" target="_blank" rel="noopener">Tensorflow playground</a>展示了数据是如何“流动”的。<br><img src="https://pic2.zhimg.com/80/v2-82f05552fd2ddde28a0ef20814d7acbb_720w.jpg" alt></p>
</li>
</ul>
<blockquote>
<p>物质组成视角：神经网络的学习过程就是学习物质组成方式的过程。<br>增加节点数：增加同一层物质的种类，比如118个元素的原子层就有118个节点。<br>增加层数：增加更多层级，比如分子层，原子层，器官层，并通过判断更抽象的概念来识别物体。</p>
</blockquote>
<p>三、神经网络的训练<br>知道了神经网络的学习过程就是学习控制着空间变换方式（物质组成方式）的权重矩阵后，接下来的问题就是如何学习每一层的权重矩阵 W 。</p>
<p>如何训练：</p>
<p>既然我们希望网络的输出尽可能的接近真正想要预测的值。那么就可以通过比较当前网络的预测值和我们真正想要的目标值，再根据两者的差异情况来更新每一层的权重矩阵（比如，如果网络的预测值高了，就调整权重让它预测低一些，不断调整，直到能够预测出目标值）。因此就需要先定义“如何比较预测值和目标值的差异”，这便是损失函数或目标函数（loss function or objective function），用于衡量预测值和目标值的差异的方程。loss function的输出值（loss）越高表示差异性越大。那神经网络的训练就变成了尽可能的缩小loss的过程。</p>
<p>所用的方法是梯度下降（Gradient descent）：通过使loss值向当前点对应梯度的反方向不断移动，来降低loss。一次移动多少是由学习速率（learning rate）来控制的。</p>
<p>梯度下降的问题：<br>然而使用梯度下降训练神经网络拥有两个主要难题。</p>
<p>1、局部极小值<br>梯度下降寻找的是loss function的局部极小值，而我们想要全局最小值。如下图所示，我们希望loss值可以降低到右侧深蓝色的最低点，但loss有可能“卡”在左侧的局部极小值中。<br><img src="https://pic2.zhimg.com/80/v2-00fe10bf8877137bc5957cf0cd7f9219_720w.jpg" alt></p>
<p>试图解决“卡在局部极小值”问题的方法分两大类：</p>
<ul>
<li>调节步伐：调节学习速率，使每一次的更新“步伐”不同。常用方法有：</li>
<li>随机梯度下降（Stochastic Gradient Descent (SGD)：每次只更新一个样本所计算*的梯度</li>
<li>小批量梯度下降（Mini-batch gradient descent）：每次更新若干样本所计算的梯度的平均值</li>
<li>动量（Momentum）：不仅仅考虑当前样本所计算的梯度；Nesterov动量（Nesterov Momentum）：Momentum的改进</li>
<li>Adagrad、RMSProp、Adadelta、Adam：这些方法都是训练过程中依照规则降低学习速率，部分也综合动量</li>
<li>优化起点：合理初始化权重（weights initialization）、预训练网络（pre-train），使网络获得一个较好的“起始点”，如最右侧的起始点就比最左侧的起始点要好。常用方法有：高斯分布初始权重（Gaussian distribution）、均匀分布初始权重（Uniform distribution）、Glorot 初始权重、He初始权、稀疏矩阵初始权重（sparse matrix）</li>
</ul>
<p>2、梯度的计算<br>机器学习所处理的数据都是高维数据，该如何快速计算梯度、而不是以年来计算。<br>其次如何更新隐藏层的权重？<br>解决方法是：计算图：反向传播算法<br>这里的解释留给非常棒的<a href="https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2015-08-Backprop/">Computational Graphs: Backpropagation</a><br>需要知道的是，反向传播算法是求梯度的一种方法。如同快速傅里叶变换（FFT）的贡献。<br>而计算图的概念又使梯度的计算更加合理方便。</p>
<p>基本流程图：<br>下面就结合图简单浏览一下训练和识别过程，并描述各个部分的作用。要结合图解阅读以下内容。但手机显示的图过小，最好用电脑打开。<br><img src="https://pic2.zhimg.com/80/v2-69c014a15afde18a4086950c30e97d1b_720w.jpg" alt></p>
<ul>
<li>收集训练集（train data）：也就是同时有input以及对应label的数据。每个数据叫做训练样本（sample）。label也叫target，也是机器学习中最贵的部分。上图表示的是我的数据库。假设input本别是x的维度是39，label的维度是48。</li>
<li><p>设计网络结构（architecture）：确定层数、每一隐藏层的节点数和激活函数，以及输出层的激活函数和损失函数。上图用的是两层隐藏层（最后一层是输出层）。隐藏层所用激活函数a( )是ReLu，输出层的激活函数是线性linear（也可看成是没有激活函数）。隐藏层都是1000节点。损失函数L( )是用于比较距离MSE：mean((output - target)^2)。MSE越小表示预测效果越好。训练过程就是不断减小MSE的过程。到此所有数据的维度都已确定：<br>训练数据：$input\in R_39;label \in R_48$<br>权重矩阵：$W_{h_1} \in R^{1000x39};W_{h2} \in R^{1000x1000};W_o \in R^{48x1000}$<br>偏移向量：$b_{h_1} \in R^1000;b_{h_2} \in R^1000; b_o \in R^48$<br>网络输出：$output \in R^{48}$</p>
</li>
<li><p>数据预处理（preprocessing）：将所有样本的input和label处理成能够使用神经网络的数据，label的值域符合激活函数的值域。并简单优化数据以便让训练易于收敛。比如中心化（mean subtraction）、归一化（normalization）、主成分分析（PCA）、白化（whitening）。假设上图的input和output全都经过了中心化和归一化。</p>
</li>
<li>权重初始化（weights initialization）：$W_{h_1},W_{h_2},W_0$在训练前不能为空，要初始化才能够计算loss从而来降低。$W_{h_1},W_{h_2},W_0$初始化决定了loss在loss function中从哪个点开始作为起点训练网络。上图用均匀分布初始权重（Uniform distribution）。</li>
<li>训练网络（training）：训练过程就是用训练数据的input经过网络计算出output，再和label计算出loss，再计算出gradients来更新weights的过程。<ul>
<li>正向传递：，算当前网络的预测值$output=linear(W_o·Relu(W_{h_2}·Relu(W_{h_1}·input+b_{h_1})+b_{h_2})+b_o)$</li>
<li>计算loss：$loss=mean((output-target)^2)$</li>
<li>计算梯度：从loss开始反向传播计算每个参数（parameters）对应的梯度（gradients）。这里用Stochastic Gradient Descent (SGD) 来计算梯度，即每次更新所计算的梯度都是从一个样本计算出来的。传统的方法Gradient Descent是正向传递所有样本来计算梯度。SGD的方法来计算梯度的话，loss function的形状如下图所示会有变化，这样在更新中就有可能“跳出”局部最小值。<br><img src="https://pic2.zhimg.com/80/v2-0c0e7f5ffa98c2c1eb87763dd5d1d9a3_720w.jpg" alt></li>
<li>更新权重：这里用最简单的方法来更新，即所有参数都 $W=W-learninggrate*gradient$</li>
<li>预测新值：训练过所有样本后，打乱样本顺序再次训练若干次。训练完毕后，当再来新的数据input，就可以利用训练的网络来预测了。这时的output就是效果很好的预测值了。下图是一张实际值和预测值的三组对比图。输出数据是48维，这里只取1个维度来画图。蓝色的是实际值，绿色的是预测值。最上方的是训练数据的对比图，而下方的两行是神经网络模型从未见过的数据预测对比图。（不过这里用的是RNN，主要是为了让大家感受一下效果）<br><img src="https://pic3.zhimg.com/80/v2-a675e692f7f7755d91bcdba5e988e910_720w.jpg" alt></li>
</ul>
</li>
</ul>
<p>注：此部分内容不是这篇文章的重点，但为了理解深层神经网络，需要明白最基本的训练过程。<br>若能理解训练过程是通过梯度下降尽可能缩小loss的过程即可。<br>若有理解障碍，可以用python实践一下<a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/" target="_blank" rel="noopener">从零开始训练一个神经网络</a>，体会整个训练过程。若有时间则可以再体会一下计算图自动求梯度的方便利用<a href="https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners" target="_blank" rel="noopener">TensorFlow</a>。</p>
<p>结合<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.50484&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" target="_blank" rel="noopener">Tensorflow playground</a>理解5种空间操作和物质组成视角<br>打开网页后，总体来说，蓝色代表正值，黄色代表负值。拿分类任务来分析。</p>
<ul>
<li>数据：在二维平面内，若干点被标记成了两种颜色。黄色，蓝色，表示想要区分的两类。你可以把平面内的任意点标记成任意颜色。网页给你提供了4种规律。神经网络会根据你给的数据训练，再分类相同规律的点。<br><img src="https://pic3.zhimg.com/80/v2-6d17d1fb77d3ae1838f5253193456317_720w.jpg" alt></li>
<li>输入：在二维平面内，你想给网络多少关于“点”的信息。从颜色就可以看出来，$x_1$左边是负，右边是正，$x_1$表示此点的横坐标值。同理，$x_2$表示此点的纵坐标值。$x_1^2$是关于横坐标值的“抛物线”信息。你也可以给更多关于这个点的信息。给的越多，越容易被分开。<br><img src="https://picb.zhimg.com/80/v2-111e37e8479aa57bedbfb2dbcd8e5b63_720w.jpg" alt></li>
<li>连接线：表示权重，蓝色表示用神经元的原始输出，黄色表示用负输出。深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值。也可以更改。在（1）中，当把$x_2$输出的一个权重改为-1时，$x_2$的形状直接倒置了。不过还需要考虑激活函数。（1）中用的是linear。在（2）中，当换成sigmoid时，你会发现没有黄色区域了。因为sigmoid的值域是(0,1)<br><img src="https://pic4.zhimg.com/80/v2-2820b0562c8fcd7a49d57c4deb1e4f3c_720w.jpg" alt><br><img src="https://pic2.zhimg.com/80/v2-83fd9f01e2ea38c7f6b8aeaa308cf040_720w.jpg" alt></li>
<li>输出：黄色背景颜色都被归为黄点类，蓝色背景颜色都被归为蓝点类。深浅表示可能性的强弱。<br><img src="https://pic4.zhimg.com/80/v2-dff3f6e72881ebd222414eabb9504671_720w.jpg" alt><br>上图中所有在黄色背景颜色的点都会被分类为“黄点“，同理，蓝色区域被分成蓝点。在上面的分类分布图中你可以看到每一层通过上一层信息的组合所形成的。权重（那些连接线）控制了“如何组合”。神经网络的学习也就是从数据中学习那些权重。Tensorflow playground所表现出来的现象就是“在我文章里所写的“物质组成思想”，这也是为什么我把<a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.27298&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" target="_blank" rel="noopener">Tensorflow playground</a>放在了那一部分。</li>
</ul>
<p>不过你要是把Tensorflow的个名字拆开来看的话，是tensor（张量）的flow（流动）。Tensorflow playground的作者想要阐述的侧重点是“张量如何流动”的。</p>
<p>5种空间变换的理解：Tensorflow playground下没有体现5种空间变换的理解。需要打开这个网站尝试：<a href="https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" target="_blank" rel="noopener">ConvNetJS demo: Classify toy 2D data</a><br><img src="https://pic4.zhimg.com/80/v2-55811ac3d91f56f19543714b1b5abe49_720w.jpg" alt><br>左侧是原始输入空间下的分类图，右侧是转换后的高维空间下的扭曲图。<br><img src="https://pic2.zhimg.com/80/v2-a81a10592b96a1d2b067e1d4ae3951e7_720w.jpg" alt><br>最终的扭曲效果是所有绿点都被扭曲到了一侧，而所有红点都被扭曲到了另一侧。这样就可以线性分割（用超平面（这里是一个平面）在中间分开两类）</p>
<p>四、表现原因<br>文章的最后稍微提一下深层神经网络。深层神经网络就是拥有更多层数的神经网络。</p>
<p>按照上文在理解视角中所述的观点，可以想出下面两条理由关于为什么更深的网络会更加容易识别，增加容纳变异体（variation）（红苹果、绿苹果）的能力、鲁棒性（robust）。</p>
<p>数学视角：变异体（variation）很多的分类的任务需要高度非线性的分割曲线。不断的利用那5种空间变换操作将原始输入空间像“捏橡皮泥一样”在高维空间下捏成更为线性可分/稀疏的形状。</p>
<p>物理视角：通过对“抽象概念”的判断来识别物体，而非细节。比如对“飞机”的判断，即便人类自己也无法用语言或者若干条规则来解释自己如何判断一个飞机。因为人脑中真正判断的不是是否“有机翼”、“能飞行”等细节现象，而是一个抽象概念。层数越深，这种概念就越抽象，所能涵盖的变异体就越多，就可以容纳战斗机，客机等很多种不同种类的飞机。</p>
<h1 id="lt-span-id-”header8-gt-YJango的TensorFlow1-x整体把握-lt-span-gt"><a href="#lt-span-id-”header8-gt-YJango的TensorFlow1-x整体把握-lt-span-gt" class="headerlink" title="&lt;span id=”header8&gt;YJango的TensorFlow1.x整体把握&lt;/span&gt;"></a>&lt;span id=”header8&gt;YJango的TensorFlow1.x整体把握&lt;/span&gt;</h1><p>目前主流的TensorFlow，用tensorflow这样工具的原因是：它允许我们用计算图（Computational Graphs）的方式建立网络。同时又可以非常方便的对网络进行操作。</p>
<p>下面就是对计算图的直观讲解</p>
<p>比喻说明：</p>
<ul>
<li><p>结构：计算图所建立的只是一个网络框架。在编程时，并不会有任何实际值出现在框架中。所有权重和偏移都是框架中的一部分，初始时至少给定初始值才能形成框架。因此需要initialization初始化。</p>
</li>
<li><p>比喻：计算图就是一个管道。编写网络就是搭建一个管道结构。在投入实际使用前，不会有任何液体进入管道。而神经网络中的权重和偏移就是管道中的阀门，可以控制液体的流动强弱和方向。在神经网络的训练中，阀门会根据数据进行自我调节、更新。但是使用之前至少要给所有阀门一个初始的状态才能形成结构。用计算图的好处是它允许我们可以从任意一个节点处取出液体。<br><img src="https://pic4.zhimg.com/80/v2-7ac033df767fcd722c88cda4829cb13b_720w.jpg" alt></p>
</li>
</ul>
<p>用法说明：<br>请类比管道构建来理解计算图的用法</p>
<p>构造阶段（construction phase）：组装计算图（管道）</p>
<ul>
<li>计算图（graph）：要组装的结构。由许多操作组成。</li>
<li>操作（ops）：接受（流入）零个或多个输入（液体），返回（流出）零个或多个输出。</li>
<li>数据类型：主要分为张量（tensor）、变量（variable）和常量（constant）<ul>
<li>张量：多维array或list（管道中的液体）<ul>
<li>创建语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor_name&#x3D;tf.placeholder(type, shape, name)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>变量：在同一时刻对图中所有其他操作都保持静态的数据（管道中的阀门）</p>
<ul>
<li>创建语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name_variable &#x3D; tf.Variable(value, name)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>初始化语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#个别变量</span><br><span class="line">init_op&#x3D;variable.initializer()</span><br><span class="line">#所有变量</span><br><span class="line">init_op&#x3D;tf.initialize_all_variables()</span><br><span class="line">#注意：init_op的类型是操作（ops），加载之前并不执行</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update_op&#x3D;tf.assign(variable to be updated, new_value)</span><br></pre></td></tr></table></figure>
</li>
<li><p>常量：无需初始化的变量</p>
<ul>
<li>创建语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name_constant&#x3D;tf.constant(value)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>执行阶段（execution phase）：使用计算图（获取液体）</p>
<ul>
<li><p>会话：执行（launch）构建的计算图。可选择执行设备：单个电脑的CPU、GPU，或电脑分布式甚至手机。</p>
<ul>
<li>创建语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#常规</span><br><span class="line">sess &#x3D; tf.Session()</span><br><span class="line">#交互</span><br><span class="line">sess &#x3D; tf.InteractiveSession()</span><br><span class="line">#交互方式可用tensor.eval()获取值，ops.run()执行操作</span><br><span class="line">#关闭</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>执行操作：使用创建的会话执行操作</p>
<ul>
<li>执行语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run(op)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>送值（feed）：输入操作的输入值（输入液体）</p>
<ul>
<li>语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run([output], feed_dict&#x3D;&#123;input1:value1, input2:value1&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>取值（fetch）：获取操作的输出值（得到液体）</p>
<ul>
<li>语句：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#单值获取 </span><br><span class="line">sess.run(one op)</span><br><span class="line">#多值获取</span><br><span class="line">sess.run([a list of ops])</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="YJango的循环神经网络——介绍"><a href="#YJango的循环神经网络——介绍" class="headerlink" title="YJango的循环神经网络——介绍"></a><span id="header9">YJango的循环神经网络——介绍</span></h1><p>该文主要目的是让大家体会循环神经网络在与前馈神经网络的不同之处。</p>
<p>大家貌似都叫Recurrent Neural Networks为循环神经网络。</p>
<p>我之前是查维基百科的缘故，所以一直叫它递归网络。</p>
<p>下面我所提到的递归网络全部都是指Recurrent Neural Networks。</p>
<p>递归神经网络的讨论分为三部分</p>
<p>介绍：描述递归网络和前馈网络的差别和优劣<br>实现：梯度消失和梯度爆炸问题，及解决问题的LSTM和GRU<br>代码：用tensorflow1.x实际演示一个任务的训练和使用</p>
<p>时序预测问题<br>一、用前馈神经网络来做时序信号预测有什么问题？</p>
<ul>
<li>依赖受限：前馈网络是利用窗处理将不同时刻的向量并接成一个更大的向量。以此利用前后发生的事情预测当前所发生的情况。如下图所示：<br><img src="https://pic4.zhimg.com/v2-c984ea3ba696a0a786bb0bb52f0d772e_b.webp" alt><ul>
<li>但其所能考虑到的前后依赖受限于将多少个向量（window size）并接在一起。所能考虑的依赖始终是固定长度的。</li>
</ul>
</li>
<li>网络规格：想要更好的预测，需要让网络考虑更多的前后依赖。<br>例：若仅给“国（）”，让玩家猜括号中的字时，所能想到的可能性非常之多。但若给“中国（）”时，可能性范围降低。当给“我是中国（）”时，猜中的可能性会进一步增加。</li>
</ul>
<p>那么很自然的做法就是扩大并接向量的数量，但这样做的同时也会使输入向量的维度和神经网络第一层的权重矩阵的大小快速增加。如YJango的前馈神经网络—代码LV3中每个输入向量的维度是39，41帧的窗处理之后，维度变成了1599，并且神经网络第一层的权重矩阵也变成了1599 by n（n为下一层的节点数）。其中很多权重都是冗余的，但却不得不一直存在于每一次的预测之中。</p>
<ul>
<li>训练所需样本数：前两点可能无伤大雅，而真正使得递归神经网络（recurrent）在时序预测中击败前馈神经网络的关键在于训练网络所需要的数据量。</li>
</ul>
<p>网络差异之处<br>几乎所有的神经网络都可以看作为一种特殊制定的前馈神经网络，这里“特殊制定”的作用在于缩减寻找映射函数的搜索空间，也正是因为搜索空间的缩小，才使得网络可以用相对较少的数据量学习到更好的规律。</p>
<p>例：解一元二次方程y=ax+b。我们需要两组配对的(x,y)来解该方程。但是如果我们知道y=ax+b实际上是y=ax，这时就只需要一对(x,y)就可以确定x与y的关系。递归神经网络和卷积神经网络等神经网络的变体就具有类似的功效。</p>
<p>二、相比前馈神经网络，递归神经网络究竟有何不同之处？</p>
<p>需要注意的是递归网络并非只有一种结构，这里介绍一种最为常用和有效的递归网络结构。</p>
<p>数学视角<br>首先让我们用从输入层到隐藏层的空间变换视角来观察，不同的地方在于，这次将时间维度一起考虑在内。</p>
<p>注：这里的圆圈不再代表节点，而是状态，是输入向量和输入经过隐藏层后的向量。</p>
<p>例子：用目前已说的所有字预测下一个字。</p>
<p>前馈网络：window size为3帧的窗处理后的前馈网络</p>
<ul>
<li>动态图：左侧是时间维度展开前，右侧是展开后（单位时刻实际工作的只有灰色部分。）。前馈网络的特点使不同时刻的预测完全是独立的。我们只能通过窗处理的方式让其照顾到前后相关性。<br><img src="https://pic3.zhimg.com/v2-8cc0db5acd643dd7ca3668ad6e35aabb_b.webp" alt></li>
<li>数学式子：$h_t=\phi(W_{xh}·concat(x_{t-1},x_t,x_{t+1})+b)$，concat表示将向量并接成一个更大维度的向量。</li>
<li>学习参数：需要从大量的数据中学习$W_{xh}$和b。</li>
<li>要学习各个时刻（3个）下所有维度（39维）的关系（39*3个），就需要很多数据。</li>
</ul>
<p>递归网络：不再有window size的概念，而是time step</p>
<ul>
<li>动态图：左侧是时间维度展开前，回路方式的表达方式，其中黑方框表示时间延迟。右侧展开后，可以看到当前时刻的$h_t$并不仅仅取决于当前时刻的输入$x_t$，同时与上一时刻的$h_{t-1}$也相关。<br><img src="https://pic3.zhimg.com/v2-db52470df88f53271d8e06722da39122_b.jpg" alt><br>数学式子：$h_t=\phi(W_{xh}·x_t+W_{hh}·h_{t-1}+b)$。{h_t}同样也由x_t经$W_{zh}$的变化后的信息决定，<br>但这里多另一份信息：$W_{hh}·h_{t-1}$，而该信息是从上一时刻的隐藏状态$h_{t-1}$经过一个不同的$W_{hh}$变换后得出的。<br>注：$W_{xh}$的形状是行为dim_input，列为dim_hidden_state，而$W_{hh}$是一个行列都为dim_hidden_state的方阵。<br>学习参数：前馈网络需要3个时刻来帮助学习一次$W_{xh}$，而递归网络可以用3个时刻来帮助学习3次$W_{xh}$和$W_{hh}$。换句话说：所有时刻的权重矩阵都是共享的。这是递归网络相对于前馈网络而言最为突出的优势。</li>
</ul>
<blockquote>
<p>递归神经网络是在时间结构上存在共享特性的神经网络变体。</p>
</blockquote>
<p>时间结构共享是递归网络的核心中的核心。</p>
<p>物理视角<br>共享特性给网络带来了诸多好处，但也产生了另一个问题：</p>
<p>三、为什么可以共享？</p>
<p>在物理视角中，YJango想给大家展示的第一点就是为什么我们可以用这种共享不同时刻权重矩阵的网络进行时序预测。</p>
<p>下图可以从直觉上帮助大家感受日常生活中很多时序信号是如何产生的。</p>
<p>例1：轨迹的产生，如地球的轨迹有两条线索决定，其中一条是地球自转，另一条是地球围绕太阳的公转。下图是太阳和其他星球。自转相当于[公式]，而公转相当于[公式]。二者共同决定实际轨迹。<br><img src="https://pic1.zhimg.com/80/v2-8b7c5c5225b6a7337e23786ecb5b2fe3_720w.jpg" alt></p>
<p>例2：同理万花尺<br><img src="https://pic2.zhimg.com/v2-9e770433dc6a146e7625dd155ba00ec5_b.jpg" alt></p>
<p>例3：演奏音乐时，乐器将力转成相应的震动产生声音，而整个演奏拥有一个主旋律贯穿全曲。其中乐器的物理特性就相当于[公式]，同一乐器在各个时刻物理特性在各个时刻都是共享的。其内在也有一个隐藏的主旋律基准[公式]，旋律信息[公式]与音乐信息[公式]共同决定下一时刻的实际声音。<br>上述例子中所产生的轨迹、音乐都是我们所能观察到的observations，我们常常会利用这些observation作为依据来做出决策。</p>
<p>下面的例子可能更容易体会共享特性对于数据量的影响。</p>
<p>实例：捏陶瓷：不同角度相当于不同的时刻<br><img src="https://pic3.zhimg.com/v2-c84b8f3c65a62e4ceee81899c5126365_b.webp" alt></p>
<ul>
<li>若用前馈网络：网络训练过程相当于不用转盘，而是徒手将各个角度捏成想要的形状。不仅工作量大，效果也难以保证。</li>
<li>若用递归网络：网络训练过程相当于在不断旋转的转盘上，以一种手势捏造所有角度。工作量降低，效果也可保证。</li>
</ul>
<p>递归网络特点</p>
<ul>
<li>时序长短可变：只要知道上一时刻的隐藏状态$h_{t-1}$与当前时刻的输入$x_t$，就可以计算当前时刻的隐藏状态$h_t$。并且由于计算所用到的W_{xh}与W_{hh}在任意时刻都是共享的。递归网络可以处理任意长度的时间序列。</li>
<li>顾及时间依赖：若当前时刻是第5帧的时序信号，那计算当前的隐藏状态$h_5$就需要当前的输入$x_5$和第4帧的隐藏状态$h_4$，而计算$h_4$又需要$h_3$，这样不断逆推到初始时刻为止。意味着常规递归网络对过去所有状态都存在着依赖关系。<br>注：在计算$h_0$的值时，若没有特别指定初始隐藏状态，则会将$h_{t-1}$全部补零，表达式会变成前馈神经网络：$h_t=\phi (W_{xh}·x_t+0+b)$</li>
<li>未来信息依赖：前馈网络是通过并接未来时刻的向量来引入未来信息对当前内容判断的限制，但常规的递归网络只对所有过去状态存在依赖关系。所以递归网络的一个扩展就是双向（bidirectional）递归网络：两个不同方向的递归层叠加。</li>
<li><p>关系图：正向（forward）递归层是从最初时刻开始，而反向（backward）递归层是从最末时刻开始。<br><img src="https://picb.zhimg.com/80/v2-a9c81692067bca508bc88ba3f3ecb7b8_720w.jpg" alt></p>
</li>
<li><p>数学式子：</p>
<ul>
<li>正向递归层：$h_t^f=\phi (W_{xh}^f·x_t+W_{hh}^f·h_{t-1}+b^f)$</li>
<li>反向递归层：$h_t^b=\phi (W_{xh}^b·x_t+W_{hh}^b·h_{t+1}+b^b)$</li>
<li>双向递归层：$h_t=h_t^f+h_t^b$</li>
<li>注：还有并接的处理方式，即$h_t=concat(h_t^f,h_t^b)$，但反向递归层的作用是引入未来信息对当前预测判断的额外限制。并不是信息维度不够。至少在我所有的实验中，相加（sum）的方式往往优于并接。</li>
<li>注：也有人将正向递归层和反向递归层中的权重$W_{xh}^f$与$W_{xh}^b$共享，$W_{hh}^f$与$W_{xh}^b$共享。我没有做实验比较过。但直觉上$W_{hh}^f$与$W_{hh}^b$共享在某些任务中可能会有些许提升。$W_{hh}^f$与$W_{hh}^b$的共享恐怕并不会起到什么作用（要贴合任务而言）。</li>
<li>注：隐藏状态$h_t$通常不会是网络的最终结果，一般都会将$h_t$再接着另一个$\phi (W_{ho}·h_t+b_o)$将其投射到输出状态$o_t$。一个最基本的递归网络不会出现前馈神经网络那样从输入层直接到输出层的情况，而是至少会有一个隐藏层。</li>
<li>注：双向递归层可以提供更好的识别预测效果，但却不能实时预测，由于反向递归的计算需要从最末时刻开始，网络不得不等待着完整序列都产生后才可以开始预测。在对于实时识别有要求的线上语音识别，其应用受限。</li>
</ul>
</li>
<li><p>递归网络输出：递归网络的出现实际上是对前馈网络在时间维度上的扩展。</p>
<ul>
<li>关系图：常规网络可以将输入和输出以向量对向量（无时间维度）的方式进行关联。而递归层的引入将其扩展到了序列对序列的匹配。从而产生了one to one右侧的一系列关联方式。较为特殊的是最后一个many to many，发生在输入输出的序列长度不确定时，其实质两个递归网络的拼接使用，公共点在紫色的隐藏状态$h_{t+1}$。<br><img src="https://picb.zhimg.com/80/v2-78c48d9ca0b66d6b46202b019b5ecb66_720w.jpg" alt></li>
<li>many to one：常用在情感分析中，将一句话关联到一个情感向量上去。</li>
<li>many to many：第一个many to many在DNN-HMM语音识别框架中常有用到</li>
<li>many to many(variable length)：第二个many to many常用在机器翻译两个不同语言时。</li>
</ul>
</li>
<li><p>递归网络数据：递归网络由于引入time step的缘故，使得其训练数据与前馈网络有所不同</p>
<ul>
<li>前馈网络：输入和输出：矩阵<ul>
<li>输入矩阵形状：(n_samples, dim_input)</li>
<li>输出矩阵形状：(n_samples, dim_output)</li>
<li>注：真正测试/训练的时候，网络的输入和输出就是向量而已。加入n_samples这个维度是为了可以实现一次训练多个样本，求出平均梯度来更新权重，这个叫做Mini-batch gradient descent。</li>
<li>如果n_samples等于1，那么这种更新方式叫做Stochastic Gradient Descent (SGD)。</li>
</ul>
</li>
<li>递归网络：输入和输出：维度至少是3的张量，如果是图片等信息，则张量维度仍会增加。<ul>
<li>输入张量形状：(time_steps, n_samples, dim_input)</li>
<li>输出张量形状：(time_steps, n_samples, dim_output)</li>
<li>注：同样是保留了Mini-batch gradient descent的训练方式，但不同之处在于多了time step这个维度。</li>
<li>Recurrent 的任意时刻的输入的本质还是单个向量，只不过是将不同时刻的向量按顺序输入网络。你可能更愿意理解为一串向量 a sequence of vectors，或者是矩阵。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>网络对待<br>请以层的概念对待所有网络。递归神经网络是指拥有递归层的神经网络，其关键在于网络中存在递归层。</p>
<p>每一层的作用是将数据从一个空间变换到另一个空间下。可以视为特征抓取方式，也可以视为分类器。二者没有明显界限并彼此包含。关键在于使用者如何理解。</p>
<p>以层的概念理解网络的好处在于，今后的神经网络往往并不会仅用到一种处理手段。往往是前馈、递归、卷积混合使用。 这时就无法再以递归神经网络来命名该结构。</p>
<p>例：下图中就是在双向递归层的前后分别又加入了两个前馈隐藏层。也可以堆积更多的双向递归层，人们也会在其前面加入“深层”二字，提高逼格。<br><img src="https://pic3.zhimg.com/80/v2-1c85ff7e786721b62d2f9b15991a6871_720w.jpg" alt></p>
<p>注：层并不是图中所画的圆圈，而是连线。圆圈所表示的是穿过各层前后的状态。</p>
<p>归网络问题<br>常规递归网络从理论上应该可以顾及所有过去时刻的依赖，然而实际却无法按人们所想象工作。原因在于梯度消失（vanishinggradient）和梯度爆炸（exploding gradient）问题。下一节就是介绍Long Short Term Memory（LSTM）和Gated Recurrent Unit（GRU）：递归网络的特别实现算法。</p>
<p>最后点个题，重要的事情说一万遍</p>
<blockquote>
<p>Recurrent Layer在时间结构上存在共享特性。</p>
</blockquote>
<h1 id="YJango的循环神经网络——实现LSTM"><a href="#YJango的循环神经网络——实现LSTM" class="headerlink" title="YJango的循环神经网络——实现LSTM"></a><span id="10">YJango的循环神经网络——实现LSTM</span></h1><p><img src="https://pic2.zhimg.com/v2-b75451ec04c675d9ba7e3e1ba2971821_1440w.jpg?source=172ae18b" alt><br>介绍<br>描述最常用的RNN实现方式：Long-Short Term Memory（LSTM）</p>
<p>梯度消失和梯度爆炸<br>网络回忆：在《循环神经网络——介绍》中提到循环神经网络用相同的方式处理每个时刻的数据。</p>
<p>动态图：<br><img src="https://pic3.zhimg.com/v2-db52470df88f53271d8e06722da39122_b.jpg" alt></p>
<p>数学公式：$h_t=\phi(W_{xh}·x_t+W_{hh}·h_{t-1}+b)$</p>
<p>设计目的：我们希望循环神经网络可以将过去时刻发生的状态信息传递给当前时刻的计算中。</p>
<p>实际问题：但普通的RNN结构却难以传递相隔较远的信息。</p>
<p>考虑：若只看上图蓝色箭头线的、隐藏状态的传递过程，不考虑非线性部分，那么就会得到一个简化的式子(1)：<br>(1) $h_t=W_{hh}·h_{t-1}$<br>如果将起始时刻的隐藏状态信息$h_0$向第t时刻传递，会得到式子(2)<br>(2) $h_t=(W_{hh})^t·h_0$<br>$W_{hh}$会被乘以多次，若允许矩阵$W_{hh}$进行特征分解<br>(3) $h_t=(W_{hh})^t·h_0$<br>式子(2)会变成(4)<br>(4) $h_t=Q·\lambda ^t·Q^T·h_0 $<br>当特征值小于1时，不断相乘的结果是特征值的t次方向 0 衰减； 当特征值大于1时，不断相乘的结果是特征值的t次方向 $\infty$扩增。 这时想要传递的$h_0$中的信息会被掩盖掉，无法传递到$h_t$。</p>
<p><img src="https://pic2.zhimg.com/80/v2-f1f179149020fd496170de1bb25fcbee_720w.png" alt></p>
<p>类比：设想$y=a^t*x$，如果a等于0.1，x在被不断乘以0.1一百次后会变成多小？如果a等于5，x在被不断乘以5一百次后会变得多大？若想要x所包含的信息既不消失，又不爆炸，就需要尽可能的将a的值保持在1。<br>注：更多内容请参阅<a href="http://www.deeplearningbook.org/contents/rnn.html" target="_blank" rel="noopener">Deep Learning by Ian Goodfellow中第十章</a>。</p>
<p>Long Short Term Memory (LSTM)<br>上面的现象可能并不意味着无法学习，但是即便可以，也会非常非常的慢。为了有效的利用梯度下降法学习，我们希望使不断相乘的梯度的积(the product of derivatives)保持在接近1的数值。</p>
<p>一种实现方式是建立线性自连接单元(linear self-connections)和在自连接部分数值接近1的权重，叫做leaky units。但Leaky units的线性自连接权重是手动设置或设为参数，而目前最有效的方式gated RNNs是通过gates的调控，允许线性自连接的权重在每一步都可以自我变化调节。LSTM就是gated RNNs中的一个实现。</p>
<p>LSTM的初步理解<br>LSTM(或者其他gated RNNs)是在标准RNN （$h_t=\phi (W_{xh}·x_t+W_{hh}·h_{t-1}+b)$）的基础上装备了若干个控制数级(magnitude)的gates。可以理解成神经网络(RNN整体)中加入其他神经网络(gates)，而这些gates只是控制数级，控制信息的流动量。</p>
<p>数学公式：这里贴出基本LSTM的数学公式，看一眼就好，仅仅是为了让大家先留一个印象，不需要记住，不需要理解。</p>
<p><img src="https://pic4.zhimg.com/80/v2-eb4824dc842bb2f73be2b8d297c51944_720w.png" alt><br>尽管式子不算复杂，却包含很多知识，接下来就是逐步分析这些式子以及背后的道理。 比如[公式]的意义和使用原因，sigmoid的使用原因。</p>
<p>门(gate)的理解<br>理解Gated RNNs的第一步就是明白gate到底起到什么作用。</p>
<ul>
<li>物理意义：gate本身可看成是十分有物理意义的一个神经网络。<ul>
<li>输入：gate的输入是控制依据；</li>
<li>输出：gate的输出是值域为[公式]的数值，表示该如何调节其他数据的数级的控制方式。</li>
</ul>
</li>
<li>使用方式：gate所产生的输出会用于控制其他数据的数级，相当于过滤器的作用。<ul>
<li>类比图：可以把信息想象成水流，而gate就是控制多少水流可以流过。</li>
</ul>
</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-5b968059df4831d80b6c049579c5ea18_720w.jpg" alt></p>
<p>例如：当用gate来控制向量[20 5 7 8]时，<br>若gate的输出为[0.1 0.2 0.9 0.5]时，原来的向量就会被对应元素相乘(element-wise)后变成：<br>$\left[ \begin{array}{cccc}20&amp;5&amp;7&amp;8 \end{array} \right]\odot \left[ \begin{array}{cccc}0.1&amp;0.2&amp;0.9&amp;0.5 \end{array} \right]=\left[ \begin{array}{cccc}20<em>0.1&amp;5</em>0.2&amp;7<em>0.9&amp;8</em>0.5 \end{array}\right]=\left[ \begin{array}{cccc}2&amp;1&amp;6.3&amp;4 \end{array} \right]$</p>
<p>若gate的输出为$\left[ \begin{array}{cccc}0.5&amp;0.5&amp;0.5&amp;0.5 \end{array} \right]$时，原来的向量就会被对应元素相乘(element-wise)后变成：<br>$\left[ \begin{array}{cccc}20&amp;5&amp;7&amp;8r \end{array} \right]\odot \left[ \begin{array}{cccc}0.5&amp;0.5&amp;0.5&amp;0.5r \end{array} \right]=\left[ \begin{array}{cccc}10&amp;2.5&amp;3.5&amp;4r \end{array} \right]$</p>
<p>控制依据：明白了gate的输出后，剩下要确定以什么信息为控制依据，也就是什么是gate的输入。<br>例如：即便是LSTM也有很多个变种。一个变种方式是调控门的输入。例如下面两种gate：<br>$g=sigmoid(X_{xg}·x_t+W_{hg}·h_{t-1}+b)$：<br>这种gate的输入有当前的输入$x_t$和上一时刻的隐藏状态$h_{t-1}$， 表示gate是将这两个信息流作为控制依据而产生输出的。<br>$g=sigmoid(X_{xg}·x_t+W_{hg}·h_{t-1}+W_{cg}·c_{t-1}+b)$：<br>这种gate的输入有当前的输入$x_t$和上一时刻的隐藏状态$h_{t-1}$，以及上一时刻的cell状态$c_{t-1}$， 表示gate是将这三个信息流作为控制依据而产生输出的。这种方式的LSTM叫做peephole connections。</p>
<p>LSTM的再次理解<br>明白了gate之后再回过头来看LSTM的数学公式</p>
<p>数学公式：<br><img src="https://pic1.zhimg.com/80/v2-e45fc2149e49856df73c73fc9b635db3_720w.png" alt></p>
<p>gates：先将前半部分的三个式子$i_t,f_t,o_t$统一理解。在LSTM中，网络首先构建了3个gates来控制信息的流通量。<br>注： 虽然gates的式子构成方式一样，但是注意3个gates式子W和b的下角标并不相同。它们有各自的物理意义，在网络学习过程中会产生不同的权重。<br>有了这3个gates后，接下来要考虑的就是如何用它们装备在普通的RNN上来控制信息流，而根据它们所用于控制信息流通的地点不同，它们又被分为：</p>
<ul>
<li>输入门$i_t$：控制有多少信息可以流入memory cell（第四个式子$C_t$）。</li>
<li>遗忘门$f_t$：控制有多少上一时刻的memory cell中的信息可以累积到当前时刻的memory cell中。</li>
<li>输出门$o_t$：控制有多少当前时刻的memory cell中的信息可以流入当前隐藏状态$H_t$中。</li>
<li>注：gates并不提供额外信息，gates只是起到限制信息的量的作用。因为gates起到的是过滤器作用，所以所用的激活函数是sigmoid而不是tanh。</li>
</ul>
<p>信息流：信息流的来源只有三处，当前的输入$x_t，上一时刻的隐藏状态$h_{t-1}$，上一时刻的cell状态$c_{t-1}$，其中$c_{t-1}是额外制造出来、可线性自连接的单元（请回想起leaky units）。真正的信息流来源可以说只有当前的输入$x_t$，上一时刻的隐藏状态$h_{t-1}$两处。三个gates的控制依据，以及数据的更新都是来源于这两处。<br>分析了gates和信息流后，再分析剩下的两个等式，来看LSTM是如何累积历史信息和计算隐藏状态h的。<br>历史信息累积：<br>式子：$c_t=f_t \odot c_{t-1}+i_t \odot tanh(W_{xc}x_t+W_{hc}h_{t-1}+b_c)$<br>其中$new=tanh(W_{xc}x_t+W_{hc}h_{t-1}+b_c)$是本次要累积的信息来源。<br>改写：$c_t=f_t \odot c_{t-1}+i_t \odot new$</p>
<p>所以历史信息的累积是并不是靠隐藏状态h自身，而是依靠memory cell这个自连接来累积。 在累积时，靠遗忘门来限制上一时刻的memory cell的信息，并靠输入门来限制新信息。并且真的达到了leaky units的思想，memory cell的自连接是线性的累积。</p>
<p>当前隐藏状态的计算：如此大费周章的最终任然是同普通RNN一样要计算当前隐藏状态。<br>式子：$h_t=o_t \odot tanh(c_t)$<br>当前隐藏状态$h_t$是从$c_t$计算得来的，因为$c_t$是以线性的方式自我更新的，所以先将其加入带有非线性功能的$tanh(c_t)$。 随后再靠输出门$o_t$的过滤来得到当前隐藏状态$h_t$。</p>
<p>普通RNN与LSTM的比较<br>下面为了加深理解循环神经网络的核心，再来和YJango一起比较一下普通RNN和LSTM的区别。</p>
<ul>
<li><p>比较公式：最大的区别是多了三个神经网络(gates)来控制数据的流通。</p>
<ul>
<li>普通RNN：$h_t=tanh(W_{xh}·x_t+W_{hh}·h_{t-1}+b)$</li>
<li>LSTM：$h_t=o_t \odot tanh(f_t \odot c_{t-1} + i_t \odot tanh(W_{xc}x_t+W_{hc}h_{t-1}+b_c))$</li>
<li>比较：二者的信息来源都是$h_t=tanh(W_{xh}·x_t+W_{hh}·h_{t-1}+b)$， 不同的是LSTM靠3个gates将信息的积累建立在线性自连接的memory cell之上，并靠其作为中间物来计算当前$h_t$。</li>
</ul>
</li>
<li><p>示图比较：图片来自<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM</a>，强烈建议一并阅读。</p>
<ul>
<li>普通RNN：<br><img src="https://picb.zhimg.com/80/v2-bce0d99e8bc969fa3c2ffa99f93935c5_720w.png" alt></li>
<li><p>加号圆圈表示线性相加，乘号圆圈表示用gate来过滤信息。<br><img src="https://picb.zhimg.com/80/v2-703dffbefaddcf8dcdb39ccf589312e9_720w.jpg" alt></p>
</li>
<li><p>比较：新信息从黄色的tanh处，线性累积到memory cell之中后，又从红色的tanh处加入非线性并返回到了隐藏状态$h_t$的计算中。</p>
<blockquote>
<p>LSTM靠3个gates将信息的积累建立在线性自连接的权重接近1的memory cell之上，并靠其作为中间物来计算当前$h_t$。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>LSTM的类比<br>对于用LSTM来实现RNN的记忆，可以类比我们所用的手机（仅仅是为了方便记忆，并非一一对应）。<br><img src="https://pic4.zhimg.com/80/v2-3cbda7436b42c7b05c8a11868794e2b2_720w.jpg" alt></p>
<p>普通RNN好比是手机屏幕，而LSTM-RNN好比是手机膜。</p>
<p>大量非线性累积历史信息会造成梯度消失(梯度爆炸)好比是不断使用后容易使屏幕刮花。</p>
<p>而LSTM将信息的积累建立在线性自连接的memory cell之上，并靠其作为中间物来计算当前$h_t好比是用手机屏幕膜作为中间物来观察手机屏幕。</p>
<p>输入门、遗忘门、输出门的过滤作用好比是手机屏幕膜的反射率、吸收率、透射率三种性质。</p>
<p>Gated RNNs的变种<br>需要再次明确的是，神经网络之所以被称之为网络是因为它可以非常自由的创建合理的连接。而上面所介绍的LSTM也只是最基本的LSTM。只要遵守几个关键点，读者可以根据需求设计自己的Gated RNNs，而至于在不同任务上的效果需要通过实验去验证。下面就简单介绍YJango所理解的几个Gated RNNs的变种的设计方向。</p>
<ul>
<li>信息流：标准的RNN的信息流有两处：input输入和hidden state隐藏状态。</li>
</ul>
<p>但往往信息流并非只有两处，即便是有两处，也可以拆分成多处，并通过明确多处信息流之间的结构关系来加入先验知识，减少训练所需数据量，从而提高网络效果。</p>
<p>例如：<a href="https://arxiv.org/pdf/1503.00075.pdf" target="_blank" rel="noopener">Tree-LSTM</a>在具有此种结构的自然语言处理任务中的应用。<br><img src="https://picb.zhimg.com/80/v2-b6cc00b99f001d39d97be0932bd52575_720w.jpg" alt></p>
<ul>
<li><p>gates的控制方式：与LSTM一样有名的是Gated Recurrent Unit (GRU)，而GRU使用gate的方式就与LSTM的不同，GRU只用了两个gates，将LSTM中的输入门和遗忘门合并成了更新门。并且并不把线性自更新建立在额外的memory cell上，而是直接线性累积建立在隐藏状态上，并靠gates来调控。<br><img src="https://pic3.zhimg.com/80/v2-eb21a394a6bc08394a26b60707471c98_720w.png" alt></p>
</li>
<li><p>gates的控制依据：上文所介绍的LSTM中的三个gates所使用的控制依据都是$Wx_{t}+Wh_{t-1}$，但是可以通过与memory cell的连接来增加控制依据或者删除某个gate的$Wx_t$或$Wh_{t-1}$来缩减控制依据。比如去掉上图中$z_t=sigmoid(W_z·[h_{t-1},x_t])$中的$h_{t-1}$从而变成$z_t=sigmoid(W_z·h_{t-1})$</p>
</li>
</ul>
<h1 id="YJango的循环神经网络——scan实现LSTM"><a href="#YJango的循环神经网络——scan实现LSTM" class="headerlink" title="YJango的循环神经网络——scan实现LSTM"></a><span id="header11">YJango的循环神经网络——scan实现LSTM</span></h1><h2 id="处理训练数据"><a href="#处理训练数据" class="headerlink" title="处理训练数据"></a>处理训练数据</h2><p>目的：减掉每句数据的平均值，除以每句数据的标准差，降低模型拟合难度。<br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 所需库包</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">import time</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"># 直接使用在代码演示LV3中定义的function</span><br><span class="line">def Standardize(seq):</span><br><span class="line">  #subtract mean</span><br><span class="line">  centerized&#x3D;seq-np.mean(seq, axis &#x3D; 0)</span><br><span class="line">  #divide standard deviation</span><br><span class="line">  normalized&#x3D;centerized&#x2F;np.std(centerized, axis &#x3D; 0)</span><br><span class="line">  return normalized</span><br><span class="line"># 读取输入和输出数据</span><br><span class="line">mfc&#x3D;np.load(&#39;X.npy&#39;)</span><br><span class="line">art&#x3D;np.load(&#39;Y.npy&#39;)</span><br><span class="line">totalsamples&#x3D;len(mfc)</span><br><span class="line"># 20%的数据作为validation set</span><br><span class="line">vali_size&#x3D;0.2</span><br><span class="line"># 将每个样本的输入和输出数据合成list，再将所有的样本合成list</span><br><span class="line"># 其中输入数据的形状是[n_samples, n_steps, D_input]</span><br><span class="line"># 其中输出数据的形状是[n_samples, D_output]</span><br><span class="line">def data_prer(X, Y):</span><br><span class="line">  D_input&#x3D;X[0].shape[1]</span><br><span class="line">  data&#x3D;[]</span><br><span class="line">  for x,y in zip(X,Y):</span><br><span class="line">      data.append([Standardize(x).reshape((1,-1,D_input)).astype(&quot;float32&quot;),</span><br><span class="line">                   Standardize(y).astype(&quot;float32&quot;)])</span><br><span class="line">  return data</span><br><span class="line"># 处理数据</span><br><span class="line">data&#x3D;data_prer(mfc, art)</span><br><span class="line"># 分训练集与验证集</span><br><span class="line">train&#x3D;data[int(totalsamples*vali_size):]</span><br><span class="line">test&#x3D;data[:int(totalsamples*vali_size)]</span><br></pre></td></tr></table></figure></p>
<p>示意图：1，2，3，4，5表示list中的每个元素，而每个元素又是一个长度为2的list。<br><img src="https://picb.zhimg.com/80/v2-2ffadd794aef7201d3a1a2e598a490ce_720w.jpg" alt></p>
<p>解释：比如全部数据有100个序列，如果设定每个input的形状就是[1, n_steps, D_input]，那么处理后的list的长度就是100，这样的数据使用的是SGD的更新方式。而如果想要使用mini-batch GD，将batch size(也就是n_samples)的个数为2，那么处理后的list的长度就会是50，每次网络训练时就会同时计算2个样本的梯度并用均值来更新权重。 因为每句语音数据的时间长短都不相同，如果使用3维tensor，需要大量的zero padding，所以将n_samples设成1。但是这样处理的缺点是：只能使用SGD，无法使用mini-batch GD。如果想使用mini-batch GD，需要几个n_steps长度相同的样本并在一起形成3维tensor（不等长时需要zero padding，如下图）。</p>
<p>演示图：v表示一个维度为39的向量，序列1的n_steps的长度为3，序列2的为7，如果想把这三个序列并成3维tensor，就需要选择最大的长度作为n_steps的长度，将不足该长度的序列补零（都是0的39维的向量）。最后会形成shape为[3,7,39]的一个3维tensor。<br><img src="https://picb.zhimg.com/80/v2-918f052df1c52710ee2d26ffe5af441a_720w.jpg" alt></p>
<h2 id="权重初始化方法"><a href="#权重初始化方法" class="headerlink" title="权重初始化方法"></a>权重初始化方法</h2><p>目的：合理的初始化权重，可以降低网络在学习时卡在鞍点或极小值的损害，增加学习速度和效果<br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">def weight_init(shape):</span><br><span class="line">  initial &#x3D; tf.random_uniform(shape,</span><br><span class="line">  minval&#x3D;-np.sqrt(5)*np.sqrt(1.0&#x2F;shape[0]), </span><br><span class="line">  maxval&#x3D;np.sqrt(5)*np.sqrt(1.0&#x2F;shape[0])</span><br><span class="line">  )</span><br><span class="line">  return tf.Variable(initial,trainable&#x3D;True)</span><br><span class="line"># 全部初始化成0</span><br><span class="line">def zero_init(shape):</span><br><span class="line">  initial &#x3D; tf.Variable(tf.zeros(shape))</span><br><span class="line">  return tf.Variable(initial,trainable&#x3D;True)</span><br><span class="line"># 正交矩阵初始化</span><br><span class="line">def orthogonal_initializer(shape,scale &#x3D; 1.0):</span><br><span class="line">  #https:&#x2F;&#x2F;github.com&#x2F;Lasagne&#x2F;Lasagne&#x2F;blob&#x2F;master&#x2F;lasagne&#x2F;init.py</span><br><span class="line">  scale &#x3D; 1.0</span><br><span class="line">  flat_shape &#x3D; (shape[0], np.prod(shape[1:]))</span><br><span class="line">  a &#x3D; np.random.normal(0.0, 1.0, flat_shape)</span><br><span class="line">  u, _, v &#x3D; np.linalg.svd(a, full_matrices&#x3D;False)</span><br><span class="line">  q &#x3D; u if u.shape &#x3D;&#x3D; flat_shape else v</span><br><span class="line">  q &#x3D; q.reshape(shape) #this needs to be corrected to float32</span><br><span class="line">  return tf.Variable(scale * q[:shape[0], :shape[1]],trainable&#x3D;True, dtype&#x3D;tf.float32)</span><br><span class="line">def bias_init(shape):</span><br><span class="line">  initial &#x3D; tf.constant(0.01, shape&#x3D;shape)</span><br><span class="line">  return tf.Variable(initial)</span><br><span class="line"># 洗牌</span><br><span class="line">def shufflelists(data):</span><br><span class="line">  ri&#x3D;np.random.permutation(len(data))</span><br><span class="line">  data&#x3D;[data[i] for i in ri]</span><br><span class="line">  return data</span><br></pre></td></tr></table></figure></p>
<p>解释：其中shufflelists是用于洗牌重新排序list的。正交矩阵初始化是有利于gated_rnn的学习的方法。</p>
<h2 id="定义LSTM类"><a href="#定义LSTM类" class="headerlink" title="定义LSTM类"></a>定义LSTM类</h2><p>属性：使用class类来定义是因为LSTM中有大量的参数，定义成属性方便管理。<br>代码：在init中就将所有需要学习的权重全部定义成属性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">class LSTMcell(object):</span><br><span class="line">  def __init__(self, incoming, D_input, D_cell, initializer, f_bias&#x3D;1.0):</span><br><span class="line"></span><br><span class="line">      # var</span><br><span class="line">      # incoming是用来接收输入数据的，其形状为[n_samples, n_steps, D_input]</span><br><span class="line">      self.incoming &#x3D; incoming</span><br><span class="line">      # 输入的维度</span><br><span class="line">      self.D_input &#x3D; D_input</span><br><span class="line">      # LSTM的hidden state的维度，同时也是memory cell的维度</span><br><span class="line">      self.D_cell &#x3D; D_cell</span><br><span class="line">      # parameters</span><br><span class="line">        # 输入门的 三个参数</span><br><span class="line">        # igate &#x3D; W_xi.* x + W_hi.* h + b_i</span><br><span class="line">      self.W_xi &#x3D; initializer([self.D_input, self.D_cell])</span><br><span class="line">      self.W_hi &#x3D; initializer([self.D_cell, self.D_cell])</span><br><span class="line">      self.b_i  &#x3D; tf.Variable(tf.zeros([self.D_cell])) </span><br><span class="line">        # 遗忘门的 三个参数 </span><br><span class="line">        # fgate &#x3D; W_xf.* x + W_hf.* h + b_f</span><br><span class="line">      self.W_xf &#x3D; initializer([self.D_input, self.D_cell])</span><br><span class="line">      self.W_hf &#x3D; initializer([self.D_cell, self.D_cell])</span><br><span class="line">      self.b_f  &#x3D; tf.Variable(tf.constant(f_bias, shape&#x3D;[self.D_cell])) </span><br><span class="line">        # 输出门的 三个参数</span><br><span class="line">        # ogate &#x3D; W_xo.* x + W_ho.* h + b_o</span><br><span class="line">      self.W_xo &#x3D; initializer([self.D_input, self.D_cell])</span><br><span class="line">      self.W_ho &#x3D; initializer([self.D_cell, self.D_cell])</span><br><span class="line">      self.b_o  &#x3D; tf.Variable(tf.zeros([self.D_cell])) </span><br><span class="line">        # 计算新信息的三个参数</span><br><span class="line">        # cell &#x3D; W_xc.* x + W_hc.* h + b_c</span><br><span class="line">      self.W_xc &#x3D; initializer([self.D_input, self.D_cell])</span><br><span class="line">      self.W_hc &#x3D; initializer([self.D_cell, self.D_cell])</span><br><span class="line">      self.b_c  &#x3D; tf.Variable(tf.zeros([self.D_cell]))  </span><br><span class="line"></span><br><span class="line">      # 最初时的hidden state和memory cell的值，二者的形状都是[n_samples, D_cell]</span><br><span class="line">      # 如果没有特殊指定，这里直接设成全部为0</span><br><span class="line">      init_for_both &#x3D; tf.matmul(self.incoming[:,0,:], tf.zeros([self.D_input, self.D_cell]))</span><br><span class="line">      self.hid_init &#x3D; init_for_both</span><br><span class="line">      self.cell_init &#x3D; init_for_both</span><br><span class="line">      # 所以要将hidden state和memory并在一起。</span><br><span class="line">      self.previous_h_c_tuple &#x3D; tf.stack([self.hid_init, self.cell_init])</span><br><span class="line">      # 需要将数据由[n_samples, n_steps, D_cell]的形状变成[n_steps, n_samples, D_cell]的形状</span><br><span class="line">      self.incoming &#x3D; tf.transpose(self.incoming, perm&#x3D;[1,0,2])</span><br></pre></td></tr></table></figure></p>
<p>解释：将hidden state和memory并在一起，以及将输入的形状变成[n_steps, n_samples, D_cell]是为了满足tensorflow中的scan的特点，后面会提到。<br>每步计算方法：定义一个function，用于制定每一个step的计算。<br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">def one_step(self, previous_h_c_tuple, current_x):</span><br><span class="line"></span><br><span class="line">    # 再将hidden state和memory cell拆分开</span><br><span class="line">    prev_h, prev_c &#x3D; tf.unstack(previous_h_c_tuple)</span><br><span class="line">    # 这时，current_x是当前的输入，</span><br><span class="line">    # prev_h是上一个时刻的hidden state</span><br><span class="line">    # prev_c是上一个时刻的memory cell</span><br><span class="line"></span><br><span class="line">    # 计算输入门</span><br><span class="line">    i &#x3D; tf.sigmoid(</span><br><span class="line">        tf.matmul(current_x, self.W_xi) + </span><br><span class="line">        tf.matmul(prev_h, self.W_hi) + </span><br><span class="line">        self.b_i)</span><br><span class="line">    # 计算遗忘门</span><br><span class="line">    f &#x3D; tf.sigmoid(</span><br><span class="line">        tf.matmul(current_x, self.W_xf) + </span><br><span class="line">        tf.matmul(prev_h, self.W_hf) + </span><br><span class="line">        self.b_f)</span><br><span class="line">    # 计算输出门</span><br><span class="line">    o &#x3D; tf.sigmoid(</span><br><span class="line">        tf.matmul(current_x, self.W_xo) + </span><br><span class="line">        tf.matmul(prev_h, self.W_ho) + </span><br><span class="line">        self.b_o)</span><br><span class="line">    # 计算新的数据来源</span><br><span class="line">    c &#x3D; tf.tanh(</span><br><span class="line">        tf.matmul(current_x, self.W_xc) + </span><br><span class="line">        tf.matmul(prev_h, self.W_hc) + </span><br><span class="line">        self.b_c)</span><br><span class="line">    # 计算当前时刻的memory cell </span><br><span class="line">    current_c &#x3D; f*prev_c + i*c</span><br><span class="line">    # 计算当前时刻的hidden state</span><br><span class="line">    current_h &#x3D; o*tf.tanh(current_c)</span><br><span class="line">    # 再次将当前的hidden state和memory cell并在一起返回</span><br><span class="line">    return tf.stack([current_h, current_c])</span><br></pre></td></tr></table></figure></p>
<p>解释：将上一时刻的hidden state和memory拆开，用于计算后，所出现的新的当前时刻的hidden state和memory会再次并在一起作为该function的返回值，同样是为了满足scan的特点。定义该function后，LSTM就已经完成了。one_step方法会使用LSTM类中所定义的parameters与当前时刻的输入和上一时刻的hidden state与memory cell计算当前时刻的hidden state和memory cell。<br>scan：使用scan逐次迭代计算所有timesteps，最后得出所有的hidden states进行后续的处理。<br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def all_steps(self):</span><br><span class="line">    # 输出形状 : [n_steps, n_sample, D_cell]</span><br><span class="line">    hstates &#x3D; tf.scan(fn &#x3D; self.one_step,</span><br><span class="line">                      elems &#x3D; self.incoming, #形状为[n_steps, n_sample, D_input]</span><br><span class="line">                      initializer &#x3D; self.previous_h_c_tuple,</span><br><span class="line">                      name &#x3D; &#39;hstates&#39;)[:,0,:,:] </span><br><span class="line">    return hstates</span><br></pre></td></tr></table></figure></p>
<p>解释：scan接受的fn, elems, initializer有以下要求：<br>fn：第一个输入是上一时刻的输出（需要与fn的返回值保持一致），第二个输入是当前时刻的输入。<br>elems：scan方法每一步都会沿着所要处理的tensor的第一个维进行一次一次取值，所以要将数据由[n_samples, n_steps, D_cell]的形状变成[n_steps, n_samples, D_cell]的形状。<br>initializer：初始值，需要与fn的第一个输入和返回值保持一致。<br>scan的返回值在上例中是[n_steps, 2, n_samples, D_cell]，其中第二个维度的2是由hidden state和memory cell组成的。</p>
<h2 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h2><p>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">D_input &#x3D; 39</span><br><span class="line">D_label &#x3D; 24</span><br><span class="line">learning_rate &#x3D; 7e-5</span><br><span class="line">num_units&#x3D;1024</span><br><span class="line"># 样本的输入和标签</span><br><span class="line">inputs &#x3D; tf.placeholder(tf.float32, [None, None, D_input], name&#x3D;&quot;inputs&quot;)</span><br><span class="line">labels &#x3D; tf.placeholder(tf.float32, [None, D_label], name&#x3D;&quot;labels&quot;)</span><br><span class="line"># 实例LSTM类</span><br><span class="line">rnn_cell &#x3D; LSTMcell(inputs, D_input, num_units, orthogonal_initializer)</span><br><span class="line"># 调用scan计算所有hidden states</span><br><span class="line">rnn0 &#x3D; rnn_cell.all_steps()</span><br><span class="line"># 将3维tensor [n_steps, n_samples, D_cell]转成 矩阵[n_steps*n_samples, D_cell]</span><br><span class="line"># 用于计算outputs</span><br><span class="line">rnn &#x3D; tf.reshape(rnn0, [-1, num_units])</span><br><span class="line"># 输出层的学习参数</span><br><span class="line">W &#x3D; weight_init([num_units, D_label])</span><br><span class="line">b &#x3D; bias_init([D_label])</span><br><span class="line">output &#x3D; tf.matmul(rnn, W) + b</span><br><span class="line"># 损失</span><br><span class="line">loss&#x3D;tf.reduce_mean((output-labels)**2)</span><br><span class="line"># 训练所需</span><br><span class="line">train_step &#x3D; tf.train.AdamOptimizer(learning_rate).minimize(loss)</span><br></pre></td></tr></table></figure></p>
<p>解释：以hard coding的方式直接构建一个网络，输入是39维，第一个隐藏层也就是RNN-LSTM，1024维，而输出层又将1024维的LSTM的输出变换到24维与label对应。<br>注： 这个网络并不仅仅取序列的最后一个值，而是要用所有timestep的值与实际轨迹进行比较计算loss</p>
<h2 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h2><p>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 建立session并实际初始化所有参数</span><br><span class="line">sess &#x3D; tf.InteractiveSession()</span><br><span class="line">tf.global_variables_initializer().run()</span><br><span class="line"># 训练并记录</span><br><span class="line">def train_epoch(EPOCH):</span><br><span class="line">  for k in range(EPOCH):</span><br><span class="line">      train0&#x3D;shufflelists(train)</span><br><span class="line">      for i in range(len(train)):</span><br><span class="line">          sess.run(train_step,feed_dict&#x3D;&#123;inputs:train0[i][0],labels:train0[i][1]&#125;)</span><br><span class="line">      tl&#x3D;0</span><br><span class="line">      dl&#x3D;0</span><br><span class="line">      for i in range(len(test)):</span><br><span class="line">          dl+&#x3D;sess.run(loss,feed_dict&#x3D;&#123;inputs:test[i][0],labels:test[i][1]&#125;)</span><br><span class="line">      for i in range(len(train)):</span><br><span class="line">          tl+&#x3D;sess.run(loss,feed_dict&#x3D;&#123;inputs:train[i][0],labels:train[i][1]&#125;)</span><br><span class="line">      print(k,&#39;train:&#39;,round(tl&#x2F;83,3),&#39;test:&#39;,round(dl&#x2F;20,3))</span><br><span class="line">t0 &#x3D; time.time()</span><br><span class="line">train_epoch(10)</span><br><span class="line">t1 &#x3D; time.time()</span><br><span class="line">print(&quot; %f seconds&quot; % round((t1 - t0),2))</span><br><span class="line"># 训练10次后的输出和时间</span><br><span class="line">(0, &#39;train:&#39;, 0.662, &#39;test:&#39;, 0.691)</span><br><span class="line">(1, &#39;train:&#39;, 0.558, &#39;test:&#39;, 0.614)</span><br><span class="line">(2, &#39;train:&#39;, 0.473, &#39;test:&#39;, 0.557)</span><br><span class="line">(3, &#39;train:&#39;, 0.417, &#39;test:&#39;, 0.53)</span><br><span class="line">(4, &#39;train:&#39;, 0.361, &#39;test:&#39;, 0.504)</span><br><span class="line">(5, &#39;train:&#39;, 0.327, &#39;test:&#39;, 0.494)</span><br><span class="line">(6, &#39;train:&#39;, 0.294, &#39;test:&#39;, 0.476)</span><br><span class="line">(7, &#39;train:&#39;, 0.269, &#39;test:&#39;, 0.468)</span><br><span class="line">(8, &#39;train:&#39;, 0.244, &#39;test:&#39;, 0.452)</span><br><span class="line">(9, &#39;train:&#39;, 0.226, &#39;test:&#39;, 0.453)</span><br><span class="line">563.110000 seconds</span><br></pre></td></tr></table></figure></p>
<p>解释：由于上文的LSTM是非常直接的编写方式，并不高效，在实际使用中会花费较长时间。</p>
<h2 id="预测效果"><a href="#预测效果" class="headerlink" title="预测效果"></a>预测效果</h2><p>代码：pY=sess.run(output,feed_dict={inputs:test[10][0]})<br>plt.plot(pY[:,8])<br>plt.plot(test[10][1][:,8])<br>plt.title(‘test’)<br>plt.legend([‘predicted’,’real’])<br>解释：plot出一个样本中的维度的预测效果与真是轨迹进行对比<br>效果图：<br><img src="https://picb.zhimg.com/80/v2-6f015b68033e1158702857617109679d_720w.jpg" alt></p>
<h2 id="总结说明"><a href="#总结说明" class="headerlink" title="总结说明"></a>总结说明</h2><p>该文是尽可能只展示LSTM最核心的部分（只训练了10次，有兴趣的朋友可以自己多训练几次），帮助大家理解其工作方式而已，完整代码可以从我的github中LSTM_lV1中找到。<br>该LSTM由于运行效率并不高，下一篇会稍微进行改动加快运行速度，并整理结构方便使用GRU以及多层RNN的堆叠以及双向RNN，同时加入其他功能。</p>
<h1 id="YJango的循环神经网络——双向LSTM-amp-GRU"><a href="#YJango的循环神经网络——双向LSTM-amp-GRU" class="headerlink" title="YJango的循环神经网络——双向LSTM&amp;GRU"></a><span id="header12">YJango的循环神经网络——双向LSTM&amp;GRU</span></h1><p><img src="https://pic2.zhimg.com/v2-39576faf84513b6f607ee5bbbec2f175_1440w.jpg?source=172ae18b" alt></p>
<p>介绍<br>双向LSTM和GRU用scan的方式实现</p>
<p>任务描述：<br>本次的代码LV2是紧接着代码LV1的升级版，所学习的内容与先前的一样，不同的是：</p>
<p>简单梳理调整了代码结构，方便使用<br>将所有gate的计算并在一个大矩阵乘法下完成提高GPU的利用率<br>除了LSTM（Long-Short Term Memory）以外的cell，还提供了GRU（gate recurrent unit） cell模块<br>双向RNN（可选择任意cell组合）<br>该代码可被用于练习结构改造或实际建模任务</p>
<h2 id="定义LSTMcell类"><a href="#定义LSTMcell类" class="headerlink" title="定义LSTMcell类"></a>定义LSTMcell类</h2><p>目的：LSTMcell包含所有学习所需要的parameters以及每一时刻所要运行的step方法<br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">class LSTMcell(object):</span><br><span class="line">  def __init__(self, incoming, D_input, D_cell, initializer,</span><br><span class="line">               f_bias&#x3D;1.0, L2&#x3D;False, h_act&#x3D;tf.tanh, </span><br><span class="line">               init_h&#x3D;None, init_c&#x3D;None):</span><br><span class="line">      # 属性</span><br><span class="line">      self.incoming &#x3D; incoming # 输入数据</span><br><span class="line">      self.D_input &#x3D; D_input</span><br><span class="line">      self.D_cell &#x3D; D_cell</span><br><span class="line">      self.initializer &#x3D; initializer # 初始化方法</span><br><span class="line">      self.f_bias &#x3D; f_bias # 遗忘门的初始偏移量</span><br><span class="line">      self.h_act &#x3D; h_act # 这里可以选择LSTM的hidden state的激活函数</span><br><span class="line">      self.type &#x3D; &#39;lstm&#39; # 区分gru</span><br><span class="line">      # 如果没有提供最初的hidden state和memory cell，会全部初始为0</span><br><span class="line">      if init_h is None and init_c is None:</span><br><span class="line">          # If init_h and init_c are not provided, initialize them</span><br><span class="line">          # the shape of init_h and init_c is [n_samples, D_cell]</span><br><span class="line">          self.init_h &#x3D; tf.matmul(self.incoming[0,:,:], tf.zeros([self.D_input, self.D_cell]))</span><br><span class="line">          self.init_c &#x3D; self.init_h</span><br><span class="line">          self.previous &#x3D; tf.stack([self.init_h, self.init_c])</span><br><span class="line">      # LSTM所有需要学习的参数</span><br><span class="line">      # 每个都是[W_x, W_h, b_f]的tuple</span><br><span class="line">      self.igate &#x3D; self.Gate()</span><br><span class="line">      self.fgate &#x3D; self.Gate(bias &#x3D; f_bias)</span><br><span class="line">      self.ogate &#x3D; self.Gate()</span><br><span class="line">      self.cell &#x3D; self.Gate()</span><br><span class="line">      # 因为所有的gate都会乘以当前的输入和上一时刻的hidden state</span><br><span class="line">      # 将矩阵concat在一起，计算后再逐一分离，加快运行速度</span><br><span class="line">      # W_x的形状是[D_input, 4*D_cell]</span><br><span class="line">      self.W_x &#x3D; tf.concat(values&#x3D;[self.igate[0], self.fgate[0], self.ogate[0], self.cell[0]], axis&#x3D;1)</span><br><span class="line">      self.W_h &#x3D; tf.concat(values&#x3D;[self.igate[1], self.fgate[1], self.ogate[1], self.cell[1]], axis&#x3D;1)</span><br><span class="line">      self.b &#x3D; tf.concat(values&#x3D;[self.igate[2], self.fgate[2], self.ogate[2], self.cell[2]], axis&#x3D;0)</span><br><span class="line">      # 对LSTM的权重进行L2 regularization</span><br><span class="line">      if L2:</span><br><span class="line">          self.L2_loss &#x3D; tf.nn.l2_loss(self.W_x) + tf.nn.l2_loss(self.W_h)</span><br><span class="line">  # 初始化gate的函数        </span><br><span class="line">  def Gate(self, bias &#x3D; 0.001):</span><br><span class="line">      # Since we will use gate multiple times, let&#39;s code a class for reusing</span><br><span class="line">      Wx &#x3D; self.initializer([self.D_input, self.D_cell])</span><br><span class="line">      Wh &#x3D; self.initializer([self.D_cell, self.D_cell])</span><br><span class="line">      b  &#x3D; tf.Variable(tf.constant(bias, shape&#x3D;[self.D_cell]),trainable&#x3D;True) </span><br><span class="line">      return Wx, Wh, b</span><br><span class="line">  # 大矩阵乘法运算完毕后，方便用于分离各个gate</span><br><span class="line">  def Slice_W(self, x, n):</span><br><span class="line">      # split W&#39;s after computing</span><br><span class="line">      return x[:, n*self.D_cell:(n+1)*self.D_cell]  </span><br><span class="line">  # 每个time step需要运行的步骤</span><br><span class="line">  def Step(self, previous_h_c_tuple, current_x):</span><br><span class="line">      # 分离上一时刻的hidden state和memory cell</span><br><span class="line">      prev_h, prev_c &#x3D; tf.unstack(previous_h_c_tuple)</span><br><span class="line">      # 统一在concat成的大矩阵中一次完成所有的gates计算</span><br><span class="line">      gates &#x3D; tf.matmul(current_x, self.W_x) + tf.matmul(prev_h, self.W_h) + self.b</span><br><span class="line">      # 分离输入门</span><br><span class="line">      i &#x3D; tf.sigmoid(self.Slice_W(gates, 0))</span><br><span class="line">      # 分离遗忘门</span><br><span class="line">      f &#x3D; tf.sigmoid(self.Slice_W(gates, 1))</span><br><span class="line">      # 分离输出门</span><br><span class="line">      o &#x3D; tf.sigmoid(self.Slice_W(gates, 2))</span><br><span class="line">      # 分离新的更新信息</span><br><span class="line">      c &#x3D; tf.tanh(self.Slice_W(gates, 3))</span><br><span class="line">      # 利用gates进行当前memory cell的计算</span><br><span class="line">      current_c &#x3D; f*prev_c + i*c</span><br><span class="line">      # 利用gates进行当前hidden state的计算</span><br><span class="line">      current_h &#x3D; o*self.h_act(current_c)</span><br><span class="line">      return tf.stack([current_h, current_c])</span><br></pre></td></tr></table></figure></p>
<h2 id="定义GRUcell类"><a href="#定义GRUcell类" class="headerlink" title="定义GRUcell类"></a>定义GRUcell类</h2><p>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">class GRUcell(object):</span><br><span class="line">  def __init__(self, incoming, D_input, D_cell, initializer, L2&#x3D;False, init_h&#x3D;None):</span><br><span class="line">      # 属性</span><br><span class="line">      self.incoming &#x3D; incoming</span><br><span class="line">      self.D_input &#x3D; D_input</span><br><span class="line">      self.D_cell &#x3D; D_cell</span><br><span class="line">      self.initializer &#x3D; initializer</span><br><span class="line">      self.type &#x3D; &#39;gru&#39;</span><br><span class="line">      # 如果没有提供最初的hidden state，会初始为0</span><br><span class="line">      # 注意GRU中并没有LSTM中的memory cell，其功能是由hidden state完成的</span><br><span class="line">      if init_h is None:</span><br><span class="line">          # If init_h is not provided, initialize it</span><br><span class="line">          # the shape of init_h is [n_samples, D_cell]</span><br><span class="line">          self.init_h &#x3D; tf.matmul(self.incoming[0,:,:], tf.zeros([self.D_input, self.D_cell]))</span><br><span class="line">          self.previous &#x3D; self.init_h</span><br><span class="line">      # 如果没有提供最初的hidden state，会初始为0</span><br><span class="line">      # 注意GRU中并没有LSTM中的memory cell，其功能是由hidden state完成的</span><br><span class="line">      self.rgate &#x3D; self.Gate()</span><br><span class="line">      self.ugate &#x3D; self.Gate()</span><br><span class="line">      self.cell &#x3D; self.Gate()</span><br><span class="line">      # 因为所有的gate都会乘以当前的输入和上一时刻的hidden state</span><br><span class="line">      # 将矩阵concat在一起，计算后再逐一分离，加快运行速度</span><br><span class="line">      # W_x的形状是[D_input, 3*D_cell]</span><br><span class="line">      self.W_x &#x3D; tf.concat(values&#x3D;[self.rgate[0], self.ugate[0], self.cell[0]], axis&#x3D;1)</span><br><span class="line">      self.W_h &#x3D; tf.concat(values&#x3D;[self.rgate[1], self.ugate[1], self.cell[1]], axis&#x3D;1)</span><br><span class="line">      self.b &#x3D; tf.concat(values&#x3D;[self.rgate[2], self.ugate[2], self.cell[2]], axis&#x3D;0)</span><br><span class="line">      # 对LSTM的权重进行L2 regularization</span><br><span class="line">      if L2:</span><br><span class="line">          self.L2_loss &#x3D; tf.nn.l2_loss(self.W_x) + tf.nn.l2_loss(self.W_h)</span><br><span class="line">  # 初始化gate的函数   </span><br><span class="line">  def Gate(self, bias &#x3D; 0.001):</span><br><span class="line">      # Since we will use gate multiple times, let&#39;s code a class for reusing</span><br><span class="line">      Wx &#x3D; self.initializer([self.D_input, self.D_cell])</span><br><span class="line">      Wh &#x3D; self.initializer([self.D_cell, self.D_cell])</span><br><span class="line">      b  &#x3D; tf.Variable(tf.constant(bias, shape&#x3D;[self.D_cell]),trainable&#x3D;True) </span><br><span class="line">      return Wx, Wh, b</span><br><span class="line">  # 大矩阵乘法运算完毕后，方便用于分离各个gate</span><br><span class="line">  def Slice_W(self, x, n):</span><br><span class="line">      # split W&#39;s after computing</span><br><span class="line">      return x[:, n*self.D_cell:(n+1)*self.D_cell]  </span><br><span class="line">  # 每个time step需要运行的步骤</span><br><span class="line">  def Step(self, prev_h, current_x):</span><br><span class="line">      # 分两次，统一在concat成的大矩阵中完成gates所需要的计算</span><br><span class="line">      Wx &#x3D; tf.matmul(current_x, self.W_x) + self.b</span><br><span class="line">      Wh &#x3D; tf.matmul(prev_h, self.W_h)</span><br><span class="line">      # 分离和组合reset gate</span><br><span class="line">      r &#x3D; tf.sigmoid(self.Slice_W(Wx, 0) + self.Slice_W(Wh, 0))</span><br><span class="line">      # 分离和组合update gate</span><br><span class="line">      u &#x3D; tf.sigmoid(self.Slice_W(Wx, 1) + self.Slice_W(Wh, 1))</span><br><span class="line">      # 分离和组合新的更新信息</span><br><span class="line">      # 注意GRU中，在这一步就已经有reset gate的干涉了</span><br><span class="line">      c &#x3D; tf.tanh(self.Slice_W(Wx, 2) + r*self.Slice_W(Wh, 2))</span><br><span class="line">      # 计算当前hidden state，GRU将LSTM中的input gate和output gate的合设成1，</span><br><span class="line">      # 用update gate完成两者的工作</span><br><span class="line">      current_h &#x3D; (1-u)*prev_h + u*c</span><br><span class="line">      return current_h</span><br></pre></td></tr></table></figure></p>
<h2 id="定义RNN函数"><a href="#定义RNN函数" class="headerlink" title="定义RNN函数"></a>定义RNN函数</h2><p>目的：用于接受cell的实例，并用scan计算所有time steps的hidden states<br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">def RNN(cell, cell_b&#x3D;None, merge&#x3D;&#39;sum&#39;):</span><br><span class="line">  &quot;&quot;&quot;</span><br><span class="line">  该函数接受的数据需要是[n_steps, n_sample, D_output],</span><br><span class="line">  函数的输出也是[n_steps, n_sample, D_output].</span><br><span class="line">  如果输入数据不是[n_steps, n_sample, D_input],</span><br><span class="line">  使用&#39;inputs_T &#x3D; tf.transpose(inputs, perm&#x3D;[1,0,2])&#39;.</span><br><span class="line">  &quot;&quot;&quot;</span><br><span class="line">  # 正向rnn的计算</span><br><span class="line">  hstates &#x3D; tf.scan(fn &#x3D; cell.Step,</span><br><span class="line">                  elems &#x3D; cell.incoming,</span><br><span class="line">                  initializer &#x3D; cell.previous,</span><br><span class="line">                  name &#x3D; &#39;hstates&#39;)</span><br><span class="line">  # lstm的step经过scan计算后会返回4维tensor，</span><br><span class="line">  # 其中[:,0,:,:]表示hidden state，</span><br><span class="line">  # [:,1,:,:]表示memory cell，这里只需要hidden state</span><br><span class="line">  if cell.type &#x3D;&#x3D; &#39;lstm&#39;:</span><br><span class="line">      hstates &#x3D; hstates[:,0,:,:]</span><br><span class="line">  # 如果提供了第二个cell，将进行反向rnn的计算</span><br><span class="line">  if cell_b is not None:</span><br><span class="line">      # 将输入数据变为反向</span><br><span class="line">      incoming_b &#x3D; tf.reverse(cell.incoming, axis&#x3D;[0])</span><br><span class="line">      # scan计算反向rnn</span><br><span class="line">      b_hstates_rev &#x3D; tf.scan(fn &#x3D; cell_b.Step,</span><br><span class="line">                  elems &#x3D; incoming_b,</span><br><span class="line">                  initializer &#x3D; cell_b.previous, # 每个cell自带的初始值</span><br><span class="line">                  name &#x3D; &#39;b_hstates&#39;)</span><br><span class="line">      if cell_b.type &#x3D;&#x3D; &#39;lstm&#39;:</span><br><span class="line">          b_hstates_rev &#x3D; b_hstates_rev[:,0,:,:]</span><br><span class="line">      # 用scan计算好的反向rnn需要再反向回来与正向rnn所计算的数据进行合并</span><br><span class="line">      b_hstates &#x3D; tf.reverse(b_hstates_rev, axis&#x3D;[0])</span><br><span class="line">      # 合并方式可以选择直接相加，也可以选择concat</span><br><span class="line">      if merge &#x3D;&#x3D; &#39;sum&#39;:</span><br><span class="line">          hstates &#x3D; hstates + b_hstates</span><br><span class="line">      else:</span><br><span class="line">          hstates &#x3D; tf.concat(values&#x3D;[hstates, b_hstates], axis&#x3D;2)</span><br><span class="line">  return hstates</span><br></pre></td></tr></table></figure></p>
<p>解释：可以使用两个GRU cell进行双向rnn的就算，也可以混搭网络构建<br>目的：这里演示的是两层relu feedforward layers后，接一层双向GRU-RNN，最后再接两层relu feedforward layers。<br>效果图：<br><img src="https://pic2.zhimg.com/80/v2-338d014ff709c0f35ece69610a9b31fb_720w.jpg" alt><br>代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">D_input &#x3D; 39</span><br><span class="line">D_label &#x3D; 24</span><br><span class="line">learning_rate &#x3D; 7e-5</span><br><span class="line">num_units&#x3D;1024</span><br><span class="line">L2_penalty &#x3D; 1e-4</span><br><span class="line">inputs &#x3D; tf.placeholder(tf.float32, [None, None, D_input], name&#x3D;&quot;inputs&quot;)</span><br><span class="line">labels &#x3D; tf.placeholder(tf.float32, [None, D_label], name&#x3D;&quot;labels&quot;)</span><br><span class="line"># 保持多少节点不被dropout掉</span><br><span class="line">drop_keep_rate &#x3D; tf.placeholder(tf.float32, name&#x3D;&quot;dropout_keep&quot;)</span><br><span class="line"># 用于reshape</span><br><span class="line">n_steps &#x3D; tf.shape(inputs)[1]</span><br><span class="line">n_samples &#x3D; tf.shape(inputs)[0]</span><br><span class="line"># 将输入数据从[n_samples, n_steps, D_input]，reshape成[n_samples*n_steps, D_input]</span><br><span class="line"># 用于feedforward layer的使用</span><br><span class="line">re1 &#x3D; tf.reshape(inputs, [-1, D_input])</span><br><span class="line"># 第一层</span><br><span class="line">Wf0 &#x3D; weight_init([D_input, num_units])</span><br><span class="line">bf0 &#x3D; bias_init([num_units])</span><br><span class="line">h1 &#x3D; tf.nn.relu(tf.matmul(re1, Wf0) + bf0)</span><br><span class="line"># dropout</span><br><span class="line">h1d &#x3D; tf.nn.dropout(h1, drop_keep_rate)</span><br><span class="line"># 第二层</span><br><span class="line">Wf1 &#x3D; weight_init([num_units, num_units])</span><br><span class="line">bf1 &#x3D; bias_init([num_units])</span><br><span class="line">h2 &#x3D; tf.nn.relu(tf.matmul(h1d, Wf1) + bf1)</span><br><span class="line"># dropout</span><br><span class="line">h2d &#x3D; tf.nn.dropout(h2, drop_keep_rate)</span><br><span class="line"># 将输入数据从[n_samples*n_steps, D_input]，reshape成[n_samples, n_steps, D_input]</span><br><span class="line"># 用于双向rnn layer的使用</span><br><span class="line">re2 &#x3D; tf.reshape(h2d, [n_samples,n_steps, num_units])</span><br><span class="line"># 将数据从[n_samples, n_steps, D_input]，转换成[n_steps, n_samples, D_input]</span><br><span class="line">inputs_T &#x3D; tf.transpose(re2, perm&#x3D;[1,0,2])</span><br><span class="line"># 实例rnn的正向cell，这里使用的是GRUcell</span><br><span class="line">rnn_fcell &#x3D; GRUcell(inputs_T, num_units, num_units, orthogonal_initializer)</span><br><span class="line"># 实例rnn的反向cell</span><br><span class="line">rnn_bcell &#x3D; GRUcell(inputs_T, num_units, num_units, orthogonal_initializer)</span><br><span class="line"># 将两个cell送给scan里计算，并使用sum的方式合并两个方向所计算的数据</span><br><span class="line">rnn0 &#x3D; RNN(rnn_fcell, rnn_bcell)</span><br><span class="line"># 将输入数据从[n_samples, n_steps, D_input]，reshape成[n_samples*n_steps, D_input]</span><br><span class="line"># 用于feedforward layer的使用</span><br><span class="line">rnn1 &#x3D; tf.reshape(rnn0, [-1, num_units])</span><br><span class="line"># dropout</span><br><span class="line">rnn2 &#x3D; tf.nn.dropout(rnn1, drop_keep_rate)</span><br><span class="line"># 第三层</span><br><span class="line">W0 &#x3D; weight_init([num_units, num_units])</span><br><span class="line">b0 &#x3D; bias_init([num_units])</span><br><span class="line">rnn3 &#x3D; tf.nn.relu(tf.matmul(rnn2, W0) + b0)</span><br><span class="line">rnn4 &#x3D; tf.nn.dropout(rnn3, drop_keep_rate)</span><br><span class="line"># 第四层</span><br><span class="line">W1 &#x3D; weight_init([num_units, num_units])</span><br><span class="line">b1 &#x3D; bias_init([num_units])</span><br><span class="line">rnn5 &#x3D; tf.nn.relu(tf.matmul(rnn4, W1) + b1)</span><br><span class="line">rnn6 &#x3D; tf.nn.dropout(rnn5, drop_keep_rate)</span><br><span class="line"># 输出层</span><br><span class="line">W &#x3D; weight_init([num_units, D_label])</span><br><span class="line">b &#x3D; bias_init([D_label])</span><br><span class="line">output &#x3D; tf.matmul(rnn6, W) + b</span><br><span class="line"># loss</span><br><span class="line">loss&#x3D;tf.reduce_mean((output-labels)**2)</span><br><span class="line">L2_total &#x3D; tf.nn.l2_loss(Wf0) + tf.nn.l2_loss(Wf1)+ tf.nn.l2_loss(W0) + tf.nn.l2_loss(W1) + tf.nn.l2_loss(W)#+ rnn_fcell.L2_loss + rnn_bcell.L2_loss </span><br><span class="line"># 训练所需的</span><br><span class="line">train_step &#x3D; tf.train.AdamOptimizer(learning_rate).minimize(loss + L2_penalty*L2_total)</span><br></pre></td></tr></table></figure></p>
<p>训练<br>剩下的代码就和代码LV1的相同了， 大家可以结合tensorboard来记录和分析所学习的权重矩阵和loss的下降等。使用方式请参考代码演示LV3，也可以和代码演示LV3中的代码结合着使用，根据自己的需要注意reshape和transpose即可。完整代码在我的<a href="https://github.com/YJango/tensorflow_basic_tutorial/" target="_blank" rel="noopener">github</a>上。</p>
<p>效果<br>loss：训练集的loss在0.022，验证集的loss在0.222，比feedforward要好很多<br>效果图：另外预测的轨迹也十分的平滑</p>
<p><img src="https://pic2.zhimg.com/80/v2-8eeb0cba9259ea5d9083bb41dd0651bd_720w.jpg" alt><br><img src="https://pic2.zhimg.com/80/v2-feb75672c765888a371f7decf8ac2f11_720w.jpg" alt><br>其他<br>速度：将所有gates的参数并在一起处理再分离可以节省很多时间，代价自然是更多的memory<br>rnn的dropout：每个gate其实也是一个再cell内部的具有物理意义的神经网络，那么同样也是可以利用dropout来防止gate在拟合物理意义时过拟合。<br>多层rnn：可以rnn层之后以相同的方式再来一层双向或单向rnn，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 第一层双向rnn</span><br><span class="line">rnn_fcell &#x3D; GRUcell(inputs_T, num_units, num_units, orthogonal_initializer)</span><br><span class="line">rnn_bcell &#x3D; GRUcell(inputs_T, num_units, num_units, orthogonal_initializer)</span><br><span class="line">rnn0 &#x3D; RNN(rnn_fcell, rnn_bcell)</span><br><span class="line"># 第二层双向rnn</span><br><span class="line">rnn_fcell2 &#x3D; GRUcell(inputs_T, num_units, num_units, orthogonal_initializer)</span><br><span class="line">rnn_bcell2 &#x3D; GRUcell(inputs_T, num_units, num_units, orthogonal_initializer)</span><br><span class="line">rnn02 &#x3D; RNN(rnn_fcell2, rnn_bcell2)</span><br><span class="line"># 后续处理</span><br><span class="line">rnn1 &#x3D; tf.reshape(rnn02, [-1, num_units])</span><br></pre></td></tr></table></figure></p>
<h1 id="YJango的卷积神经网络——介绍"><a href="#YJango的卷积神经网络——介绍" class="headerlink" title="YJango的卷积神经网络——介绍"></a><span id="header13">YJango的卷积神经网络——介绍</span></h1><p>如果要提出一个新的神经网络结构，首先就需要引入像循环神经网络中“时间共享”这样的先验知识，降低学习所需要的训练数据需求量。 而卷积神经网络同样也引入了这样的先验知识：“空间共享”。下面就让我们以画面识别作为切入点，看看该先验知识是如何被引入到神经网络中的。</p>
<p>视觉感知<br>一、画面识别是什么任务？</p>
<p>学习知识的第一步就是明确任务，清楚该知识的输入输出。卷积神经网络最初是服务于画面识别的，所以我们先来看看画面识别的实质是什么。</p>
<p>先观看几组动物与人类视觉的差异对比图。</p>
<ol>
<li>苍蝇的视觉和人的视觉的差异<br><img src="https://pic1.zhimg.com/80/v2-55069445ed54ce163b76c611ba26b639_720w.jpg" alt><br><img src="https://pic3.zhimg.com/80/v2-4a0ea7ba42166b62bc4f42e8b150815d_720w.png" alt></li>
<li>蛇的视觉和人的视觉的差异<br><img src="https://pic2.zhimg.com/80/v2-a4d35c245931f264ed9a0716fdf20685_720w.jpg" alt><br><img src="https://pic3.zhimg.com/80/v2-3da84b5b80ba7a0d779284566f80be93_720w.png" alt><br>（更多对比图请参考<a href="http%3A//chuansong.me/n/2656056">链接</a>）</li>
</ol>
<p>通过上面的两组对比图可以知道，即便是相同的图片经过不同的视觉系统，也会得到不同的感知。</p>
<p>这里引出一条知识：生物所看到的景象并非世界的原貌，而是长期进化出来的适合自己生存环境的一种感知方式。 蛇的猎物一般是夜间行动，所以它就进化出了一种可以在夜间也能很好观察的感知系统，感热。</p>
<p>任何视觉系统都是将图像反光与脑中所看到的概念进行关联。<br><img src="https://pic4.zhimg.com/80/v2-2c82abd20c4e7c40f7f13f035b924b0b_720w.png" alt></p>
<p>所以画面识别实际上并非识别这个东西客观上是什么，而是寻找人类的视觉关联方式，并再次应用。 如果我们不是人类，而是蛇类，那么画面识别所寻找的?就和现在的不一样。</p>
<p>画面识别实际上是寻找（学习）人类的视觉关联方式?，并再次应用。<br>二、图片被识别成什么取决于哪些因素？</p>
<p>下面用两张图片来体会识别结果取决于哪些因素。</p>
<ol>
<li>老妇与少女<br><img src="https://pic1.zhimg.com/80/v2-c902a9e33b0322051a5f9165e9439247_720w.jpg" alt><br>请观察上面这张图片，你看到的是老妇还是少女？ 以不同的方式去观察这张图片会得出不同的答案。 图片可以观察成有大鼻子、大眼睛的老妇。也可以被观察成少女，但这时老妇的嘴会被识别成少女脖子上的项链，而老妇的眼睛则被识别为少女的耳朵。</li>
<li>海豚与男女<br><img src="https://pic3.zhimg.com/80/v2-7e5bc60a9e9bd0b597e4b650fecc439e_720w.jpg" alt></li>
</ol>
<p>上面这张图片如果是成人观察，多半看到的会是一对亲热的男女。倘若儿童看到这张图片，看到的则会是一群海豚（男女的轮廓是由海豚构造出的）。所以，识别结果受年龄，文化等因素的影响，换句话说：</p>
<blockquote>
<p>图片被识别成什么不仅仅取决于图片本身，还取决于图片是如何被观察的。</p>
</blockquote>
<p>图像表达<br>我们知道了“画面识别是从大量的(x,y)数据中寻找人类的视觉关联方式?，并再次应用。 其x-是输入，表示所看到的东西y-输出，表示该东西是什么。</p>
<p>在自然界中，x是物体的反光，那么在计算机中，图像又是如何被表达和存储的呢？<br><img src="https://pic2.zhimg.com/v2-d2859e5c486ed704492ab80079e99535_b.jpg" alt></p>
<p>图像在计算机中是一堆按顺序排列的数字，数值为0到255。0表示最暗，255表示最亮。 你可以把这堆数字用一个长长的向量来表示，也就是<a href="https%3A//www.tensorflow.org/get_started/mnist/beginners">tensorflow的mnist教程</a>中784维向量的表示方式。 然而这样会失去平面结构的信息，为保留该结构信息，通常选择矩阵的表示方式：28x28的矩阵。</p>
<p>上图是只有黑白颜色的灰度图，而更普遍的图片表达方式是RGB颜色模型，即红（Red）、绿（Green）、蓝（Blue）三原色的色光以不同的比例相加，以产生多种多样的色光。</p>
<p>这样，RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维张量去理解，其中的每一个矩阵又叫这个图片的一个channel。</p>
<p>在电脑中，一张图片是数字构成的“长方体”。可用 宽width, 高height, 深depth 来描述，如图。<br><img src="https://pic2.zhimg.com/80/v2-0d24890b2e0d73f4ce4ad17ebfb2d0c4_720w.png" alt></p>
<blockquote>
<p>画面识别的输入x是shape为(width, height, depth)的三维张量。</p>
</blockquote>
<p>接下来要考虑的就是该如何处理这样的“数字长方体”。</p>
<p>画面不变性<br>在决定如何处理“数字长方体”之前，需要清楚所建立的网络拥有什么样的特点。 我们知道一个物体不管在画面左侧还是右侧，都会被识别为同一物体，这一特点就是不变性（invariance），如下图所示。<br><img src="https://pic4.zhimg.com/80/v2-b9aed3dd68b9818561faa7d8ed24ea5a_720w.png" alt></p>
<p>我们希望所建立的网络可以尽可能的满足这些不变性特点。</p>
<p>为了理解卷积神经网络对这些不变性特点的贡献，我们将用不具备这些不变性特点的前馈神经网络来进行比较。</p>
<p>图片识别—前馈神经网络</p>
<p>方便起见，我们用depth只有1的灰度图来举例。 想要完成的任务是：在宽长为4x4的图片中识别是否有下图所示的“横折”。 图中，黄色圆点表示值为0的像素，深色圆点表示值为1的像素。 我们知道不管这个横折在图片中的什么位置，都会被认为是相同的横折。<br><img src="https://pic4.zhimg.com/80/v2-18c11c6f485e9f1bbc9a50eb3d248439_720w.png" alt><br>若训练前馈神经网络来完成该任务，那么表达图像的三维张量将会被摊平成一个向量，作为网络的输入，即(width, height, depth)为(4, 4, 1)的图片会被展成维度为16的向量作为网络的输入层。再经过几层不同节点个数的隐藏层，最终输出两个节点，分别表示“有横折的概率”和“没有横折的概率”，如下图所示。<br><img src="https://pic3.zhimg.com/80/v2-2b411af47b1cad7b727bb676c847ce59_720w.png" alt><br>下面我们用数字（16进制）对图片中的每一个像素点（pixel）进行编号。 当使用右侧那种物体位于中间的训练数据来训练网络时，网络就只会对编号为5,6,9,a的节点的权重进行调节。 若让该网络识别位于右下角的“横折”时，则无法识别。<br><img src="https://picb.zhimg.com/80/v2-ce9919e4930c1f29241afec0538b2605_720w.png" alt><br>解决办法是用大量物体位于不同位置的数据训练，同时增加网络的隐藏层个数从而扩大网络学习这些变体的能力。</p>
<p>然而这样做十分不效率，因为我们知道在左侧的“横折”也好，还是在右侧的“横折”也罢，大家都是“横折”。 为什么相同的东西在位置变了之后要重新学习？有没有什么方法可以将中间所学到的规律也运用在其他的位置？ 换句话说，也就是让不同位置用相同的权重。</p>
<p>图片识别—卷积神经网络<br>卷积神经网络就是让权重在不同位置共享的神经网络。</p>
<p>局部连接<br>在卷积神经网络中，我们先选择一个局部区域，用这个局部区域去扫描整张图片。 局部区域所圈起来的所有节点会被连接到下一层的一个节点上。</p>
<p>为了更好的和前馈神经网络做比较，我将这些以矩阵排列的节点展成了向量。 下图展示了被红色方框所圈中编号为0,1,4,5的节点是如何通过w1,w2,w3,w4连接到下一层的节点0上的。<br><img src="https://pic1.zhimg.com/80/v2-e877b9099b1139c1a34b0bf66bf92aa4_720w.png" alt><br>这个带有连接强弱的红色方框就叫做 filter 或 kernel 或 feature detector。 而filter的范围叫做filter size，这里所展示的是2x2的filter size。<br>$\left[ \begin{array}{cc} w_1&amp;w_2\\w_3&amp;w_4 \end{array} \right]$<br>第二层的节点0的数值就是局部区域的线性组合，即被圈中节点的数值乘以对应的权重后相加。 用x表示输入值，y表示输出值，用图中标注数字表示角标，则下面列出了两种计算编号为0的输出值$y_0$的表达式。</p>
<p>注：在局部区域的线性组合后，也会和前馈神经网络一样，加上一个偏移量$b_0$。<br><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+y_0+%26%3D+x_0%2Aw_1+%2B+x_1%2Aw_2%2B+x_4%2Aw_3%2B+x_5%2Aw_4%2Bb_0%5C%5Cy_0+%26%3D+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_1%26w_2%26+w_3%26w_4+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_0%5C%5C+x_1%5C%5C+x_4%5C%5C+x_5%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%2Bb_0+%5Cend%7Bsplit%7D" alt></p>
<p>空间共享<br>当filter扫到其他位置计算输出节点[公式]时，[公式]，包括[公式]是共用的。</p>
<p>下面这张动态图展示了当filter扫过不同区域时，节点的链接方式。 动态图的最后一帧则显示了所有连接。 可以注意到，每个输出节点并非像前馈神经网络中那样与全部的输入节点连接，而是部分连接。 这也就是为什么大家也叫前馈神经网络（feedforward neural network）为fully-connected neural network。 图中显示的是一步一步的移动filter来扫描全图，一次移动多少叫做stride。<br>![](<a href="https://pic1.zhimg.com/v2-4fd0400ccebc8adb2dffe24aac163e70_b.jpg" target="_blank" rel="noopener">https://pic1.zhimg.com/v2-4fd0400ccebc8adb2dffe24aac163e70_b.jpg</a></p>
<blockquote>
<p>空间共享也就是卷积神经网络所引入的先验知识。</p>
</blockquote>
<p>输出表达<br>如先前在图像表达中提到的，图片不用向量去表示是为了保留图片平面结构的信息。 同样的，卷积后的输出若用上图的排列方式则丢失了平面结构信息。 所以我们依然用矩阵的方式排列它们，就得到了下图所展示的连接。<br><img src="https://pic4.zhimg.com/80/v2-e1691956fd1beb5d7a637924a1a73d91_720w.png" alt><br>这也就是你们在网上所看到的下面这张图。在看这张图的时候请结合上图的连接一起理解，即输入（绿色）的每九个节点连接到输出（粉红色）的一个节点上的。<br><img src="https://pic3.zhimg.com/v2-7fce29335f9b43bce1b373daa40cccba_b.jpg" alt><br>经过一个feature detector计算后得到的粉红色区域也叫做一个“Convolved Feature” 或 “Activation Map” 或 “Feature Map”。<br>Depth维的处理<br>现在我们已经知道了depth维度只有1的灰度图是如何处理的。 但前文提过，图片的普遍表达方式是下图这样有3个channels的RGB颜色模型。 当depth为复数的时候，每个feature detector是如何卷积的？<br><img src="https://pic2.zhimg.com/80/v2-0d24890b2e0d73f4ce4ad17ebfb2d0c4_720w.png" alt></p>
<p>现象：2x2所表达的filter size中，一个2表示width维上的局部连接数，另一个2表示height维上的局部连接数，并却没有depth维上的局部连接数，是因为depth维上并非局部，而是全部连接的。</p>
<p>在2D卷积中，filter在张量的width维, height维上是局部连接，在depth维上是贯串全部channels的。</p>
<p>类比：想象在切蛋糕的时候，不管这个蛋糕有多少层，通常大家都会一刀切到底，但是在长和宽这两个维上是局部切割。</p>
<p>下面这张图展示了，在depth为复数时，filter是如何连接输入节点到输出节点的。 图中红、绿、蓝颜色的节点表示3个channels。 黄色节点表示一个feature detector卷积后得到的Feature Map。 其中被透明黑框圈中的12个节点会被连接到黄黑色的节点上。</p>
<p>在输入depth为1时：被filter size为2x2所圈中的4个输入节点连接到1个输出节点上。<br>在输入depth为3时：被filter size为2x2，但是贯串3个channels后，所圈中的12个输入节点连接到1个输出节点上。<br>在输入depth为n时：2x2xn个输入节点连接到1个输出节点上。<br><img src="https://pic2.zhimg.com/80/v2-23db15ec3f783bbb5cf811711e46dbba_720w.png" alt><br>(可从<a href="https%3A//www.vectary.com/u/yjango/cnn">vectary</a>在3D编辑下查看)</p>
<p>注意：三个channels的权重并不共享。 即当深度变为3后，权重也跟着扩增到了三组，如式子(3)所示，不同channels用的是自己的权重。 式子中增加的角标r,g,b分别表示red channel, green channel, blue channel的权重。<br><img src="https://www.zhihu.com/equation?tex=%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Br1%7D%26w_%7Br2%7D%5C%5C+w_%7Br3%7D%26w_%7Br4%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%2C+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bg1%7D%26w_%7Bg2%7D%5C%5C+w_%7Bg3%7D%26w_%7Bg4%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%2C+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bb1%7D%26w_%7Bb2%7D%5C%5C+w_%7Bb3%7D%26w_%7Bb4%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D" alt></p>
<p>计算例子：用$x_{r0}$表示red channel的编号为0的输入节点，$x_{g5}$表示green channel编号为5个输入节点。$x_{b1}$表示blue channel。如式子(4)所表达，这时的一个输出节点实际上是12个输入节点的线性组合。<br><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bsplit%7D+y_0+%26%3D+x_%7Br0%7D%2Aw_%7Br1%7D+%2B+x_%7Br1%7D%2Aw_%7Br2%7D%2B+x_%7Br4%7D%2Aw_%7Br3%7D%2B+x_%7Br5%7D%2Aw_%7Br4%7D%2B+x_%7Bg0%7D%2Aw_%7Bg1%7D+%2B+x_%7Bg1%7D%2Aw_%7Bg2%7D%2B+x_%7Bg4%7D%2Aw_%7Bg3%7D%2B+x_%7Bg5%7D%2Aw_%7Bg4%7D%2B+x_%7Bb0%7D%2Aw_%7Bb1%7D+%2B+x_%7Bb1%7D%2Aw_%7Bb2%7D%2B+x_%7Bb4%7D%2Aw_%7Bb3%7D%2B+x_%7Bb5%7D%2Aw_%7Bb4%7D%2Bb_0%5C%5Cy_0+%26%3D+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Br1%7D%26w_%7Br2%7D%26+w_%7Br3%7D%26w_%7Br4%7D+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_%7Br0%7D%5C%5C+x_%7Br1%7D%5C%5C+x_%7Br4%7D%5C%5C+x_%7Br5%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D+%2B%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bg1%7D%26w_%7Bg2%7D%26+w_%7Bg3%7D%26w_%7Bg4%7D+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_%7Bg0%7D%5C%5C+x_%7Bg1%7D%5C%5C+x_%7Bg4%7D%5C%5C+x_%7Bg5%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%2B%5Cleft%5B+%5Cbegin%7Bmatrix%7D+w_%7Bb1%7D%26w_%7Bb2%7D%26+w_%7Bb3%7D%26w_%7Bb4%7D+%5Cend%7Bmatrix%7D+%5Cright%5D+%5Ccdot+%5Cleft%5B+%5Cbegin%7Bmatrix%7D+x_%7Bb0%7D%5C%5C+x_%7Bb1%7D%5C%5C+x_%7Bb4%7D%5C%5C+x_%7Bb5%7D%5C%5C+%5Cend%7Bmatrix%7D+%5Cright%5D%2Bb_0%5Cend%7Bsplit%7D" alt><br>当filter扫到其他位置计算输出节点[公式]时，那12个权重在不同位置是共用的，如下面的动态图所展示。 透明黑框圈中的12个节点会连接到被白色边框选中的黄色节点上。<br><img src="https://pic4.zhimg.com/v2-0bc83b72ef50099b70a10cc3ab528f62_b.jpg" alt></p>
<blockquote>
<p>每个filter会在width维, height维上，以局部连接和空间共享，并贯串整个depth维的方式得到一个Feature Map。</p>
</blockquote>
<p>Zero padding<br>细心的读者应该早就注意到了，4x4的图片被2x2的filter卷积后变成了3x3的图片，每次卷积后都会小一圈的话，经过若干层后岂不是变的越来越小？ Zero padding就可以在这时帮助控制Feature Map的输出尺寸，同时避免了边缘信息被一步步舍弃的问题。</p>
<p>例如：下面4x4的图片在边缘Zero padding一圈后，再用3x3的filter卷积后，得到的Feature Map尺寸依然是4x4不变。<br><img src="https://picb.zhimg.com/80/v2-c1010eb5dcf032ea95eab495a45f9b31_720w.png" alt><br>通常大家都想要在卷积时保持图片的原始尺寸。 选择3x3的filter和1的zero padding，或5x5的filter和2的zero padding可以保持图片的原始尺寸。 这也是为什么大家多选择3x3和5x5的filter的原因。 另一个原因是3x3的filter考虑到了像素与其距离为1以内的所有其他像素的关系，而5x5则是考虑像素与其距离为2以内的所有其他像素的关系。</p>
<p>尺寸：Feature Map的尺寸等于(input_size + 2 * padding_size − filter_size)/stride+1。</p>
<p>注意：上面的式子是计算width或height一维的。padding_size也表示的是单边补零的个数。例如(4+2-3)/1+1 = 4，保持原尺寸。</p>
<p>不用去背这个式子。其中(input_size + 2 * padding_size)是经过Zero padding扩充后真正要卷积的尺寸。 减去 filter_size后表示可以滑动的范围。 再除以可以一次滑动（stride）多少后得到滑动了多少次，也就意味着得到了多少个输出节点。 再加上第一个不需要滑动也存在的输出节点后就是最后的尺寸。</p>
<p>形状、概念抓取<br>知道了每个filter在做什么之后，我们再来思考这样的一个filter会抓取到什么样的信息。</p>
<p>我们知道不同的形状都可由细小的“零件”组合而成的。比如下图中，用2x2的范围所形成的16种形状可以组合成格式各样的“更大”形状。</p>
<p>卷积的每个filter可以探测特定的形状。又由于Feature Map保持了抓取后的空间结构。若将探测到细小图形的Feature Map作为新的输入再次卷积后，则可以由此探测到“更大”的形状概念。 比如下图的第一个“大”形状可由2,3,4,5基础形状拼成。第二个可由2,4,5,6组成。第三个可由6,1组成。<br><img src="https://pic4.zhimg.com/80/v2-f53f6ac43abd2555cfbbba6ea7fdc0e4_720w.png" alt><br>除了基础形状之外，颜色、对比度等概念对画面的识别结果也有影响。卷积层也会根据需要去探测特定的概念。</p>
<p>可以从下面这张图中感受到不同数值的filters所卷积过后的Feature Map可以探测边缘，棱角，模糊，突出等概念。<br><img src="https://pic4.zhimg.com/80/v2-644d108587a6ce7fa471ede5d2e11e98_720w.png" alt></p>
<p>如我们先前所提，图片被识别成什么不仅仅取决于图片本身，还取决于图片是如何被观察的。</p>
<p>而filter内的权重矩阵W是网络根据数据学习得到的，也就是说，我们让神经网络自己学习以什么样的方式去观察图片。</p>
<p>拿老妇与少女的那幅图片举例，当标签是少女时，卷积网络就会学习抓取可以成少女的形状、概念。 当标签是老妇时，卷积网络就会学习抓取可以成老妇的形状、概念。</p>
<p>下图展现了在人脸识别中经过层层的卷积后，所能够探测的形状、概念也变得越来越抽象和复杂。</p>
<p><img src="https://pic4.zhimg.com/80/v2-c78b8d059715bb5f42c93716a98d5a69_720w.jpg" alt></p>
<blockquote>
<p>卷积神经网络会尽可能寻找最能解释训练数据的抓取方式。</p>
</blockquote>
<p>多filters<br>每个filter可以抓取探测特定的形状的存在。 假如我们要探测下图的长方框形状时，可以用4个filters去探测4个基础“零件”。<br><img src="https://pic4.zhimg.com/80/v2-6df64fccc9a8e2f696626f85233acb3c_720w.png" alt><br><img src="https://pic3.zhimg.com/80/v2-65461a21a909eca2e190c54db59a2c8f_720w.png" alt></p>
<p>因此我们自然而然的会选择用多个不同的filters对同一个图片进行多次抓取。 如下图（动态图过大，如果显示不出，请看到该<a href="https://link.zhihu.com/?target=https%3A//ujwlkarn.files.wordpress.com/2016/08/giphy.gif">链接</a>观看），同一个图片，经过两个（红色、绿色）不同的filters扫描过后可得到不同特点的Feature Maps。 每增加一个filter，就意味着你想让网络多抓取一个特征。<br><img src="https://pic4.zhimg.com/v2-c7f1ea1d42820b4de30bd548c3986ecd_b.jpg" alt></p>
<p>这样卷积层的输出也不再是depth为1的一个平面，而是和输入一样是depth为复数的长方体。</p>
<p>如下图所示，当我们增加一个filter（紫色表示）后，就又可以得到一个Feature Map。 将不同filters所卷积得到的Feature Maps按顺序堆叠后，就得到了一个卷积层的最终输出。<br><img src="https://pic3.zhimg.com/80/v2-d11e1d2f2c41b6df713573f8155bc324_720w.png" alt></p>
<blockquote>
<p>卷积层的输入是长方体，输出也是长方体。</p>
</blockquote>
<p>这样卷积后输出的长方体可以作为新的输入送入另一个卷积层中处理。</p>
<p>加入非线性<br>和前馈神经网络一样，经过线性组合和偏移后，会加入非线性增强模型的拟合能力。</p>
<p>将卷积所得的Feature Map经过ReLU变换（elementwise）后所得到的output就如下图所展示。<br><img src="https://pic4.zhimg.com/80/v2-54a469b2873542e75abf2bc5d8fcaa1a_720w.png" alt></p>
<p>输出长方体<br>现在我们知道了一个卷积层的输出也是一个长方体。 那么这个输出长方体的(width, height, depth)由哪些因素决定和控制。</p>
<p>这里直接用CS231n的Summary：<br><img src="https://pic3.zhimg.com/80/v2-a9983c3cee935b68c73965bc1abe268c_720w.png" alt></p>
<p>计算例子：请体会<a href="https://link.zhihu.com/?target=http%3A//cs231n.github.io/convolutional-networks/">CS231n</a>的Convolution Demo部分的演示。</p>
<p>矩阵乘法执行卷积<br>如果按常规以扫描的方式一步步计算局部节点和filter的权重的点乘，则不能高效的利用GPU的并行能力。 所以更普遍的方法是用两个大矩阵的乘法来一次性囊括所有计算。</p>
<p>因为卷积层的每个输出节点都是由若干个输入节点的线性组合所计算。 因为输出的节点个数是$W_2\times H_2 \times D_2$，所以就有$W_2 \times H_2 \times D_2$个线性组合。</p>
<p>读过我写的线性代数教程的读者请回忆，矩阵乘矩阵的意义可以理解为批量的线性组合按顺序排列。 其中一个矩阵所表示的信息是多组权重，另一个矩阵所表示的信息是需要进行组合的向量。 大家习惯性的把组成成分放在矩阵乘法的右边，而把权重放在矩阵乘法的左边。 所以这个大型矩阵乘法可以用$W_{row}·X_{col}$表示，其中$W_{row}$和$X_{col}$都是矩阵。<br><img src="https://pic3.zhimg.com/80/v2-11a4d56793af815eb2b4585d64aec178_720w.png" alt></p>
<p>卷积的每个输出是由局部的输入节点和对应的filter权重展成向量后所计算的，如式子(2)。 那么$W_{row}$中的每一行则是每个filter的权重，有$F·F·D_1$个； 而$X_{col}$的每一列是所有需要进行组合的节点（上面的动态图中被黑色透明框圈中的节点），也有$F·F·D_1$个。 $X_{col}$的列的个数则表示每个filter要滑动多少次才可以把整个图片扫描完，有$W_2·H_2$次。 因为我们有多个filters，$W_{row}$的行的个数则是filter的个数K。<br>最后我们得到：<br>$W_{row} \in R^{K\times·F·D_1}$<br>$X_{col} \in R^{K·F·D_1 \times W_2·H_2}$<br>$W_{row}·X_{col} \in R^{K\times·H_2}$</p>
<p>当然矩阵乘法后需要将$W_{row} \times X_{col}$整理成形状为$W_2 \times H_2 \times D_2$的三维张量以供后续处理（如再送入另一个卷积层）。 $X_{col}$则也需要逐步的局部滑动图片，最后堆叠构成用于计算矩阵乘法的形式。</p>
<p>Max pooling<br>在卷积后还会有一个pooling的操作，尽管有其他的比如average pooling等，这里只提max pooling。</p>
<p>max pooling的操作如下图所示：整个图片被不重叠的分割成若干个同样大小的小块（pooling size）。每个小块内只取最大的数字，再舍弃其他节点后，保持原有的平面结构得出output。<br><img src="https://pic4.zhimg.com/80/v2-1a4b2a3795d8f073e921d766e70ce6ec_720w.jpg" alt></p>
<p>max pooling在不同的depth上是分开执行的，且不需要参数控制。 那么问题就max pooling有什么作用？部分信息被舍弃后难道没有影响吗？<br><img src="https://pic1.zhimg.com/80/v2-cd717414dcf32dac4df73c00f1e7c6c3_720w.jpg" alt></p>
<p>Max pooling的主要功能是downsamping，却不会损坏识别结果。 这意味着卷积后的Feature Map中有对于识别物体不必要的冗余信息。 那么我们就反过来思考，这些“冗余”信息是如何产生的。</p>
<p>直觉上，我们为了探测到某个特定形状的存在，用一个filter对整个图片进行逐步扫描。但只有出现了该特定形状的区域所卷积获得的输出才是真正有用的，用该filter卷积其他区域得出的数值就可能对该形状是否存在的判定影响较小。 比如下图中，我们还是考虑探测“横折”这个形状。 卷积后得到3x3的Feature Map中，真正有用的就是数字为3的那个节点，其余数值对于这个任务而言都是无关的。 所以用3x3的Max pooling后，并没有对“横折”的探测产生影响。 试想在这里例子中如果不使用Max pooling，而让网络自己去学习。 网络也会去学习与Max pooling近似效果的权重。因为是近似效果，增加了更多的parameters的代价，却还不如直接进行Max pooling。<br><img src="https://pic3.zhimg.com/80/v2-8e9d7ec0662e903e475bd93a64067554_720w.png" alt></p>
<p>Max pooling还有类似“选择句”的功能。假如有两个节点，其中第一个节点会在某些输入情况下最大，那么网络就只在这个节点上流通信息；而另一些输入又会让第二个节点的值最大，那么网络就转而走这个节点的分支。</p>
<p>但是Max pooling也有不好的地方。因为并非所有的抓取都像上图的例子。有些周边信息对某个概念是否存在的判定也有影响。 并且Max pooling是对所有的Feature Maps进行等价的操作。就好比用相同网孔的渔网打鱼，一定会有漏网之鱼。</p>
<p>全连接层<br>当抓取到足以用来识别图片的特征后，接下来的就是如何进行分类。 全连接层（也叫前馈层）就可以用来将最后的输出映射到<a href="https%3A//yjango.gitbooks.io/superorganism/content/ren_gong_shen_jing_wang_luo.html">线性可分的空间</a>。 通常卷积网络的最后会将末端得到的长方体平摊(flatten)成一个长长的向量，并送入全连接层配合输出层进行分类。</p>
<p>卷积神经网络大致就是covolutional layer, pooling layer, ReLu layer, fully-connected layer的组合，例如下图所示的结构。<br><img src="https://picb.zhimg.com/80/v2-cf87890eb8f2358f23a1ac78eb764257_720w.png" alt></p>
<p>这里也体现了深层神经网络或deep learning之所以称deep的一个原因：模型将特征抓取层和分类层合在了一起。 负责特征抓取的卷积层主要是用来学习“如何观察”。</p>
<p>下图简述了机器学习的发展，从最初的人工定义特征再放入分类器的方法，到让机器自己学习特征，再到如今尽量减少人为干涉的deep learning。<br><img src="https://pic3.zhimg.com/80/v2-60e7c1e89c5aed5b828cbb24fc1e5a80_720w.png" alt></p>
<p>结构发展<br>以上介绍了卷积神经网络的基本概念。 以下是几个比较有名的卷积神经网络结构，详细的请看<a href="http%3A//cs231n.github.io/convolutional-networks/">CS231n</a>。</p>
<p>LeNet：第一个成功的卷积神经网络应用<br>AlexNet：类似LeNet，但更深更大。使用了层叠的卷积层来抓取特征（通常是一个卷积层马上一个max pooling层）<br>ZF Net：增加了中间卷积层的尺寸，让第一层的stride和filter size更小。<br>GoogLeNet：减少parameters数量，最后一层用max pooling层代替了全连接层，更重要的是Inception-v4模块的使用。<br>VGGNet：只使用3x3 卷积层和2x2 pooling层从头到尾堆叠。<br>ResNet：引入了跨层连接和batch normalization。<br>DenseNet：将跨层连接从头进行到尾。</p>
<p>总结一下：这些结构的发展趋势有：</p>
<p>使用small filter size的卷积层和pooling<br>去掉parameters过多的全连接层<br>Inception（稍后会对其中的细节进行说明）<br>跳层连接</p>
<p>不变性的满足<br>接下来会谈谈我个人的，对于画面不变性是如何被卷积神经网络满足的想法。 同时结合不变性，对上面提到的结构发展的重要变动进行直觉上的解读。</p>
<p>需要明白的是为什么加入不变性可以提高网络表现。 并不是因为我们用了更炫酷的处理方式，而是加入了先验知识，无需从零开始用数据学习，节省了训练所需数据量。 思考表现提高的原因一定要从训练所需要的数据量切入。 提出满足新的不变性特点的神经网络是计算机视觉的一个主要研究方向。</p>
<p>平移不变性<br>可以说卷积神经网络最初引入局部连接和空间共享，就是为了满足平移不变性。</p>
<p><img src="https://pic1.zhimg.com/80/v2-1aac56212d5d143a006d569318e3ee8b_720w.png" alt></p>
<p>因为空间共享，在不同位置的同一形状就可以被等价识别，所以不需要对每个位置都进行学习</p>
<p><img src="https://pic4.zhimg.com/80/v2-18c11c6f485e9f1bbc9a50eb3d248439_720w.png" alt></p>
<p>旋转和视角不变性<br>个人觉得卷积神经网络克服这一不变性的主要手段还是靠大量的数据。 并没有明确加入“旋转和视角不变性”的先验特性。<br><img src="https://picb.zhimg.com/80/v2-0ce892f8b247f2b48a76cc57cbcba41d_720w.png" alt></p>
<p><a href="https%3A//arxiv.org/abs/1703.06211">Deformable Convolutional Networks</a>似乎是对此变性进行了进行增强。</p>
<p>尺寸不变性<br>与平移不变性不同，最初的卷积网络并没有明确照顾尺寸不变性这一特点。</p>
<p>我们知道filter的size是事先选择的，而不同的尺寸所寻找的形状（概念）范围不同。</p>
<p>从直观上思考，如果选择小范围，再一步步通过组合，仍然是可以得到大范围的形状。 如3x3尺寸的形状都是可以由2x2形状的图形组合而成。所以形状的尺寸不变性对卷积神经网络而言并不算问题。 这恐怕ZF Net让第一层的stride和filter size更小，VGGNet将所有filter size都设置成3x3仍可以得到优秀结果的一个原因。</p>
<p>但是，除了形状之外，很多概念的抓取通常需要考虑一个像素与周边更多像素之间的关系后得出。 也就是说5x5的filter也是有它的优点。 同时，小尺寸的堆叠需要很多个filters来共同完成，如果需要抓取的形状恰巧在5x5的范围，那么5x5会比3x3来的更有效率。 所以一次性使用多个不同filter size来抓取多个范围不同的概念是一种顺理成章的想法，而这个也就是Inception。 可以说Inception是为了尺寸不变性而引入的一个先验知识。</p>
<p>Inception<br>下图是Inception的结构，尽管也有不同的版本，但是其动机都是一样的：消除尺寸对于识别结果的影响，一次性使用多个不同filter size来抓取多个范围不同的概念，并让网络自己选择需要的特征。</p>
<p>你也一定注意到了蓝色的1x1卷积，撇开它，先看左边的这个结构。</p>
<p>输入（可以是被卷积完的长方体输出作为该层的输入）进来后，通常我们可以选择直接使用像素信息(1x1卷积)传递到下一层，可以选择3x3卷积，可以选择5x5卷积，还可以选择max pooling的方式downsample刚被卷积后的feature maps。 但在实际的网络设计中，究竟该如何选择需要大量的实验和经验的。 Inception就不用我们来选择，而是将4个选项给神经网络，让网络自己去选择最合适的解决方案。</p>
<p>接下来我们再看右边的这个结构，多了很多蓝色的1x1卷积。 这些1x1卷积的作用是为了让网络根据需要能够更灵活的控制数据的depth的。<br><img src="https://pic1.zhimg.com/80/v2-9692631d087622f1b34c80055f13fac5_720w.png" alt></p>
<p>1x1卷积核<br>如果卷积的输出输入都只是一个平面，那么1x1卷积核并没有什么意义，它是完全不考虑像素与周边其他像素关系。 但卷积的输出输入是长方体，所以1x1卷积实际上是对每个像素点，在不同的channels上进行线性组合（信息整合），且保留了图片的原有平面结构，调控depth，从而完成升维或降维的功能。</p>
<p>如下图所示，如果选择2个filters的1x1卷积层，那么数据就从原本的depth 3 降到了2。若用4个filters，则起到了升维的作用。</p>
<p>这就是为什么上面Inception的4个选择中都混合一个1x1卷积，如右侧所展示的那样。 其中，绿色的1x1卷积本身就1x1卷积，所以不需要再用另一个1x1卷积。 而max pooling用来去掉卷积得到的Feature Map中的冗余信息，所以出现在1x1卷积之前，紧随刚被卷积后的feature maps。（由于没做过实验，不清楚调换顺序会有什么影响。）<br><img src="https://pic1.zhimg.com/80/v2-59429b22ac90930c502736b33db0d8e0_720w.png" alt></p>
<p>跳层连接<br>前馈神经网络也好，卷积神经网络也好，都是一层一层逐步变换的，不允许跳层组合。 但现实中是否有跳层组合的现象？</p>
<p>比如说我们在判断一个人的时候，很多时候我们并不是观察它的全部，或者给你的图片本身就是残缺的。 这时我们会靠单个五官，外加这个人的着装，再加他的身形来综合判断这个人，如下图所示。 这样，即便图片本身是残缺的也可以很好的判断它是什么。 这和前馈神经网络的先验知识不同，它允许不同层级之间的因素进行信息交互、综合判断。</p>
<p>残差网络就是拥有这种特点的神经网络。大家喜欢用identity mappings去解释为什么残差网络更优秀。 这里我只是提供了一个以先验知识的角度去理解的方式。 需要注意的是每一层并不会像我这里所展示的那样，会形成明确的五官层。 只是有这样的组合趋势，实际无法保证神经网络到底学到了什么内容。<br><img src="https://pic2.zhimg.com/80/v2-40fb6ab7bf89ce43af1c52e673da65eb_720w.png" alt></p>
<p>用下图举一个更易思考的例子。 图形1,2,3,4,5,6是第一层卷积层抓取到的概念。 图形7,8,9是第二层卷积层抓取到的概念。 图形7,8,9是由1,2,3,4,5,6的基础上组合而成的。</p>
<p>但当我们想要探测的图形10并不是单纯的靠图形7,8,9组成，而是第一个卷积层的图形6和第二个卷积层的8,9组成的话，不允许跨层连接的卷积网络不得不用更多的filter来保持第一层已经抓取到的图形信息。并且每次传递到下一层都需要学习那个用于保留前一层图形概念的filter的权重。 当层数变深后，会越来越难以保持，还需要max pooling将冗余信息去掉。</p>
<p>一个合理的做法就是直接将上一层所抓取的概念也跳层传递给下下一层，不用让其每次都重新学习。 就好比在编程时构建了不同规模的functions。 每个function我们都是保留，而不是重新再写一遍。提高了重用性。</p>
<p>同时，因为ResNet使用了跳层连接的方式。也不需要max pooling对保留低层信息时所产生的冗余信息进行去除。<br><img src="https://pic2.zhimg.com/80/v2-87fc4b7449d751c59977c3a368ae6f7e_720w.png" alt></p>
<p>Inception中的第一个1x1的卷积通道也有类似的作用，但是1x1的卷积仍有权重需要学习。 并且Inception所使用的结合方式是concatenate的合并成一个更大的向量的方式，而ResNet的结合方式是sum。 两个结合方式各有优点。 concatenate当需要用不同的维度去组合成新观念的时候更有益。 而sum则更适用于并存的判断。比如既有油头发，又有胖身躯，同时穿着常年不洗的牛仔裤，三个不同层面的概念并存时，该人会被判定为程序员的情况。 又比如双向LSTM中正向和逆向序列抓取的结合常用相加的方式结合。在语音识别中，这表示既可以正向抓取某种特征，又可以反向抓取另一种特征。当两种特征同时存在时才会被识别成某个特定声音。</p>
<p>在下图的ResNet中，前一层的输入会跳过部分卷积层，将底层信息传递到高层。<br><img src="https://pic4.zhimg.com/80/v2-d3fd09f011583932b832ea64f78233af_720w.png" alt><br>在下图的DenseNet中，底层信息会被传递到所有的后续高层。<br><img src="https://pic1.zhimg.com/80/v2-0bebba2947e5e968a93e6def0ae5d00c_720w.png" alt></p>
<p>后续<br>随着时间推移，各个ResNet,GoogLeNet等框架也都在原有的基础上进行了发展和改进。 但基本都是上文描述的概念的组合使用加上其他的tricks。</p>
<p>如下图所展示的，加入跳层连接的Inception-ResNet。<br><img src="https://pic3.zhimg.com/80/v2-389496d1436895dfe43199a0f54c35ca_720w.jpg" alt></p>
<h1 id="YJango的Word-Embedding—介绍"><a href="#YJango的Word-Embedding—介绍" class="headerlink" title="YJango的Word Embedding—介绍"></a><span id="header14">YJango的Word Embedding—介绍</span></h1><p><img src="https://pic2.zhimg.com/v2-55dca535836121c65546bc11e2d457c1_1440w.jpg?source=172ae18b" alt><br>单词表达<br>先前在卷积神经网络的一节中，提到过图片是如何在计算机中被表达的。 同样的，单词也需要用计算机可以理解的方式表达后，才可以进行接下来的操作。</p>
<p>One hot representation<br>程序中编码单词的一个方法是one hot encoding。</p>
<p>实例：有1000个词汇量。排在第一个位置的代表英语中的冠词”a”，那么这个”a”是用[1,0,0,0,0,…]，只有第一个位置是1，其余位置都是0的1000维度的向量表示，如下图中的第一列所示。</p>
<p><img src="https://pic3.zhimg.com/80/v2-09e1bda72c4b903e25db203ab4aa6dc6_720w.jpg" alt></p>
<p>也就是说，</p>
<p>在one hot representation编码的每个单词都是一个维度，彼此independent。<br>Distributed representation<br>然而每个单词彼此无关这个特点明显不符合我们的现实情况。我们知道大量的单词都是有关。</p>
<p>语义：girl和woman虽然用在不同年龄上，但指的都是女性。</p>
<p>复数：word和words仅仅是复数和单数的差别。</p>
<p>时态：buy和bought表达的都是“买”，但发生的时间不同。</p>
<p>所以用one hot representation的编码方式，上面的特性都没有被考虑到。</p>
<p>我们更希望用诸如“语义”，“复数”，“时态”等维度去描述一个单词。每一个维度不再是0或1，而是连续的实数，表示不同的程度。</p>
<p>目的</p>
<p>但是说到底，为什么我们想要用Distributed representation的方式去表达一个单词呢? 这样做带来了什么好处？</p>
<p>数据量角度</p>
<p>这需要再次记住我们的目的：</p>
<p>机器学习：从大量的个样本 ${(x_i,y_i)_{i=1}^N}$ 中，寻找可以较好预测未见过 $x_{new}$ 所对应 $y_{new}$ 的函数 $f:x-&gt;y$ 。</p>
<p>实例：在我们日常生活的学习中，大量的 ${(x_i,y_i)_{i=1}^N}$ 就是历年真题， $x_i$ 是题目，而 $y_i$ 是对应的正确答案。高考时将会遇到的 $x_{new}$ 往往是我们没见过的题目，希望可以通过做题训练出来的解题方法 $f:x-&gt;y$ 来求解出正确的 $y_{new}$ 。</p>
<p>如果可以见到所有的情况，那么只需要记住所有的 $x_i$ 所对应的 $y_i$ 就可以完美预测。但正如高考无法见到所有类型的题一样，我们无法见到所有的情况。这意味着，</p>
<blockquote>
<p>机器学习需要从有限的例子中寻找到合理的 f 。</p>
</blockquote>
<p>高考有两个方向提高分数：</p>
<p>方向一：训练更多的数据：题海战术。<br>方向二：加入先验知识：尽可能排除不必要的可能性。<br>问题的关键在于训练所需要的数据量上。</p>
<p>同理，如果我们用One hot representation去学习，那么每一个单词我们都需要实例数据去训练，即便我们知道”Cat”和”Kitty”很多情况下可以被理解成一个意思。</p>
<p>为什么相同的东西却需要分别用不同的数据进行学习？</p>
<p>神经网络分析<br>假设我们的词汇只有4个，girl, woman, boy, man，下面就思考用两种不同的表达方式会有什么区别。</p>
<p>One hot representation<br>尽管我们知道他们彼此的关系，但是计算机并不知道。在神经网络的输入层中，每个单词都会被看作一个节点。 而我们知道训练神经网络就是要学习每个连接线的权重。如果只看第一层的权重，下面的情况需要确定4*3个连接线的关系，因为每个维度都彼此独立，girl的数据不会对其他单词的训练产生任何帮助，训练所需要的数据量，基本就固定在那里了。<br><img src="https://pic4.zhimg.com/80/v2-e153aa561b6d729f5023e077eb7f204c_720w.jpg" alt></p>
<p>Distributed representation<br>我们这里手动的寻找这四个单词之间的关系 f 。可以用两个节点去表示四个单词。每个节点取不同值时的意义如下表。 那么girl就可以被编码成向量[0,1]，man可以被编码成[1,1]（第一个维度是gender，第二个维度是age）。</p>
<p><img src="https://pic4.zhimg.com/80/v2-a6c5f337408f1e3ec31d67074a830bd6_720w.jpg" alt></p>
<p>那么这时再来看神经网络需要学习的连接线的权重就缩小到了2*3。同时，当送入girl为输入的训练数据时，因为它是由两个节点编码的。那么与girl共享相同连接的其他输入例子也可以被训练到（如可以帮助到与其共享female的woman，和child的boy的训练）。</p>
<p><img src="https://pic2.zhimg.com/80/v2-764d83497fecd09920e19cfd91fb1dd8_720w.jpg" alt></p>
<p>Word embedding也就是要达到第二个神经网络所表示的结果，降低训练所需要的数据量。</p>
<p>而上面的四个单词可以被拆成2个节点的是由我们人工提供的先验知识将原始的输入空间经过 f (上图中的黄色箭头)投射到了另一个空间（维度更小），所以才能够降低训练所需要的数据量。 但是我们没有办法一直人工提供，机器学习的宗旨就是让机器代替人力去发现pattern。</p>
<p>Word embedding就是要从数据中自动学习到输入空间到Distributed representation空间的 映射f 。</p>
<p>训练方法<br>问题来了，我们该如何自动寻找到类似上面的关系，将One hot representation转变成Distributed representation。 我们事先并不明确目标是什么，所以这是一个无监督学习任务。</p>
<p>无监督学习中常用思想是：当得到数据${(x_i,y_i)_{i=1}^N}$后，我们又不知道目标（输出）时，</p>
<p>方向一：从各个输入 {${xi}_{i=1}^N$}之间的关系找目标。 如聚类。<br>方向二：并接上以目标输出 $y_i$ 作为新输入的另一个任务 $g:y-&gt;z$ ，同时我们知道的对应$z_i$ 值。用数据 ${(x_i,y_i)_{i=1}^N}$训练得到 $k:x-&gt;z$ ,也就是 $z=g(f(x))$ ，中间的表达 $y=f(x)$ 则是我们真正想要的目标。如生成对抗网络。</p>
<p>Word embedding更偏向于方向二。 同样是学习一个 k:x-&gt;z ，但训练后并不使用 k ，而是只取前半部分的 f:x-&gt;y 。</p>
<p>到这里，我们希望所寻找的 k:x-&gt;z 既有标签 z ，又可以让 f(x) 所转换得到的 y 的表达具有Distributed representation中所演示的特点。</p>
<p>同时我们还知道，</p>
<blockquote>
<p>单词意思需要放在特定的上下文中去理解。</p>
</blockquote>
<p>那么具有相同上下文的单词，往往是有联系的。</p>
<p>实例：那这两个单词都狗的品种名，而上下文的内容已经暗指了该单词具有可爱，会舔人的特点。</p>
<ul>
<li>这个可爱的 泰迪 舔了我的脸。</li>
<li>这个可爱的 金巴 舔了我的脸。<br>而从上面这个例子中我们就可以找到一个 $k:x-&gt;z$ ：预测上下文。</li>
</ul>
<blockquote>
<p>用输入单词 x 作为中心单词去预测其他单词 z 出现在其周边的可能性。</p>
</blockquote>
<p>我们既知道对应的 z ，同时该任务 k 又可以让 f(x) 所转换得到的 y 的表达具有Distributed representation中所演示的特点。 因为我们让相似的单词（如泰迪和金巴）得到相同的输出（上下文），那么神经网络就会将泰迪的输入和金巴的输入经过神经网络 f(x) 得到的泰迪的输出和 金巴的输出几乎相同。</p>
<p>用输入单词作为中心单词去预测周边单词的方式叫做：<a href="http%3A//mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">Word2Vec The Skip-Gram Model</a>。</p>
<p>用输入单词作为周边单词去预测中心单词的方式叫做：<a href="https%3A//iksinc.wordpress.com/tag/continuous-bag-of-words-cbow/">Continuous Bag of Words (CBOW)</a>。</p>
<h1 id="YJango的Batch-Normalization—介绍"><a href="#YJango的Batch-Normalization—介绍" class="headerlink" title="YJango的Batch Normalization—介绍"></a><span id="header15">YJango的Batch Normalization—介绍</span></h1><p>做法<br>设，每个batch输入是 $x=[x_0,x_1,x_2,…,x_n]$ （其中每个 $x_i$ 都是一个样本， n 是batch size） 假如在第一层后加入Batch normalization layer后， $h_i$ 的计算就倍替换为下图所示的那样。<br><img src="https://pic4.zhimg.com/80/v2-cd6a1087598ee5a2ae24d1a86a6b2190_720w.jpg" alt></p>
<ul>
<li>矩阵 x 先经过 $W_{h_1}$ 的线性变换后得到 $s_1$<ul>
<li>注：因为减去batch的平均值 $u_B$ 后， b 的作用会被抵消掉，所以没必要加入 b （红色删除线）。</li>
</ul>
</li>
<li>将 $s_1$ 再减去batch的平均值 $u_B$ ，并除以batch的标准差 $\sqrt{\sigma_B+\epsilon}$ 得到 $s_2$ 。 $\epsilon$ 是为了避免除数为0的情况所使用的微小正数。<ul>
<li>$u_B=\frac{1}{m} \sum_{i=0}^{m}W_{h_i}x_i$</li>
<li>$\sigma^2=\frac{1}{m} \sum_{i=0}^{m}(W_{h_i}-u_B)^2$</li>
<li>注：但 $s_2$ 基本会被限制在正态分布下，使得网络的表达能力下降。为解决该问题，引入两个新的parameters： $\gamma$ 和 $\beta$ 。 $\gamma$ 和 $\beta$ 是在训练时网络自己学习得到的。</li>
</ul>
</li>
<li>将 $s_2$ 乘以 $\gamma$ 调整数值大小，再加上 $\beta$ 增加偏移后得到 $s_3$ 。</li>
<li>为加入非线性能力， $s_3$ 也会跟随着ReLU等激活函数。</li>
<li>最终得到的 $h_1$ 会被送到下一层作为输入。</li>
</ul>
<p>需要注意的是，上述的计算方法用于在训练。因为测试时常会只预测一个新样本，也就是说batch size为1。若还用相同的方法计算 $u_B$ ， $u_B$ 就会是这个新样本自身， $s_1-u_B$ 就会成为0。</p>
<p>所以在测试时，所使用的 u 和 $\sigma^2$ 是整个训练集的均值 $u_p$ 和方差 $\sigma^2_p$ 。</p>
<p>而整个训练集的均值$u_p$和方差 $\sigma^2_p$ 的值通常也是在训练的同时用移动平均法来计算</p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/uploads/weixin.png" alt="Zhangshuai WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/uploads/zhifubao.jpg" alt="Zhangshuai Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/08/10/%E5%AD%A6%E4%B9%A0%E8%A7%82/" rel="next" title="学习观">
                <i class="fa fa-chevron-left"></i> 学习观
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar2.jpg"
                alt="Zhangshuai" />
            
              <p class="site-author-name" itemprop="name">Zhangshuai</p>
              <p class="site-description motion-element" itemprop="description">你刚才说了JOJO对吧</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7Carchive">
              
                  <span class="site-state-item-count">71</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=486194129&auto=1&height=66"></iframe>
          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/GitHubzhangshuai" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="1802528291@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/ying-ying-ying-vue" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i>知乎</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://music.163.com/#/user/home?id=377737250" target="_blank" title="网易云音乐">
                      
                        <i class="fa fa-fw fa-globe"></i>网易云音乐</a>
                  </span>
                
            </div>
          

          
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          

          
          

          

        </div>
      </section>


      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#函数、概率、信息的基础串讲"><span class="nav-number">1.</span> <span class="nav-text">函数、概率、信息的基础串讲</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#如何生动有趣的入门线性代数"><span class="nav-number">2.</span> <span class="nav-text">如何生动有趣的入门线性代数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率simple入门"><span class="nav-number">3.</span> <span class="nav-text">概率simple入门</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#很多人都不知道自动化与机器学习的区别"><span class="nav-number">4.</span> <span class="nav-text">很多人都不知道自动化与机器学习的区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习理论引入的知识分类"><span class="nav-number">5.</span> <span class="nav-text">机器学习理论引入的知识分类</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#英语总结"><span class="nav-number">6.</span> <span class="nav-text">英语总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#英语学习关键点"><span class="nav-number">6.1.</span> <span class="nav-text">英语学习关键点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#记音素要在单词中记忆"><span class="nav-number">6.2.</span> <span class="nav-text">记音素要在单词中记忆</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深层学习为何要“Deep”"><span class="nav-number">7.</span> <span class="nav-text">深层学习为何要“Deep”</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lt-span-id-”header8-gt-YJango的TensorFlow1-x整体把握-lt-span-gt"><span class="nav-number">8.</span> <span class="nav-text">&lt;span id&#x3D;”header8&gt;YJango的TensorFlow1.x整体把握&lt;&#x2F;span&gt;</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的循环神经网络——介绍"><span class="nav-number">9.</span> <span class="nav-text">YJango的循环神经网络——介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的循环神经网络——实现LSTM"><span class="nav-number">10.</span> <span class="nav-text">YJango的循环神经网络——实现LSTM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的循环神经网络——scan实现LSTM"><span class="nav-number">11.</span> <span class="nav-text">YJango的循环神经网络——scan实现LSTM</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#处理训练数据"><span class="nav-number">11.1.</span> <span class="nav-text">处理训练数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#权重初始化方法"><span class="nav-number">11.2.</span> <span class="nav-text">权重初始化方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#定义LSTM类"><span class="nav-number">11.3.</span> <span class="nav-text">定义LSTM类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建网络"><span class="nav-number">11.4.</span> <span class="nav-text">构建网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练网络"><span class="nav-number">11.5.</span> <span class="nav-text">训练网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预测效果"><span class="nav-number">11.6.</span> <span class="nav-text">预测效果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结说明"><span class="nav-number">11.7.</span> <span class="nav-text">总结说明</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的循环神经网络——双向LSTM-amp-GRU"><span class="nav-number">12.</span> <span class="nav-text">YJango的循环神经网络——双向LSTM&amp;GRU</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#定义LSTMcell类"><span class="nav-number">12.1.</span> <span class="nav-text">定义LSTMcell类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#定义GRUcell类"><span class="nav-number">12.2.</span> <span class="nav-text">定义GRUcell类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#定义RNN函数"><span class="nav-number">12.3.</span> <span class="nav-text">定义RNN函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的卷积神经网络——介绍"><span class="nav-number">13.</span> <span class="nav-text">YJango的卷积神经网络——介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的Word-Embedding—介绍"><span class="nav-number">14.</span> <span class="nav-text">YJango的Word Embedding—介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YJango的Batch-Normalization—介绍"><span class="nav-number">15.</span> <span class="nav-text">YJango的Batch Normalization—介绍</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script type="text/javascript" src="/js/src/busuanzi.js"></script>


<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张帅</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>









  <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
  <span class="post-meta-divider">|</span>
  <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>


<script>
setTimeout(function(){
document.getElementById('busuanzi_container_site_pv').style.display='inline-block'
document.getElementById('busuanzi_container_site_uv').style.display='inline-block'
},1000)
</script>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


  <!-- 页面点击小红心 -->


   <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
   <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
   <script type="text/javascript" src="/js/src/fireworks.js"></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
